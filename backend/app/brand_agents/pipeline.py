"""
Brand Analysis Pipeline

Multi-Agent Pipelineì˜ ë©”ì¸ ì¡°ìœ¨ì
"""

import logging
import asyncio
from typing import Dict, Optional, List
from datetime import datetime
from .collectors import BlogCollectorAgent, InstagramCollectorAgent, YouTubeCollectorAgent
from .normalizer import DataNormalizer
from .analyzers import TextAnalyzerAgent, VisualAnalyzerAgent, EngagementAnalyzerAgent
from .synthesizer import BrandProfileSynthesizer
from .schemas import BrandProfile, UnifiedContent, MediaInfo, BrandProfileSource, ConfidenceLevel

logger = logging.getLogger(__name__)


class BrandAnalysisPipeline:
    """
    ë¸Œëœë“œ ë¶„ì„ Multi-Agent Pipeline

    4 Layer Architecture:
    - Layer 1: Platform Collectors (ë°ì´í„° ìˆ˜ì§‘)
    - Layer 2: Data Normalizer (ë°ì´í„° ì •ê·œí™”)
    - Layer 3: Analysis Agents (ë¶„ì„)
    - Layer 4: Brand Profile Synthesizer (í†µí•©)
    """

    def __init__(self, db=None):
        """
        Args:
            db: Database session (YouTube Collectorì— í•„ìš”)
        """
        self.db = db

        # Layer 1: Collectors (YouTubeëŠ” ëŸ°íƒ€ì„ì— ìƒì„±)
        self.collectors = {
            'blog': BlogCollectorAgent(),
            'instagram': InstagramCollectorAgent()
        }

        # Layer 2: Normalizer
        self.normalizer = DataNormalizer()

        # Layer 3: Analyzers
        self.analyzers = {
            'text': TextAnalyzerAgent(),
            'visual': VisualAnalyzerAgent(),
            'engagement': EngagementAnalyzerAgent()
        }

        # Layer 4: Synthesizer
        self.synthesizer = BrandProfileSynthesizer()

    async def run(
        self,
        user_id: int,
        platform_urls: Dict[str, str],
        max_items: int = 10
    ) -> BrandProfile:
        """
        ë¸Œëœë“œ ë¶„ì„ Pipeline ì‹¤í–‰

        Args:
            user_id: ì‚¬ìš©ì ID (int)
            platform_urls: í”Œë«í¼ë³„ URL
                {
                    'blog': 'https://blog.naver.com/example',
                    'instagram': 'https://instagram.com/example',
                    'youtube': 'connected'  # YouTubeëŠ” OAuth ì—°ë™ ê¸°ë°˜
                }
            max_items: ê° í”Œë«í¼ë‹¹ ìµœëŒ€ ìˆ˜ì§‘ ì•„ì´í…œ ìˆ˜

        Returns:
            BrandProfile ê°ì²´
        """
        try:
            logger.info("=" * 80)
            logger.info("ğŸš€ Brand Analysis Multi-Agent Pipeline ì‹œì‘")
            logger.info("=" * 80)

            # ===== Layer 1: ë°ì´í„° ìˆ˜ì§‘ =====
            logger.info("\nğŸ“¦ Layer 1: Platform Data Collection")
            logger.info("-" * 80)

            collection_tasks = []
            platforms_to_analyze = []

            # ì…ë ¥ëœ í”Œë«í¼ì— ëŒ€í•´ì„œë§Œ collector ì‹¤í–‰
            if 'blog' in platform_urls and platform_urls['blog']:
                logger.info(f"  âœ“ ë¸”ë¡œê·¸ ìˆ˜ì§‘ ì˜ˆì •: {platform_urls['blog']}")
                collection_tasks.append(
                    self.collectors['blog'].collect(platform_urls['blog'], max_items)
                )
                platforms_to_analyze.append('naver_blog')

            if 'instagram' in platform_urls and platform_urls['instagram']:
                logger.info(f"  âœ“ ì¸ìŠ¤íƒ€ê·¸ë¨ ìˆ˜ì§‘ ì˜ˆì •: {platform_urls['instagram']}")
                collection_tasks.append(
                    self.collectors['instagram'].collect(platform_urls['instagram'], max_items)
                )
                platforms_to_analyze.append('instagram')

            # YouTubeëŠ” OAuth ì—°ë™ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì§‘
            if 'youtube' in platform_urls and platform_urls['youtube']:
                logger.info(f"  âœ“ YouTube ìˆ˜ì§‘ ì˜ˆì • (OAuth ì—°ë™ ê¸°ë°˜)")
                youtube_collector = YouTubeCollectorAgent(db=self.db, user_id=user_id)
                collection_tasks.append(
                    youtube_collector.collect(max_items=max_items)
                )
                platforms_to_analyze.append('youtube')

            if not collection_tasks:
                raise ValueError("ë¶„ì„í•  í”Œë«í¼ì´ ì—†ìŠµë‹ˆë‹¤")

            # ë³‘ë ¬ ìˆ˜ì§‘ ì‹¤í–‰
            logger.info(f"\n  â³ {len(collection_tasks)}ê°œ í”Œë«í¼ ë³‘ë ¬ ìˆ˜ì§‘ ì¤‘...")
            raw_contents_lists = await asyncio.gather(*collection_tasks, return_exceptions=False)

            # ê²°ê³¼ ë³‘í•©
            raw_contents = []
            for raw_list in raw_contents_lists:
                if raw_list:
                    raw_contents.extend(raw_list)

            logger.info(f"  âœ… ì´ {len(raw_contents)}ê°œ ì½˜í…ì¸  ìˆ˜ì§‘ ì™„ë£Œ")

            if not raw_contents:
                raise ValueError("ìˆ˜ì§‘ëœ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤")

            # ===== Layer 2: ë°ì´í„° ì •ê·œí™” =====
            logger.info("\nğŸ”„ Layer 2: Data Normalization")
            logger.info("-" * 80)

            unified_contents = [
                self.normalizer.normalize(raw) for raw in raw_contents
            ]
            logger.info(f"  âœ… {len(unified_contents)}ê°œ ì½˜í…ì¸  ì •ê·œí™” ì™„ë£Œ")

            # ===== Layer 3: ë¶„ì„ =====
            logger.info("\nğŸ” Layer 3: Multi-Agent Analysis")
            logger.info("-" * 80)

            logger.info("  ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘...")
            logger.info("  ğŸ¨ ë¹„ì£¼ì–¼ ë¶„ì„ ì‹œì‘...")
            logger.info("  ğŸ“Š ì°¸ì—¬ ì§€í‘œ ë¶„ì„ ì‹œì‘...")

            # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
            text_analysis, visual_analysis, engagement_analysis = await asyncio.gather(
                self.analyzers['text'].analyze(unified_contents),
                self.analyzers['visual'].analyze(unified_contents),
                self.analyzers['engagement'].analyze(unified_contents)
            )

            logger.info("  âœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ")

            # ===== Layer 4: ë¸Œëœë“œ í”„ë¡œí•„ í†µí•© =====
            logger.info("\nğŸ”® Layer 4: Brand Profile Synthesis")
            logger.info("-" * 80)

            brand_profile = await self.synthesizer.synthesize(
                user_id=user_id,
                text_analysis=text_analysis,
                visual_analysis=visual_analysis,
                engagement_analysis=engagement_analysis,
                unified_contents=unified_contents,
                analyzed_platforms=platforms_to_analyze
            )

            # âœ… ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸: SNS ë¶„ì„ì„ì„ ëª…ì‹œ
            brand_profile.source = BrandProfileSource.SNS_ANALYSIS
            brand_profile.confidence_level = ConfidenceLevel.HIGH
            brand_profile.updated_at = datetime.utcnow()

            logger.info("=" * 80)
            logger.info("âœ… Brand Analysis Pipeline ì™„ë£Œ!")
            logger.info(f"   ë¸Œëœë“œëª…: {brand_profile.brand_name or '(ë¯¸í™•ì¸)'}")
            logger.info(f"   ë¶„ì„ëœ í”Œë«í¼: {', '.join(platforms_to_analyze)}")
            logger.info(f"   ì´ ì½˜í…ì¸  ìˆ˜: {len(unified_contents)}")
            logger.info(f"   ì‹ ë¢°ë„: {brand_profile.confidence_level}")
            logger.info("=" * 80 + "\n")

            return brand_profile

        except Exception as e:
            logger.error(f"\nâŒ Pipeline ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise Exception(f"ë¸Œëœë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

    async def run_from_manual_samples(
        self,
        user_id: str,
        text_samples: Optional[List[str]] = None,
        image_samples: Optional[List[str]] = None,
        video_samples: Optional[List[str]] = None
    ) -> BrandProfile:
        """
        ìˆ˜ë™ ìƒ˜í”Œë¡œë¶€í„° ë¸Œëœë“œ ë¶„ì„ (Multi-Agent Pipeline í™œìš©)

        Args:
            user_id: ì‚¬ìš©ì ID
            text_samples: í…ìŠ¤íŠ¸ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
            image_samples: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            video_samples: ì˜ìƒ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

        Returns:
            BrandProfile ê°ì²´ (source=MANUAL_SAMPLES, confidence_level=MEDIUM)
        """
        try:
            logger.info("=" * 80)
            logger.info("ğŸš€ Manual Samples Brand Analysis Pipeline ì‹œì‘")
            logger.info("=" * 80)

            # ===== Layer 1 ê±´ë„ˆë›°ê¸°: ìˆ˜ë™ ìƒ˜í”Œì„ UnifiedContentë¡œ ë³€í™˜ =====
            logger.info("\nğŸ“¦ Manual Samples â†’ UnifiedContent ë³€í™˜")
            logger.info("-" * 80)

            unified_contents = []

            # í…ìŠ¤íŠ¸ ìƒ˜í”Œ ë³€í™˜
            if text_samples:
                for idx, text in enumerate(text_samples):
                    if text and text.strip():
                        unified_contents.append(UnifiedContent(
                            platform='manual_text',
                            title=None,
                            body_text=text,
                            media=None,
                            tags=[],
                            engagement=None,
                            created_at=datetime.utcnow(),
                            platform_specific={'sample_index': idx}
                        ))
                logger.info(f"  âœ“ {len(text_samples)}ê°œ í…ìŠ¤íŠ¸ ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ")

            # ì´ë¯¸ì§€ ìƒ˜í”Œ ë³€í™˜
            if image_samples:
                for idx, img_path in enumerate(image_samples):
                    unified_contents.append(UnifiedContent(
                        platform='manual_image',
                        title=None,
                        body_text='',
                        media=MediaInfo(
                            type='image',
                            urls=[img_path],
                            count=1
                        ),
                        tags=[],
                        engagement=None,
                        created_at=datetime.utcnow(),
                        platform_specific={'sample_index': idx, 'file_path': img_path}
                    ))
                logger.info(f"  âœ“ {len(image_samples)}ê°œ ì´ë¯¸ì§€ ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ")

            # ì˜ìƒ ìƒ˜í”Œ ë³€í™˜
            if video_samples:
                for idx, vid_path in enumerate(video_samples):
                    unified_contents.append(UnifiedContent(
                        platform='manual_video',
                        title=None,
                        body_text='',
                        media=MediaInfo(
                            type='video',
                            urls=[vid_path],
                            count=1
                        ),
                        tags=[],
                        engagement=None,
                        created_at=datetime.utcnow(),
                        platform_specific={'sample_index': idx, 'file_path': vid_path}
                    ))
                logger.info(f"  âœ“ {len(video_samples)}ê°œ ì˜ìƒ ìƒ˜í”Œ ë³€í™˜ ì™„ë£Œ")

            if not unified_contents:
                raise ValueError("ë³€í™˜ëœ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤")

            logger.info(f"  âœ… ì´ {len(unified_contents)}ê°œ ìƒ˜í”Œ UnifiedContentë¡œ ë³€í™˜ ì™„ë£Œ")

            # ===== Layer 2: ì •ê·œí™” ê±´ë„ˆë›°ê¸° (ì´ë¯¸ UnifiedContent í˜•ì‹) =====

            # ===== Layer 3: ë¶„ì„ =====
            logger.info("\nğŸ” Layer 3: Multi-Agent Analysis")
            logger.info("-" * 80)

            logger.info("  ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘...")
            logger.info("  ğŸ¨ ë¹„ì£¼ì–¼ ë¶„ì„ ì‹œì‘...")
            logger.info("  ğŸ“Š ì°¸ì—¬ ì§€í‘œ ë¶„ì„ ì‹œì‘...")

            # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
            text_analysis, visual_analysis, engagement_analysis = await asyncio.gather(
                self.analyzers['text'].analyze(unified_contents),
                self.analyzers['visual'].analyze(unified_contents),
                self.analyzers['engagement'].analyze(unified_contents)
            )

            logger.info("  âœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ")

            # ===== Layer 4: ë¸Œëœë“œ í”„ë¡œí•„ í†µí•© =====
            logger.info("\nğŸ”® Layer 4: Brand Profile Synthesis")
            logger.info("-" * 80)

            brand_profile = await self.synthesizer.synthesize(
                user_id=user_id,
                text_analysis=text_analysis,
                visual_analysis=visual_analysis,
                engagement_analysis=engagement_analysis,
                unified_contents=unified_contents,
                analyzed_platforms=['manual_samples']
            )

            # âœ… ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸: ìˆ˜ë™ ìƒ˜í”Œ ë¶„ì„ì„ì„ ëª…ì‹œ
            brand_profile.source = BrandProfileSource.MANUAL_SAMPLES
            brand_profile.confidence_level = ConfidenceLevel.MEDIUM
            brand_profile.updated_at = datetime.utcnow()

            logger.info("=" * 80)
            logger.info("âœ… Manual Samples Brand Analysis Pipeline ì™„ë£Œ!")
            logger.info(f"   ë¸Œëœë“œëª…: {brand_profile.brand_name or '(ë¯¸í™•ì¸)'}")
            logger.info(f"   ë¶„ì„ëœ ìƒ˜í”Œ: {len(unified_contents)}ê°œ")
            logger.info(f"   ì‹ ë¢°ë„: {brand_profile.confidence_level}")
            logger.info("=" * 80 + "\n")

            return brand_profile

        except Exception as e:
            logger.error(f"\nâŒ Manual Samples Pipeline ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise Exception(f"ìˆ˜ë™ ìƒ˜í”Œ ë¸Œëœë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
