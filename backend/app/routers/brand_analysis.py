"""
ë©€í‹° í”Œë«í¼ ë¸Œëœë“œ ë¶„ì„ API ë¼ìš°í„°
"""

from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks, UploadFile, File, Form
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
from datetime import datetime
import logging
import asyncio

from ..database import get_db, SessionLocal
from ..models import User, BrandAnalysis
from ..auth import get_current_user
from ..services.naver_blog_service import NaverBlogService
from ..services.brand_analyzer_service import BrandAnalyzerService

router = APIRouter(prefix="/api/brand-analysis", tags=["brand-analysis"])
logger = logging.getLogger(__name__)


class MultiPlatformAnalysisRequest(BaseModel):
    """ë©€í‹° í”Œë«í¼ ë¶„ì„ ìš”ì²­"""
    blog_url: Optional[str] = None
    instagram_url: Optional[str] = None
    youtube_url: Optional[str] = None
    max_posts: int = 10  # ê° í”Œë«í¼ë‹¹ ìµœëŒ€ í¬ìŠ¤íŠ¸ ìˆ˜


class ManualAnalysisRequest(BaseModel):
    """ìˆ˜ë™ ì½˜í…ì¸  ë¶„ì„ ìš”ì²­"""
    text_samples: Optional[List[str]] = None
    # image_samplesì™€ video_samplesëŠ” FormDataë¡œ ë°›ìŒ


class AnalysisResponse(BaseModel):
    """ë¶„ì„ ì‘ë‹µ"""
    status: str
    message: str
    analysis: Optional[Dict[str, Any]] = None


async def analyze_blog_platform(blog_url: str, max_posts: int) -> Dict[str, Any]:
    """ë¸”ë¡œê·¸ í”Œë«í¼ ë¶„ì„"""
    try:
        logger.info(f"ë¸”ë¡œê·¸ ë¶„ì„ ì‹œì‘: {blog_url}")
        blog_service = NaverBlogService()
        posts = await blog_service.collect_blog_posts(blog_url, max_posts)

        if not posts:
            return None

        # ë¸”ë¡œê·¸ ë¶„ì„ (BrandAnalyzerService ì‚¬ìš©)
        analyzer = BrandAnalyzerService()
        result = await analyzer.analyze_brand(posts, {})

        return {
            "url": blog_url,
            "analyzed_posts": len(posts),
            "analysis": result
        }
    except Exception as e:
        logger.error(f"ë¸”ë¡œê·¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None


async def analyze_instagram_platform(instagram_url: str, max_posts: int) -> Dict[str, Any]:
    """ì¸ìŠ¤íƒ€ê·¸ë¨ í”Œë«í¼ ë¶„ì„ (TODO: ì‹¤ì œ êµ¬í˜„ í•„ìš”)"""
    try:
        logger.info(f"ì¸ìŠ¤íƒ€ê·¸ë¨ ë¶„ì„ ì‹œì‘: {instagram_url}")
        # TODO: ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ë¡¤ë§ ë° ë¶„ì„ êµ¬í˜„
        # í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        return {
            "url": instagram_url,
            "analyzed_posts": 0,
            "analysis": {
                "instagram": {
                    "caption_style": "ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ”",
                    "image_style": "ë°ê³  í™”ì‚¬í•œ",
                    "hashtag_pattern": "5-10ê°œ, ë¸Œëœë“œëª… í¬í•¨",
                    "color_palette": ["#FF6B6B", "#4ECDC4", "#45B7D1"]
                }
            }
        }
    except Exception as e:
        logger.error(f"ì¸ìŠ¤íƒ€ê·¸ë¨ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None


async def analyze_youtube_platform(youtube_url: str, max_videos: int) -> Dict[str, Any]:
    """ìœ íŠœë¸Œ í”Œë«í¼ ë¶„ì„ (TODO: ì‹¤ì œ êµ¬í˜„ í•„ìš”)"""
    try:
        logger.info(f"ìœ íŠœë¸Œ ë¶„ì„ ì‹œì‘: {youtube_url}")
        # TODO: ìœ íŠœë¸Œ API ì—°ë™ ë° ë¶„ì„ êµ¬í˜„
        # í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        return {
            "url": youtube_url,
            "analyzed_videos": 0,
            "analysis": {
                "youtube": {
                    "content_style": "íŠœí† ë¦¬ì–¼ ì¤‘ì‹¬",
                    "title_pattern": "ìˆ«ì í™œìš©, ì§ˆë¬¸í˜•",
                    "description_style": "ìƒì„¸í•˜ê³  êµ¬ì¡°ì ",
                    "thumbnail_style": "í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´, ë°ì€ ë°°ê²½"
                }
            }
        }
    except Exception as e:
        logger.error(f"ìœ íŠœë¸Œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None


async def multi_platform_analysis_background(
    user_id: int,
    blog_url: Optional[str],
    instagram_url: Optional[str],
    youtube_url: Optional[str],
    max_posts: int
):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë©€í‹° í”Œë«í¼ ë¶„ì„ ìˆ˜í–‰
    """
    logger.info(f"ğŸš€ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘ - ì‚¬ìš©ì ID: {user_id}")

    # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ìš© ìƒˆ DB ì„¸ì…˜ ìƒì„±
    try:
        db = SessionLocal()
        logger.info("âœ… DB ì„¸ì…˜ ìƒì„± ì„±ê³µ")
    except Exception as e:
        logger.error(f"âŒ DB ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info(f"ì‚¬ìš©ì {user_id}ì˜ ë©€í‹° í”Œë«í¼ ë¶„ì„ ì‹œì‘")

        # ì‚¬ìš©ì ì¡°íšŒ
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            logger.error(f"ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_id}")
            return

        # BrandAnalysis ë ˆì½”ë“œ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        brand_analysis = db.query(BrandAnalysis).filter(BrandAnalysis.user_id == user_id).first()
        if not brand_analysis:
            brand_analysis = BrandAnalysis(user_id=user_id)
            db.add(brand_analysis)

        # ë¶„ì„í•  í”Œë«í¼ í™•ì¸
        platforms_to_analyze = []
        if blog_url:
            platforms_to_analyze.append(("blog", blog_url))
        if instagram_url:
            platforms_to_analyze.append(("instagram", instagram_url))
        if youtube_url:
            platforms_to_analyze.append(("youtube", youtube_url))

        if not platforms_to_analyze:
            logger.error("ë¶„ì„í•  í”Œë«í¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        for platform, _ in platforms_to_analyze:
            if platform == "blog":
                brand_analysis.blog_analysis_status = "analyzing"
                brand_analysis.blog_url = blog_url
            elif platform == "instagram":
                brand_analysis.instagram_analysis_status = "analyzing"
                brand_analysis.instagram_url = instagram_url
            elif platform == "youtube":
                brand_analysis.youtube_analysis_status = "analyzing"
                brand_analysis.youtube_url = youtube_url
        db.commit()

        # ë³‘ë ¬ë¡œ í”Œë«í¼ ë¶„ì„ ì‹¤í–‰
        tasks = []
        if blog_url:
            tasks.append(analyze_blog_platform(blog_url, max_posts))
        if instagram_url:
            tasks.append(analyze_instagram_platform(instagram_url, max_posts))
        if youtube_url:
            tasks.append(analyze_youtube_platform(youtube_url, max_posts))

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ì²˜ë¦¬
        overall_data = {
            "brand_name": None,
            "business_type": None,
            "brand_tone": None,
            "brand_values": None,
            "target_audience": None,
            "brand_personality": None,
            "key_themes": None,
            "emotional_tone": None
        }

        for i, (platform, url) in enumerate(platforms_to_analyze):
            result = results[i]

            if isinstance(result, Exception) or result is None:
                # ë¶„ì„ ì‹¤íŒ¨
                if platform == "blog":
                    brand_analysis.blog_analysis_status = "failed"
                elif platform == "instagram":
                    brand_analysis.instagram_analysis_status = "failed"
                elif platform == "youtube":
                    brand_analysis.youtube_analysis_status = "failed"
                continue

            # í”Œë«í¼ë³„ ë°ì´í„° ì €ì¥
            if platform == "blog" and result.get("analysis"):
                analysis = result["analysis"]
                overall = analysis.get("overall", {})
                blog = analysis.get("blog", {})

                # Overall ë°ì´í„° (ì²« ë²ˆì§¸ í”Œë«í¼ ë°ì´í„° ì‚¬ìš©)
                if not overall_data["brand_tone"]:
                    overall_data["brand_name"] = overall.get("brand_name")
                    overall_data["business_type"] = overall.get("business_type")
                    overall_data["brand_tone"] = overall.get("brand_tone")
                    overall_data["brand_values"] = overall.get("brand_values")
                    overall_data["target_audience"] = overall.get("target_audience")
                    overall_data["brand_personality"] = overall.get("brand_personality")
                    overall_data["key_themes"] = overall.get("key_themes")
                    overall_data["emotional_tone"] = overall.get("emotional_tone")

                # Blog ë°ì´í„°
                brand_analysis.blog_writing_style = blog.get("writing_style")
                brand_analysis.blog_content_structure = blog.get("content_structure")
                brand_analysis.blog_call_to_action = blog.get("call_to_action")
                brand_analysis.blog_keyword_usage = blog.get("keyword_usage")
                brand_analysis.blog_analyzed_posts = result.get("analyzed_posts", 0)
                brand_analysis.blog_analyzed_at = datetime.utcnow()
                brand_analysis.blog_analysis_status = "completed"

            elif platform == "instagram" and result.get("analysis"):
                instagram = result["analysis"].get("instagram", {})
                brand_analysis.instagram_caption_style = instagram.get("caption_style")
                brand_analysis.instagram_image_style = instagram.get("image_style")
                brand_analysis.instagram_hashtag_pattern = instagram.get("hashtag_pattern")
                brand_analysis.instagram_color_palette = instagram.get("color_palette")
                brand_analysis.instagram_analyzed_posts = result.get("analyzed_posts", 0)
                brand_analysis.instagram_analyzed_at = datetime.utcnow()
                brand_analysis.instagram_analysis_status = "completed"

            elif platform == "youtube" and result.get("analysis"):
                youtube = result["analysis"].get("youtube", {})
                brand_analysis.youtube_content_style = youtube.get("content_style")
                brand_analysis.youtube_title_pattern = youtube.get("title_pattern")
                brand_analysis.youtube_description_style = youtube.get("description_style")
                brand_analysis.youtube_thumbnail_style = youtube.get("thumbnail_style")
                brand_analysis.youtube_analyzed_videos = result.get("analyzed_videos", 0)
                brand_analysis.youtube_analyzed_at = datetime.utcnow()
                brand_analysis.youtube_analysis_status = "completed"

        # Overall ë°ì´í„° ì €ì¥
        if overall_data["brand_tone"]:
            brand_analysis.brand_name = overall_data["brand_name"]
            brand_analysis.business_type = overall_data["business_type"]
            brand_analysis.brand_tone = overall_data["brand_tone"]
            brand_analysis.brand_values = overall_data["brand_values"]
            brand_analysis.target_audience = overall_data["target_audience"]
            brand_analysis.brand_personality = overall_data["brand_personality"]
            brand_analysis.key_themes = overall_data["key_themes"]
            brand_analysis.emotional_tone = overall_data["emotional_tone"]

        db.commit()
        logger.info(f"ì‚¬ìš©ì {user_id}ì˜ ë©€í‹° í”Œë«í¼ ë¶„ì„ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"ë©€í‹° í”Œë«í¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        try:
            brand_analysis = db.query(BrandAnalysis).filter(BrandAnalysis.user_id == user_id).first()
            if brand_analysis:
                if blog_url:
                    brand_analysis.blog_analysis_status = "failed"
                if instagram_url:
                    brand_analysis.instagram_analysis_status = "failed"
                if youtube_url:
                    brand_analysis.youtube_analysis_status = "failed"
                db.commit()
        except:
            pass
    finally:
        # DB ì„¸ì…˜ ë‹«ê¸°
        db.close()


@router.post("/multi-platform", response_model=AnalysisResponse)
async def analyze_multi_platform(
    request: MultiPlatformAnalysisRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ë©€í‹° í”Œë«í¼ ë¸Œëœë“œ ë¶„ì„ ì‹œì‘ (ë¹„ë™ê¸°)

    - ë¸”ë¡œê·¸, ì¸ìŠ¤íƒ€ê·¸ë¨, ìœ íŠœë¸Œ ì¤‘ ì œê³µëœ í”Œë«í¼ë§Œ ë¶„ì„
    - ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ë˜ë©°, ì™„ë£Œ í›„ DBì— ì €ì¥
    """
    try:
        # ìµœì†Œ 1ê°œ í”Œë«í¼ URL í•„ìš”
        if not any([request.blog_url, request.instagram_url, request.youtube_url]):
            raise HTTPException(
                status_code=400,
                detail="ìµœì†Œ 1ê°œ ì´ìƒì˜ í”Œë«í¼ URLì´ í•„ìš”í•©ë‹ˆë‹¤."
            )

        # BrandAnalysis ë ˆì½”ë“œ í™•ì¸
        brand_analysis = db.query(BrandAnalysis).filter(BrandAnalysis.user_id == current_user.id).first()

        # ì´ë¯¸ ë¶„ì„ ì¤‘ì¸ì§€ í™•ì¸
        if brand_analysis:
            analyzing = (
                (request.blog_url and brand_analysis.blog_analysis_status == "analyzing") or
                (request.instagram_url and brand_analysis.instagram_analysis_status == "analyzing") or
                (request.youtube_url and brand_analysis.youtube_analysis_status == "analyzing")
            )
            if analyzing:
                raise HTTPException(
                    status_code=400,
                    detail="ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                )

        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ë¶„ì„ ì‹œì‘
        background_tasks.add_task(
            multi_platform_analysis_background,
            current_user.id,
            request.blog_url,
            request.instagram_url,
            request.youtube_url,
            request.max_posts
        )

        platforms = []
        if request.blog_url:
            platforms.append("ë¸”ë¡œê·¸")
        if request.instagram_url:
            platforms.append("ì¸ìŠ¤íƒ€ê·¸ë¨")
        if request.youtube_url:
            platforms.append("ìœ íŠœë¸Œ")

        return AnalysisResponse(
            status="started",
            message=f"{', '.join(platforms)} ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë©€í‹° í”Œë«í¼ ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")


@router.get("/status", response_model=Dict[str, Any])
async def get_analysis_status(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ë¸Œëœë“œ ë¶„ì„ ìƒíƒœ ì¡°íšŒ

    Returns:
        ê° í”Œë«í¼ë³„ ë¶„ì„ ìƒíƒœ ë° ê²°ê³¼
    """
    brand_analysis = db.query(BrandAnalysis).filter(BrandAnalysis.user_id == current_user.id).first()

    if not brand_analysis:
        return {
            "overall": None,
            "blog": {"status": "pending", "url": None, "analyzed_at": None},
            "instagram": {"status": "pending", "url": None, "analyzed_at": None},
            "youtube": {"status": "pending", "url": None, "analyzed_at": None}
        }

    # Overall ë°ì´í„°
    overall = None
    if brand_analysis.brand_tone:
        overall = {
            "brand_name": brand_analysis.brand_name,
            "business_type": brand_analysis.business_type,
            "brand_tone": brand_analysis.brand_tone,
            "brand_values": brand_analysis.brand_values,
            "target_audience": brand_analysis.target_audience,
            "brand_personality": brand_analysis.brand_personality,
            "key_themes": brand_analysis.key_themes,
            "emotional_tone": brand_analysis.emotional_tone
        }

    # í”Œë«í¼ë³„ ìƒíƒœ
    blog_data = {
        "status": brand_analysis.blog_analysis_status,
        "url": brand_analysis.blog_url,
        "analyzed_at": brand_analysis.blog_analyzed_at.isoformat() if brand_analysis.blog_analyzed_at else None
    }
    if brand_analysis.blog_analysis_status == "completed":
        blog_data["analysis"] = {
            "writing_style": brand_analysis.blog_writing_style,
            "content_structure": brand_analysis.blog_content_structure,
            "call_to_action": brand_analysis.blog_call_to_action,
            "keyword_usage": brand_analysis.blog_keyword_usage
        }

    instagram_data = {
        "status": brand_analysis.instagram_analysis_status,
        "url": brand_analysis.instagram_url,
        "analyzed_at": brand_analysis.instagram_analyzed_at.isoformat() if brand_analysis.instagram_analyzed_at else None
    }
    if brand_analysis.instagram_analysis_status == "completed":
        instagram_data["analysis"] = {
            "caption_style": brand_analysis.instagram_caption_style,
            "image_style": brand_analysis.instagram_image_style,
            "hashtag_pattern": brand_analysis.instagram_hashtag_pattern,
            "color_palette": brand_analysis.instagram_color_palette
        }

    youtube_data = {
        "status": brand_analysis.youtube_analysis_status,
        "url": brand_analysis.youtube_url,
        "analyzed_at": brand_analysis.youtube_analyzed_at.isoformat() if brand_analysis.youtube_analyzed_at else None
    }
    if brand_analysis.youtube_analysis_status == "completed":
        youtube_data["analysis"] = {
            "content_style": brand_analysis.youtube_content_style,
            "title_pattern": brand_analysis.youtube_title_pattern,
            "description_style": brand_analysis.youtube_description_style,
            "thumbnail_style": brand_analysis.youtube_thumbnail_style
        }

    return {
        "overall": overall,
        "blog": blog_data,
        "instagram": instagram_data,
        "youtube": youtube_data
    }


async def manual_content_analysis_background(
    user_id: int,
    text_samples: Optional[List[str]],
    image_samples: Optional[List[str]],  # ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    video_samples: Optional[List[str]],  # ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    db: Session
):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆ˜ë™ ì½˜í…ì¸  ë¶„ì„ ìˆ˜í–‰
    """
    try:
        logger.info(f"ì‚¬ìš©ì {user_id}ì˜ ìˆ˜ë™ ì½˜í…ì¸  ë¶„ì„ ì‹œì‘")

        # ì‚¬ìš©ì ì¡°íšŒ
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            logger.error(f"ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_id}")
            return

        # BrandAnalysis ë ˆì½”ë“œ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        brand_analysis = db.query(BrandAnalysis).filter(BrandAnalysis.user_id == user_id).first()
        if not brand_analysis:
            brand_analysis = BrandAnalysis(user_id=user_id)
            db.add(brand_analysis)
            db.commit()

        # Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ìƒ˜í”Œ ë¶„ì„
        analyzer = BrandAnalyzerService()

        # í…ìŠ¤íŠ¸ ìƒ˜í”Œ ë¶„ì„
        if text_samples and len(text_samples) >= 2:
            # í…ìŠ¤íŠ¸ë¥¼ í¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
            posts = [{"title": f"ìƒ˜í”Œ {i+1}", "content": sample, "date": "N/A"}
                     for i, sample in enumerate(text_samples)]

            business_info = {
                'brand_name': user.brand_name,
                'business_type': user.business_type,
                'business_description': user.business_description
            }

            text_analysis = await analyzer.analyze_brand(posts, business_info)

            # Overall ë°ì´í„° ì €ì¥
            overall = text_analysis.get('overall', {})
            brand_analysis.brand_tone = overall.get('brand_tone')
            brand_analysis.brand_values = overall.get('brand_values')
            brand_analysis.target_audience = overall.get('target_audience')
            brand_analysis.brand_personality = overall.get('brand_personality')
            brand_analysis.key_themes = overall.get('key_themes')
            brand_analysis.emotional_tone = overall.get('emotional_tone')

            # Blog ë°ì´í„° ì €ì¥ (ìˆ˜ë™ ì…ë ¥ì˜ ê²½ìš° blog í•„ë“œ í™œìš©)
            blog = text_analysis.get('blog', {})
            brand_analysis.blog_writing_style = blog.get('writing_style')
            brand_analysis.blog_content_structure = blog.get('content_structure')
            brand_analysis.blog_call_to_action = blog.get('call_to_action')
            brand_analysis.blog_keyword_usage = blog.get('keyword_usage')
            brand_analysis.blog_analyzed_posts = len(text_samples)
            brand_analysis.blog_analyzed_at = datetime.utcnow()
            brand_analysis.blog_analysis_status = "completed"

        # ì´ë¯¸ì§€ ìƒ˜í”Œ ë¶„ì„ (AI ë³´ì™„ ë¶„ì„)
        if image_samples and len(image_samples) >= 2:
            # TODO: ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ë¶„ì„ êµ¬í˜„
            # í˜„ì¬ëŠ” ê¸°ë³¸ê°’ ì„¤ì •
            brand_analysis.instagram_caption_style = "ìˆ˜ë™ ì…ë ¥ ê¸°ë°˜"
            brand_analysis.instagram_image_style = f"{len(image_samples)}ê°œ ìƒ˜í”Œ ê¸°ë°˜ ë¶„ì„"
            brand_analysis.instagram_hashtag_pattern = "ì¼ë°˜ì ì¸ íŒ¨í„´"
            brand_analysis.instagram_color_palette = ["#000000", "#FFFFFF"]
            brand_analysis.instagram_analyzed_posts = len(image_samples)
            brand_analysis.instagram_analyzed_at = datetime.utcnow()
            brand_analysis.instagram_analysis_status = "completed"

        # ì˜ìƒ ìƒ˜í”Œ ë¶„ì„ (AI ë³´ì™„ ë¶„ì„)
        if video_samples and len(video_samples) >= 2:
            # TODO: ì˜ìƒ ìŠ¤íƒ€ì¼ ë¶„ì„ êµ¬í˜„
            # í˜„ì¬ëŠ” ê¸°ë³¸ê°’ ì„¤ì •
            brand_analysis.youtube_content_style = "ìˆ˜ë™ ì…ë ¥ ê¸°ë°˜"
            brand_analysis.youtube_title_pattern = f"{len(video_samples)}ê°œ ìƒ˜í”Œ ê¸°ë°˜ ë¶„ì„"
            brand_analysis.youtube_description_style = "ì¼ë°˜ì ì¸ ìŠ¤íƒ€ì¼"
            brand_analysis.youtube_thumbnail_style = "ê¸°ë³¸ ìŠ¤íƒ€ì¼"
            brand_analysis.youtube_analyzed_videos = len(video_samples)
            brand_analysis.youtube_analyzed_at = datetime.utcnow()
            brand_analysis.youtube_analysis_status = "completed"

        # AI ë³´ì™„ ë¶„ì„: ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° Geminië¡œ ë³´ì™„
        if not brand_analysis.brand_tone:
            # Overall ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° AIë¡œ ìƒì„±
            logger.info("Overall ë°ì´í„° ë¶€ì¡± - AI ë³´ì™„ ë¶„ì„ ìˆ˜í–‰")

            # ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ AI ë³´ì™„
            supplemental_prompt = f"""
ë‹¤ìŒ ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¸Œëœë“œ íŠ¹ì„±ì„ ì¶”ë¡ í•´ì£¼ì„¸ìš”:

- ë¸Œëœë“œëª…: {user.brand_name}
- ì—…ì¢…: {user.business_type}
- ì„¤ëª…: {user.business_description}

ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
  "brand_tone": "ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆ",
  "brand_values": ["ê°€ì¹˜1", "ê°€ì¹˜2"],
  "target_audience": "íƒ€ê²Ÿ ê³ ê°ì¸µ",
  "brand_personality": "ë¸Œëœë“œ ì„±ê²© ì„¤ëª…",
  "key_themes": ["ì£¼ì œ1", "ì£¼ì œ2"],
  "emotional_tone": "ê°ì •ì  í†¤"
}}
"""
            try:
                import google.generativeai as genai
                import json
                import os

                api_key = os.getenv("GEMINI_API_KEY")
                if api_key:
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel('gemini-2.0-flash-exp')
                    response = model.generate_content(supplemental_prompt)
                    response_text = response.text.strip()

                    # JSON íŒŒì‹±
                    if response_text.startswith('```json'):
                        response_text = response_text.replace('```json', '').replace('```', '').strip()

                    supplemental_data = json.loads(response_text)

                    brand_analysis.brand_tone = supplemental_data.get('brand_tone')
                    brand_analysis.brand_values = supplemental_data.get('brand_values')
                    brand_analysis.target_audience = supplemental_data.get('target_audience')
                    brand_analysis.brand_personality = supplemental_data.get('brand_personality')
                    brand_analysis.key_themes = supplemental_data.get('key_themes')
                    brand_analysis.emotional_tone = supplemental_data.get('emotional_tone')

                    logger.info("AI ë³´ì™„ ë¶„ì„ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"AI ë³´ì™„ ë¶„ì„ ì‹¤íŒ¨: {e}")

        db.commit()
        logger.info(f"ì‚¬ìš©ì {user_id}ì˜ ìˆ˜ë™ ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"ìˆ˜ë™ ì½˜í…ì¸  ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")


@router.post("/manual", response_model=AnalysisResponse)
async def analyze_manual_content(
    background_tasks: BackgroundTasks,
    text_samples: Optional[str] = Form(None),  # JSON ë¬¸ìì—´ë¡œ ë°›ìŒ
    image_files: Optional[List[UploadFile]] = File(None),
    video_files: Optional[List[UploadFile]] = File(None),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ìˆ˜ë™ ì½˜í…ì¸  ì—…ë¡œë“œ ë¶„ì„ ì‹œì‘ (ë¹„ë™ê¸°)

    - í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜ìƒ ìƒ˜í”Œ ì¤‘ ìµœì†Œ 1ê°œ íƒ€ì…ì—ì„œ 2ê°œ ì´ìƒ ì œê³µ í•„ìš”
    - ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ë˜ë©°, ì™„ë£Œ í›„ DBì— ì €ì¥
    - ìƒ˜í”Œì´ ë¶€ì¡±í•œ ê²½ìš° AI ë³´ì™„ ë¶„ì„ ìˆ˜í–‰
    """
    try:
        import json

        # í…ìŠ¤íŠ¸ ìƒ˜í”Œ íŒŒì‹±
        text_list = None
        if text_samples:
            try:
                text_list = json.loads(text_samples)
            except:
                text_list = [text_samples]

        # ìœ íš¨ì„± ê²€ì‚¬
        has_valid_text = text_list and len(text_list) >= 2
        has_valid_images = image_files and len(image_files) >= 2
        has_valid_videos = video_files and len(video_files) >= 2

        if not (has_valid_text or has_valid_images or has_valid_videos):
            raise HTTPException(
                status_code=400,
                detail="ìµœì†Œ 1ê°œ ì½˜í…ì¸  íƒ€ì…ì—ì„œ 2ê°œ ì´ìƒì˜ ìƒ˜í”Œì´ í•„ìš”í•©ë‹ˆë‹¤."
            )

        # íŒŒì¼ ì €ì¥ (TODO: ì‹¤ì œ ì €ì¥ ë¡œì§ êµ¬í˜„)
        image_paths = []
        video_paths = []

        if image_files:
            for img in image_files:
                # TODO: ì‹¤ì œ íŒŒì¼ ì €ì¥ ë¡œì§
                image_paths.append(f"/tmp/{img.filename}")

        if video_files:
            for vid in video_files:
                # TODO: ì‹¤ì œ íŒŒì¼ ì €ì¥ ë¡œì§
                video_paths.append(f"/tmp/{vid.filename}")

        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ë¶„ì„ ì‹œì‘
        background_tasks.add_task(
            manual_content_analysis_background,
            current_user.id,
            text_list,
            image_paths if image_paths else None,
            video_paths if video_paths else None,
            db
        )

        content_types = []
        if has_valid_text:
            content_types.append("í…ìŠ¤íŠ¸")
        if has_valid_images:
            content_types.append("ì´ë¯¸ì§€")
        if has_valid_videos:
            content_types.append("ì˜ìƒ")

        return AnalysisResponse(
            status="started",
            message=f"{', '.join(content_types)} ìƒ˜í”Œ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìˆ˜ë™ ì½˜í…ì¸  ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
