"""
AI Agentic ì¹´ë“œë‰´ìŠ¤ ìƒì„± ì‹œìŠ¤í…œ
ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°: ì •ë³´ í™•ì¥ â†’ ë¶„ì„ â†’ ê¸°íš â†’ ë””ìì¸ â†’ í’ˆì§ˆê²€ì¦

Vertex AI API ì‚¬ìš© (Google Cloud Platform)
"""

import os
import json
import re
from typing import List, Dict, Optional, Tuple
import httpx

# Vertex AI ì„í¬íŠ¸
import vertexai
from vertexai.generative_models import GenerativeModel, Part, Tool
from google.cloud import aiplatform

# Vertex AI ì´ˆê¸°í™” í•¨ìˆ˜
def init_vertex_ai():
    """Vertex AI ì´ˆê¸°í™” - í”„ë¡œì íŠ¸ ë° ì¸ì¦ ì„¤ì •"""
    project_id = os.getenv("GOOGLE_CLOUD_PROJECT", "bubbly-solution-480805-b5")
    location = "us-central1"  # Gemini ëª¨ë¸ ì§€ì› ë¦¬ì „

    # ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if credentials_path and os.path.exists(credentials_path):
        print(f"ğŸ”‘ [Vertex AI] ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦: {credentials_path}")
    else:
        print(f"âš ï¸ [Vertex AI] GOOGLE_APPLICATION_CREDENTIALS ê²½ë¡œ í™•ì¸ í•„ìš”")

    try:
        vertexai.init(project=project_id, location=location)
        print(f"âœ… [Vertex AI] ì´ˆê¸°í™” ì™„ë£Œ - í”„ë¡œì íŠ¸: {project_id}, ë¦¬ì „: {location}")
        return True
    except Exception as e:
        print(f"âŒ [Vertex AI] ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# ì•± ì‹œì‘ ì‹œ Vertex AI ì´ˆê¸°í™”
_vertex_ai_initialized = False

# í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from .prompts import (
    get_content_enricher_prompt,
    get_orchestrator_prompt,
    get_content_planner_prompt,
    get_visual_designer_prompt,
    get_quality_assurance_prompt,
    TONE_MAPPING,
    STYLE_GUIDELINES,
    PAGE_STRUCTURE_GUIDE,
)


# ==================== í°íŠ¸ ì„¤ì • ====================

FONT_PAIRS = {
    "pretendard": {
        "korean": "Pretendard",
        "english": "Inter",
        "style": "modern",
        "description": "í˜„ëŒ€ì ì´ê³  ê¹”ë”í•œ ëŠë‚Œ"
    },
    "noto": {
        "korean": "Noto Sans KR",
        "english": "Noto Sans",
        "style": "neutral",
        "description": "ì¤‘ë¦½ì ì´ê³  ê°€ë…ì„± ì¢‹ì€ ëŠë‚Œ"
    },
    "spoqa": {
        "korean": "Spoqa Han Sans",
        "english": "Roboto",
        "style": "friendly",
        "description": "ì¹œê·¼í•˜ê³  ë¶€ë“œëŸ¬ìš´ ëŠë‚Œ"
    }
}


# ==================== Agent 0: Content Enricher (ì •ë³´ í™•ì¥ + ì›¹ ê²€ìƒ‰) ====================

class ContentEnricherAgent:
    """ì‚¬ìš©ìì˜ ê°„ë‹¨í•œ ì…ë ¥ì„ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì‹¤ì œ ì •ë³´ë¡œ í™•ì¥í•˜ëŠ” ì—ì´ì „íŠ¸"""

    @staticmethod
    def _ensure_vertex_ai():
        """Vertex AI ì´ˆê¸°í™” í™•ì¸"""
        global _vertex_ai_initialized
        if not _vertex_ai_initialized:
            _vertex_ai_initialized = init_vertex_ai()
        return _vertex_ai_initialized

    @staticmethod
    async def _search_web_info(query: str) -> str:
        """
        Google Searchë¥¼ í†µí•´ ì£¼ì œì— ëŒ€í•œ ì‹¤ì œ ì •ë³´ë¥¼ ê²€ìƒ‰
        Vertex AI Gemini + Google Search Grounding ì‚¬ìš©
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âš ï¸ [Web Search] Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨")
                return ""

            # Vertex AI Gemini ëª¨ë¸ (Google Search Grounding ì§€ì›)
            from vertexai.generative_models import GenerativeModel, Tool, grounding

            # Google Search ë„êµ¬ ì„¤ì •
            google_search_tool = Tool.from_google_search_retrieval(
                grounding.GoogleSearchRetrieval()
            )

            search_model = GenerativeModel(
                "gemini-2.0-flash-001",
                tools=[google_search_tool]
            )

            search_prompt = f"""ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”.
ì£¼ì œ: {query}

ê²€ìƒ‰í•´ì„œ ì°¾ì•„ì•¼ í•  ì •ë³´:
1. ì •í™•í•œ ë‚ ì§œ, ì‹œê°„, ì¥ì†Œ
2. ê´€ë ¨ëœ ì£¼ìš” ì¸ë¬¼/ê¸°ê´€
3. êµ¬ì²´ì ì¸ ìˆ«ìë‚˜ í†µê³„
4. ì£¼ìš” ì‚¬ê±´ì˜ ê²½ê³¼ë‚˜ ê³¼ì •
5. ì˜ë¯¸ì™€ ì¤‘ìš”ì„±

ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ì •ë³´ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.
ë§Œì•½ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ë‹¤ë©´ "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"ì´ë¼ê³  ë‹µí•˜ì„¸ìš”."""

            response = search_model.generate_content(search_prompt)
            search_result = response.text.strip()

            print(f"ğŸ” [Web Search] ê²€ìƒ‰ ì™„ë£Œ: {query[:30]}...")
            print(f"   ğŸ“„ ê²°ê³¼ ê¸¸ì´: {len(search_result)}ì")

            return search_result

        except Exception as e:
            print(f"âš ï¸ [Web Search] ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return ""

    @staticmethod
    async def enrich_content(user_input: str, purpose: str, user_context: Dict = None) -> Dict:
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ê³  ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì‹¤ì œ ì •ë³´ë¡œ í™•ì¥

        Returns:
            {
                "original_input": "ì›ë³¸ ì…ë ¥",
                "enriched_content": "í™•ì¥ëœ ì½˜í…ì¸ ",
                "added_elements": ["ê³„ì ˆê°", "êµ¬ì²´ì  ì˜ˆì‹œ", ...],
                "context_suggestions": ["ì¶”ê°€ ë§¥ë½ ì •ë³´"],
                "recommended_page_count": 3-5,
                "researched_facts": ["ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ì‚¬ì‹¤ë“¤"]
            }
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨!")
                return ContentEnricherAgent._get_fallback_enrichment(user_input, purpose)

            # Step 1: ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ ì •ë³´ ìˆ˜ì§‘
            print(f"ğŸŒ [Content Enricher] ì›¹ ê²€ìƒ‰ ì‹œì‘: {user_input}")
            web_info = await ContentEnricherAgent._search_web_info(user_input)

            # Step 2: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½˜í…ì¸  ìƒì„±
            model = GenerativeModel("gemini-2.0-flash-001")

            # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì •ë³´ êµ¬ì„±
            user_context_info = ""
            if user_context:
                context_parts = []
                if user_context.get('brand_name'):
                    context_parts.append(f"- ë¸Œëœë“œëª…: {user_context['brand_name']}")
                if user_context.get('business_type'):
                    business_type_map = {
                        'startup': 'ìŠ¤íƒ€íŠ¸ì—…/ì‹ ìƒ ë¸Œëœë“œ',
                        'small_business': 'ì†Œê·œëª¨ ë¹„ì¦ˆë‹ˆìŠ¤',
                        'personal_brand': 'ê°œì¸ ë¸Œëœë“œ/ì¸í”Œë£¨ì–¸ì„œ',
                        'corporate': 'ê¸°ì—…/ëŒ€ê¸°ì—…',
                        'nonprofit': 'ë¹„ì˜ë¦¬ ë‹¨ì²´',
                        'freelancer': 'í”„ë¦¬ëœì„œ',
                        'ecommerce': 'ì´ì»¤ë¨¸ìŠ¤/ì˜¨ë¼ì¸ ì‡¼í•‘ëª°',
                        'local_business': 'ì§€ì—­ ë¹„ì¦ˆë‹ˆìŠ¤'
                    }
                    context_parts.append(f"- ë¹„ì¦ˆë‹ˆìŠ¤ ìœ í˜•: {business_type_map.get(user_context['business_type'], user_context['business_type'])}")
                if user_context.get('business_description'):
                    context_parts.append(f"- ë¹„ì¦ˆë‹ˆìŠ¤ ì„¤ëª…: {user_context['business_description']}")
                if user_context.get('target_audience'):
                    target = user_context['target_audience']
                    if isinstance(target, dict):
                        target_str = ", ".join([f"{k}: {v}" for k, v in target.items()])
                    else:
                        target_str = str(target)
                    context_parts.append(f"- íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤: {target_str}")
                if user_context.get('brand_tone'):
                    context_parts.append(f"- ë¸Œëœë“œ í†¤: {user_context['brand_tone']}")
                if user_context.get('brand_personality'):
                    context_parts.append(f"- ë¸Œëœë“œ ì„±ê²©: {user_context['brand_personality']}")
                if user_context.get('key_themes'):
                    context_parts.append(f"- í•µì‹¬ í…Œë§ˆ: {', '.join(user_context['key_themes'])}")
                if user_context.get('text_tone'):
                    tone_map = {
                        'casual': 'ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ',
                        'professional': 'ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ”',
                        'friendly': 'ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ',
                        'formal': 'ê²©ì‹ ìˆê³  ì •ì¤‘í•œ'
                    }
                    context_parts.append(f"- í…ìŠ¤íŠ¸ í†¤: {tone_map.get(user_context['text_tone'], user_context['text_tone'])}")

                if context_parts:
                    user_context_info = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¢ ë¸Œëœë“œ/ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ (ì˜¨ë³´ë”© ë°ì´í„°)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{chr(10).join(context_parts)}
**ì¤‘ìš”**: ìœ„ ë¸Œëœë“œ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ ë¸Œëœë“œ ì •ì²´ì„±ì— ë§ëŠ” ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            web_search_section = ""
            if web_info and "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ" not in web_info:
                web_search_section = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ì‹¤ì œ ì •ë³´
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{web_info}
**ì¤‘ìš”**: ìœ„ ê²€ìƒ‰ ê²°ê³¼ì˜ êµ¬ì²´ì ì¸ ì‚¬ì‹¤(ë‚ ì§œ, ì¥ì†Œ, ìˆ«ì, ê³¼ì • ë“±)ì„ ë°˜ë“œì‹œ ì½˜í…ì¸ ì— í¬í•¨í•˜ì„¸ìš”!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

            # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš© + ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
            base_prompt = get_content_enricher_prompt(
                user_input=user_input,
                purpose=purpose,
                user_context=user_context_info
            )

            # ì›¹ ê²€ìƒ‰ ì„¹ì…˜ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            if web_search_section:
                enhanced_prompt = base_prompt.replace(
                    "## ë‹¹ì‹ ì˜ ì—­í• ",
                    f"{web_search_section}\n## ë‹¹ì‹ ì˜ ì—­í• "
                )
            else:
                enhanced_prompt = base_prompt

            response = model.generate_content(enhanced_prompt)
            response_text = response.text.strip()

            print("ğŸ” Raw Enrichment Response:\n", response_text)

            json_match = re.search(r'\{[\s\S]*\}', response_text)

            if json_match:
                enrichment = json.loads(json_match.group(0))
                # ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
                if web_info and "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ" not in web_info:
                    enrichment['web_search_used'] = True
                    enrichment['researched_info'] = web_info[:500]  # ìš”ì•½ë³¸ ì €ì¥
                else:
                    enrichment['web_search_used'] = False

                print(f"âœ… [Content Enricher] ì •ë³´ í™•ì¥ ì™„ë£Œ")
                print(f"   ğŸ“ ì›ë³¸: {user_input[:50]}...")
                print(f"   âœ¨ í™•ì¥: {enrichment.get('enriched_content', '')[:80]}...")
                print(f"   ğŸ“Š ì¶”ì²œ í˜ì´ì§€: {enrichment.get('recommended_page_count', 3)}ì¥")
                print(f"   ğŸŒ ì›¹ ê²€ìƒ‰ ì‚¬ìš©: {enrichment.get('web_search_used', False)}")
                return enrichment

            return ContentEnricherAgent._get_fallback_enrichment(user_input, purpose)

        except Exception as e:
            print(f"âš ï¸ [Content Enricher] í™•ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return ContentEnricherAgent._get_fallback_enrichment(user_input, purpose)

    @staticmethod
    def _get_fallback_enrichment(user_input: str, purpose: str = "info") -> Dict:
        """
        í´ë°± í™•ì¥ ê²°ê³¼ - ëª©ì (purpose)ì— ë§ëŠ” í™ë³´/ì´ë²¤íŠ¸/ì •ë³´ ì½˜í…ì¸  ìƒì„±

        purpose ì¢…ë¥˜:
        - promotion: ì œí’ˆ/ì„œë¹„ìŠ¤ í™ë³´
        - event: ì´ë²¤íŠ¸/í–‰ì‚¬ ì•ˆë‚´
        - menu: ë©”ë‰´/ê°€ê²© ì†Œê°œ
        - info: ì •ë³´ ì „ë‹¬
        """
        input_length = len(user_input)
        if input_length < 30:
            page_count = 3
        elif input_length < 80:
            page_count = 4
        else:
            page_count = 5

        # ëª©ì ë³„ ì½˜í…ì¸  í…œí”Œë¦¿
        if purpose == "promotion":
            # í™ë³´ìš© - ë§¤ë ¥ì ì¸ ë§ˆì¼€íŒ… ë¬¸êµ¬
            enriched = f"âœ¨ ìƒˆë¡­ê²Œ ì„ ë³´ì´ëŠ” íŠ¹ë³„í•œ ê¸°íšŒ! {user_input}ì„(ë¥¼) ì§€ê¸ˆ ë°”ë¡œ ë§Œë‚˜ë³´ì„¸ìš”. ë†“ì¹˜ë©´ í›„íšŒí•  íŠ¹ë³„í•œ í˜œíƒì´ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤."
            key_points = [
                "ì§€ê¸ˆì´ ë°”ë¡œ êµ¬ë§¤/ì°¸ì—¬ ì ê¸°",
                "í•œì • ê¸°ê°„ íŠ¹ë³„ í˜œíƒ",
                "ë‹¤ë¥¸ ê³³ì—ì„œ ì°¾ê¸° í˜ë“  íŠ¹ë³„í•¨"
            ]
            tone = "exciting"
        elif purpose == "event":
            # ì´ë²¤íŠ¸ìš© - ì°¸ì—¬ ìœ ë„
            enriched = f"ğŸ‰ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”! {user_input}! íŠ¹ë³„í•œ ìˆœê°„ì„ í•¨ê»˜ í•˜ì„¸ìš”. ë‹¤ì–‘í•œ í˜œíƒê³¼ ì¦ê±°ì›€ì´ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."
            key_points = [
                "ì´ë²¤íŠ¸ ì°¸ì—¬ ë°©ë²•",
                "íŠ¹ë³„ í˜œíƒ ë° ê²½í’ˆ",
                "ì°¸ì—¬ ê¸°ê°„ ë° ì¡°ê±´"
            ]
            tone = "exciting"
        elif purpose == "menu":
            # ë©”ë‰´ìš© - ë§›ìˆëŠ” ì„¤ëª…
            enriched = f"ğŸ½ï¸ ì…ë§›ì„ ì‚¬ë¡œì¡ëŠ” íŠ¹ë³„í•œ ë©”ë‰´! {user_input}. ì •ì„±ê» ì¤€ë¹„í•œ ë©”ë‰´ë¥¼ ë§Œë‚˜ë³´ì„¸ìš”."
            key_points = [
                "ì—„ì„ ëœ ì¬ë£Œë¡œ ë§Œë“  íŠ¹ë³„í•¨",
                "í•©ë¦¬ì ì¸ ê°€ê²©",
                "ì§€ê¸ˆ ë°”ë¡œ ì£¼ë¬¸í•˜ì„¸ìš”"
            ]
            tone = "friendly"
        else:
            # ì •ë³´ìš© - ìœ ìš©í•œ ì •ë³´ ì „ë‹¬
            enriched = f"ğŸ“Œ ì•Œì•„ë‘ë©´ ìœ ìš©í•œ ì •ë³´! {user_input}ì— ëŒ€í•´ í•µì‹¬ë§Œ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤."
            key_points = [
                "í•µì‹¬ í¬ì¸íŠ¸ ì •ë¦¬",
                "ì•Œì•„ë‘ë©´ ì¢‹ì€ íŒ",
                "ë” ì•Œì•„ë³´ê¸°"
            ]
            tone = "friendly"

        return {
            "original_input": user_input,
            "enriched_content": enriched,
            "key_points": key_points,
            "added_elements": ["ëª©ì ì— ë§ëŠ” í†¤", "í–‰ë™ ìœ ë„ ë¬¸êµ¬"],
            "tone_suggestion": tone,
            "recommended_page_count": page_count,
            "page_count_reason": f"ì…ë ¥ ê¸¸ì´({input_length}ì) ê¸°ë°˜ ìë™ ê²°ì •",
            "web_search_used": False,
            "purpose": purpose
        }


# ==================== Agent 1: Orchestrator (ì¡°ìœ¨ì) ====================

class OrchestratorAgent:
    """ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ìœ¨í•˜ëŠ” ë§ˆìŠ¤í„° ì—ì´ì „íŠ¸"""

    @staticmethod
    async def analyze_user_request(enriched_data: Dict, purpose: str) -> Dict:
        """
        í™•ì¥ëœ ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—… ê³„íš ìˆ˜ë¦½

        Args:
            enriched_data: ContentEnricherAgentì˜ ê²°ê³¼
            purpose: ì½˜í…ì¸  ëª©ì 

        Returns:
            {
                "content_type": "cardnews",
                "page_count": 3,
                "target_audience": "ì¼ë°˜ ëŒ€ì¤‘",
                "tone": "ì¹œê·¼í•œ",
                "key_message": "í•µì‹¬ ë©”ì‹œì§€",
                "requires_images": true,
                "style": "modern",
                "font_pair": "pretendard",
                "enriched_content": "í™•ì¥ëœ ì½˜í…ì¸ "
            }
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨!")
                return OrchestratorAgent._get_fallback_analysis(enriched_data, purpose)

            model = GenerativeModel("gemini-2.0-flash-001")

            enriched_content = enriched_data.get('enriched_content', enriched_data.get('original_input', ''))
            recommended_pages = enriched_data.get('recommended_page_count', 3)
            tone_suggestion = enriched_data.get('tone_suggestion', 'ì¹œê·¼í•œ')

            # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš©
            prompt = get_orchestrator_prompt(
                enriched_content=enriched_content,
                key_points=enriched_data.get('key_points', []),
                recommended_pages=recommended_pages,
                tone_suggestion=tone_suggestion,
                purpose=purpose
            )

            response = model.generate_content(prompt)
            response_text = response.text.strip()

            print("ğŸ” Raw Vertex AI Analysis Response:\n", response_text)

            json_match = re.search(r'\{[\s\S]*\}', response_text)

            if json_match:
                analysis = json.loads(json_match.group(0))
                # í™•ì¥ëœ ì½˜í…ì¸  ì¶”ê°€
                analysis['enriched_content'] = enriched_content
                analysis['key_points'] = enriched_data.get('key_points', [])

                print(f"âœ… [Orchestrator] ë¶„ì„ ì™„ë£Œ:")
                print(f"   ğŸ“„ í˜ì´ì§€: {analysis.get('page_count', 3)}ì¥")
                print(f"   ğŸ¨ ìŠ¤íƒ€ì¼: {analysis.get('style', 'modern')}")
                print(f"   ğŸ”¤ í°íŠ¸: {analysis.get('font_pair', 'pretendard')}")
                return analysis

            return OrchestratorAgent._get_fallback_analysis(enriched_data, purpose)

        except Exception as e:
            print(f"âš ï¸ [Orchestrator] ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return OrchestratorAgent._get_fallback_analysis(enriched_data, purpose)

    @staticmethod
    def _get_fallback_analysis(enriched_data: Dict, purpose: str) -> Dict:
        """í´ë°± ë¶„ì„ ê²°ê³¼ - purposeë¥¼ í¬í•¨í•˜ì—¬ í´ë°± ì½˜í…ì¸ ì—ì„œë„ ëª©ì ì— ë§ëŠ” ì½˜í…ì¸  ìƒì„±"""
        page_count = enriched_data.get('recommended_page_count', 3)
        enriched_content = enriched_data.get('enriched_content', enriched_data.get('original_input', ''))

        return {
            "content_type": "cardnews",
            "page_count": page_count,
            "page_count_reason": "ìë™ ê²°ì •",
            "target_audience": "ì¼ë°˜ ëŒ€ì¤‘",
            "tone": enriched_data.get('tone_suggestion', 'ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´'),
            "key_message": enriched_content[:50],
            "requires_images": True,
            "style": "modern",
            "font_pair": "pretendard",
            "font_reason": "ê¸°ë³¸ í°íŠ¸",
            "enriched_content": enriched_content,
            "key_points": enriched_data.get('key_points', []),
            "purpose": purpose  # í´ë°±ì—ì„œë„ purpose ì „ë‹¬
        }


# ==================== Agent 2: Content Planner (ì½˜í…ì¸  ê¸°íšì) ====================

class ContentPlannerAgent:
    """Wrtn AIë¥¼ í™œìš©í•˜ì—¬ í˜ì´ì§€ë³„ ì½˜í…ì¸ ë¥¼ ê¸°íší•˜ëŠ” ì—ì´ì „íŠ¸"""

    @staticmethod
    async def plan_cardnews_pages(user_input: str, analysis: Dict) -> List[Dict]:
        """
        Google Geminië¥¼ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ë³„ ì½˜í…ì¸  êµ¬ì„±

        Returns:
            [
                {
                    "page": 1,
                    "title": "í˜ì´ì§€ ì œëª©",
                    "content": "í˜ì´ì§€ ë‚´ìš©",
                    "visual_concept": "ë¹„ì£¼ì–¼ ì»¨ì…‰",
                    "layout": "title_center" | "split" | "full_image"
                }
            ]
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨!")
                return ContentPlannerAgent._get_fallback_content(user_input, analysis)

            print(f"âœ… Vertex AI í”„ë¡œì íŠ¸: {os.getenv('GOOGLE_CLOUD_PROJECT', 'bubbly-solution-480805-b5')}")
            model = GenerativeModel("gemini-2.0-flash-001")

            tone = analysis.get('tone', 'ì¹œê·¼í•œ')
            audience = analysis.get('target_audience', 'ì¼ë°˜ ëŒ€ì¤‘')
            page_count = analysis.get('page_count', 5)
            style = analysis.get('style', 'modern')
            enriched_content = analysis.get('enriched_content', user_input)
            key_points = analysis.get('key_points', [])

            # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš©
            prompt = get_content_planner_prompt(
                page_count=page_count,
                enriched_content=enriched_content,
                key_points=key_points,
                tone=tone,
                audience=audience,
                style=style
            )

            # Vertex AI API í˜¸ì¶œ
            response = model.generate_content(prompt)
            response_text = response.text.strip()

            print("ğŸ” Raw Vertex AI Response:\n", response_text)

            # JSONë§Œ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì¶œ
            start = response_text.find("[")
            end = response_text.rfind("]") + 1

            if start != -1 and end != -1:
                json_text = response_text[start:end]
                print("ğŸ” Extracted JSON:\n", json_text)

                try:
                    pages = json.loads(json_text)

                    # ìƒì„±ëœ í˜ì´ì§€ ê°œìˆ˜ í™•ì¸ ì¶œë ¥
                    print(f"âœ… {len(pages)}ê°œì˜ í˜ì´ì§€ ìƒì„± ì™„ë£Œ")
                    for p in pages:
                        print(f"ğŸ“„ {p.get('page')}. {p.get('title')}")

                    return pages

                except Exception as e:
                    print("âŒ JSON ë””ì½”ë”© ì‹¤íŒ¨:", e)
                    print("ğŸ” ë””ì½”ë”© ì‹¤íŒ¨ JSON ë‚´ìš©:\n", json_text)
                    return ContentPlannerAgent._get_fallback_content(user_input, analysis)

            else:
                print("âŒ JSON êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ ( '[' ë˜ëŠ” ']' ì—†ìŒ )")
                print("ğŸ” Raw Response:\n", response_text)
                return ContentPlannerAgent._get_fallback_content(user_input, analysis)

        except Exception as e:
            print(f"âš ï¸ [Content Planner] ê¸°íš ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return ContentPlannerAgent._get_fallback_content(user_input, analysis)

    @staticmethod
    def _get_fallback_content(user_input: str, analysis: Dict) -> List[Dict]:
        """
        í´ë°± ì½˜í…ì¸  - ëª©ì (purpose)ì— ë§ëŠ” í™ë³´/ì´ë²¤íŠ¸/ì •ë³´ ì½˜í…ì¸  ìƒì„±

        í™ë³´ìš©(promotion): ë§¤ë ¥ì ì¸ ë§ˆì¼€íŒ… ë¬¸êµ¬ë¡œ êµ¬ë§¤/ì°¸ì—¬ ìœ ë„
        ì´ë²¤íŠ¸ìš©(event): ì°¸ì—¬ë¥¼ ìœ ë„í•˜ëŠ” í¥ë¯¸ë¡œìš´ ë¬¸êµ¬
        ë©”ë‰´ìš©(menu): ë©”ë‰´/ìƒí’ˆ ì†Œê°œ
        ì •ë³´ìš©(info): ìœ ìš©í•œ ì •ë³´ ì „ë‹¬
        """
        page_count = analysis.get('page_count', 3)
        pages = []

        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        topic = analysis.get('enriched_content', user_input.strip())[:50]  # enriched_content í™œìš©
        key_points = analysis.get('key_points', [])
        purpose = analysis.get('purpose', 'info')

        # ëª©ì ë³„ ì½˜í…ì¸  í…œí”Œë¦¿
        if purpose == "promotion":
            # í™ë³´ìš© í…œí”Œë¦¿
            first_page = {
                "title": "NEW ARRIVAL",
                "subtitle": "ìƒˆë¡œìš´ ì‹œì‘ì„ ì•Œë¦¬ë‹¤",
                "hook": "âœ¨ íŠ¹ë³„í•œ ê¸°íšŒë¥¼ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”!",
                "visual_concept": "ì„¸ë ¨ë˜ê³  ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ì œí’ˆ í™ë³´ ì´ë¯¸ì§€, íŠ¸ë Œë””í•œ ëŠë‚Œ"
            }
            middle_templates = [
                {"title": "Special Point", "content": ["â€¢ í”„ë¦¬ë¯¸ì—„ í€„ë¦¬í‹°", "â€¢ í•©ë¦¬ì ì¸ ê°€ê²©", "â€¢ í•œì • ìˆ˜ëŸ‰"]},
                {"title": "Why Choose Us", "content": ["â€¢ ê²€ì¦ëœ í’ˆì§ˆ", "â€¢ ë¹ ë¥¸ ë°°ì†¡", "â€¢ íŠ¹ë³„ í˜œíƒ"]},
                {"title": "Limited Edition", "content": ["â€¢ ì´ë²ˆ ì‹œì¦Œ í•œì •", "â€¢ ì„ ì°©ìˆœ íŠ¹ê°€", "â€¢ ë†“ì¹˜ë©´ í›„íšŒ"]}
            ]
            last_page = {
                "title": "ì§€ê¸ˆ ë°”ë¡œ!",
                "content": ["ğŸ›’ êµ¬ë§¤í•˜ëŸ¬ ê°€ê¸°", "ğŸ’¬ ë¬¸ì˜í•˜ê¸°"],
                "cta": "ë†“ì¹˜ì§€ ë§ˆì„¸ìš”!"
            }
        elif purpose == "event":
            # ì´ë²¤íŠ¸ìš© í…œí”Œë¦¿
            first_page = {
                "title": "ğŸ‰ EVENT",
                "subtitle": "íŠ¹ë³„í•œ ì´ë²¤íŠ¸ê°€ ì‹œì‘ë©ë‹ˆë‹¤",
                "hook": "ì°¸ì—¬ë§Œ í•´ë„ ì„ ë¬¼ì´!",
                "visual_concept": "ì¶•ì œ ë¶„ìœ„ê¸°ì˜ ë°ê³  í™”ë ¤í•œ ì´ë²¤íŠ¸ ì´ë¯¸ì§€"
            }
            middle_templates = [
                {"title": "ì´ë²¤íŠ¸ í˜œíƒ", "content": ["â€¢ ì°¸ì—¬ì ì „ì› í˜œíƒ", "â€¢ ì¶”ì²¨ ê²½í’ˆ", "â€¢ íŠ¹ë³„ í• ì¸"]},
                {"title": "ì°¸ì—¬ ë°©ë²•", "content": ["â€¢ íŒ”ë¡œìš° & ì¢‹ì•„ìš”", "â€¢ ëŒ“ê¸€ ë‚¨ê¸°ê¸°", "â€¢ ì¹œêµ¬ íƒœê·¸"]},
                {"title": "ê²½í’ˆ ì•ˆë‚´", "content": ["â€¢ 1ë“±: íŠ¹ë³„ ìƒí’ˆ", "â€¢ 2ë“±: í• ì¸ ì¿ í°", "â€¢ ì°¸ê°€ìƒ: ì†Œì •ì˜ ì„ ë¬¼"]}
            ]
            last_page = {
                "title": "ì°¸ì—¬í•˜ê¸°",
                "content": ["â° ê¸°ê°„ í•œì •!", "ğŸ‘‰ ì§€ê¸ˆ ë°”ë¡œ ì°¸ì—¬í•˜ì„¸ìš”"],
                "cta": "ì´ë²¤íŠ¸ ì°¸ì—¬"
            }
        elif purpose == "menu":
            # ë©”ë‰´ìš© í…œí”Œë¦¿
            first_page = {
                "title": "MENU",
                "subtitle": "ì •ì„±ì„ ë‹´ì€ íŠ¹ë³„í•œ ë§›",
                "hook": "ğŸ½ï¸ ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë©”ë‰´",
                "visual_concept": "ë§›ìˆì–´ ë³´ì´ëŠ” ìŒì‹ ì‚¬ì§„, ê³ ê¸‰ìŠ¤ëŸ¬ìš´ í”Œë ˆì´íŒ…"
            }
            middle_templates = [
                {"title": "ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´", "content": ["â€¢ ì…°í”„ ì¶”ì²œ", "â€¢ ë² ìŠ¤íŠ¸ì…€ëŸ¬", "â€¢ ì‹ ë©”ë‰´"]},
                {"title": "íŠ¹ë³„í•œ ì¬ë£Œ", "content": ["â€¢ ì‹ ì„ í•œ ì¬ë£Œ", "â€¢ ì—„ì„ ëœ ì‹ì¬ë£Œ", "â€¢ í”„ë¦¬ë¯¸ì—„ í’ˆì§ˆ"]},
                {"title": "ê°€ê²© ì•ˆë‚´", "content": ["â€¢ í•©ë¦¬ì ì¸ ê°€ê²©", "â€¢ ì„¸íŠ¸ í• ì¸", "â€¢ ë‹¨í’ˆ ë©”ë‰´"]}
            ]
            last_page = {
                "title": "ì£¼ë¬¸í•˜ê¸°",
                "content": ["ğŸ“ ì „í™” ì£¼ë¬¸", "ğŸ›µ ë°°ë‹¬ ê°€ëŠ¥"],
                "cta": "ë§›ìˆê²Œ ë“œì„¸ìš”!"
            }
        else:
            # ì •ë³´ìš© í…œí”Œë¦¿ (ê¸°ë³¸)
            first_page = {
                "title": "ì•Œì•„ë‘ì„¸ìš”",
                "subtitle": "ìœ ìš©í•œ ì •ë³´ ëª¨ìŒ",
                "hook": "ğŸ“Œ í•µì‹¬ë§Œ ì •ë¦¬í–ˆì–´ìš”",
                "visual_concept": "ê¹”ë”í•˜ê³  ì •ëˆëœ ì •ë³´ ì „ë‹¬ ì´ë¯¸ì§€"
            }
            middle_templates = [
                {"title": "í•µì‹¬ í¬ì¸íŠ¸", "content": ["â€¢ ì¤‘ìš”í•œ ë‚´ìš© 1", "â€¢ ì¤‘ìš”í•œ ë‚´ìš© 2", "â€¢ ì¤‘ìš”í•œ ë‚´ìš© 3"]},
                {"title": "ì•Œì•„ë‘ë©´ ì¢‹ì€ íŒ", "content": ["â€¢ ì‹¤ìš©ì ì¸ íŒ 1", "â€¢ ì‹¤ìš©ì ì¸ íŒ 2"]},
                {"title": "ì°¸ê³  ì‚¬í•­", "content": ["â€¢ ì¶”ê°€ ì •ë³´", "â€¢ ê´€ë ¨ ë§í¬"]}
            ]
            last_page = {
                "title": "ë” ì•Œì•„ë³´ê¸°",
                "content": ["ğŸ” ìì„¸í•œ ì •ë³´ëŠ”", "ğŸ‘‰ ë§í¬ë¥¼ í™•ì¸í•˜ì„¸ìš”"],
                "cta": "í™•ì¸í•˜ê¸°"
            }

        # í˜ì´ì§€ ìƒì„±
        for i in range(page_count):
            if i == 0:
                # ì²« í˜ì´ì§€: ì£¼ì œ ê¸°ë°˜ Hook
                page = {
                    "page": 1,
                    "title": first_page["title"],
                    "subtitle": first_page["subtitle"],
                    "content": [],
                    "content_type": "hook",
                    "visual_concept": first_page["visual_concept"],
                    "layout": "center"
                }
            elif i == page_count - 1:
                # ë§ˆì§€ë§‰ í˜ì´ì§€: CTA
                page = {
                    "page": i + 1,
                    "title": last_page["title"],
                    "content": last_page["content"],
                    "content_type": "cta",
                    "visual_concept": "í–‰ë™ì„ ìœ ë„í•˜ëŠ” ë°ê³  ê¸ì •ì ì¸ ì´ë¯¸ì§€",
                    "layout": "center"
                }
            else:
                # ì¤‘ê°„ í˜ì´ì§€: í‚¤í¬ì¸íŠ¸ ë˜ëŠ” í…œí”Œë¦¿
                template_idx = (i - 1) % len(middle_templates)
                template = middle_templates[template_idx]

                # key_pointsê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                if key_points and i - 1 < len(key_points):
                    content_items = [f"â€¢ {key_points[i - 1]}"]
                else:
                    content_items = template["content"]

                page = {
                    "page": i + 1,
                    "title": template["title"],
                    "content": content_items,
                    "content_type": "bullet",
                    "visual_concept": f"{topic} ê´€ë ¨ ì‹œê°ì  ì´ë¯¸ì§€",
                    "layout": "center"
                }

            pages.append(page)

        return pages


# ==================== Agent 3: Visual Designer (ë¹„ì£¼ì–¼ ë””ìì´ë„ˆ) ====================

class VisualDesignerAgent:
    """Gamma AI ë˜ëŠ” ì´ë¯¸ì§€ ìƒì„± AIë¥¼ í™œìš©í•˜ì—¬ ë¹„ì£¼ì–¼ì„ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸"""

    @staticmethod
    async def generate_page_visuals(pages: List[Dict], style: str) -> List[Dict]:
        """
        ê° í˜ì´ì§€ì˜ ë¹„ì£¼ì–¼ ì´ë¯¸ì§€ ìƒì„± - ê° í˜ì´ì§€ë§ˆë‹¤ ê³ ìœ í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            pages: í˜ì´ì§€ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸
            style: ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (modern/minimal/vibrant/professional)

        Returns:
            pagesì— image_prompt ì¶”ê°€ëœ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âš ï¸ [Visual Designer] Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨, í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±")
                return VisualDesignerAgent._generate_prompts_only(pages, style)

            model = GenerativeModel("gemini-2.0-flash-001")

            print(f"\nğŸ¨ [Visual Designer] ê° í˜ì´ì§€ë§ˆë‹¤ ê³ ìœ í•œ ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")

            for i, page in enumerate(pages):
                # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš©
                prompt = get_visual_designer_prompt(
                    page_num=i + 1,
                    total_pages=len(pages),
                    title=page['title'],
                    content=page.get('content', []),
                    visual_concept=page.get('visual_concept', ''),
                    style=style,
                    layout=page.get('layout', 'center')
                )

                response = model.generate_content(prompt)
                optimized_prompt = response.text.strip()

                # í”„ë¡¬í”„íŠ¸ ì •ë³´ ì €ì¥
                page['image_prompt'] = optimized_prompt
                page['prompt_generation_log'] = f"Vertex AIê°€ í˜ì´ì§€ {i+1}ì˜ ê³ ìœ í•œ ë¹„ì£¼ì–¼ ìƒì„±: {page['visual_concept']}"

                print(f"  âœ… í˜ì´ì§€ {i+1}/{len(pages)} ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸:")
                print(f"     ğŸ“ {optimized_prompt[:100]}...")

            print(f"\nâœ… [Visual Designer] {len(pages)}ê°œì˜ ê³ ìœ í•œ ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
            return pages

        except Exception as e:
            print(f"âš ï¸ [Visual Designer] ë¹„ì£¼ì–¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return VisualDesignerAgent._generate_prompts_only(pages, style)

    @staticmethod
    def _generate_prompts_only(pages: List[Dict], style: str) -> List[Dict]:
        """ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„± (í´ë°±)"""
        style_keywords = {
            "modern": "clean gradient background, geometric shapes, modern design, no text",
            "minimal": "minimal white background, subtle colors, simple, no text",
            "vibrant": "vibrant colors, dynamic composition, energetic, no text",
            "professional": "professional corporate background, balanced, trustworthy, no text"
        }

        base_prompt = style_keywords.get(style, style_keywords["modern"])

        for page in pages:
            page['image_prompt'] = f"{base_prompt}, {page['visual_concept']}, high quality, absolutely no text or letters or words"

        return pages


# ==================== Agent 4: Quality Assurance (í’ˆì§ˆ ê²€ì¦) ====================

class QualityAssuranceAgent:
    """ìƒì„±ëœ ì½˜í…ì¸ ì˜ í’ˆì§ˆì„ ê²€ì¦í•˜ê³  ê°œì„ í•˜ëŠ” ì—ì´ì „íŠ¸"""

    @staticmethod
    def _ensure_vertex_ai():
        """Vertex AI ì´ˆê¸°í™” í™•ì¸"""
        global _vertex_ai_initialized
        if not _vertex_ai_initialized:
            _vertex_ai_initialized = init_vertex_ai()
        return _vertex_ai_initialized

    @staticmethod
    async def validate_and_improve(pages: List[Dict], original_input: str, analysis: Dict) -> Dict:
        """
        ì½˜í…ì¸  í’ˆì§ˆ ê²€ì¦ ë° ê°œì„  ì œì•ˆ

        Returns:
            {
                "overall_score": 8.5,
                "consistency_score": 9,
                "message_clarity_score": 8,
                "needs_improvement": [2, 4],
                "suggestions": ["í˜ì´ì§€ 2: ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ìš”", ...],
                "approved": true
            }
        """
        try:
            # Vertex AI ì´ˆê¸°í™”
            QualityAssuranceAgent._ensure_vertex_ai()

            # Vertex AI ëª¨ë¸ ì‚¬ìš©
            model = GenerativeModel("gemini-2.0-flash-001")

            # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš©
            prompt = get_quality_assurance_prompt(
                original_input=original_input,
                target_audience=analysis.get('target_audience', 'ì¼ë°˜ ëŒ€ì¤‘'),
                tone=analysis.get('tone', 'ì¹œê·¼í•œ'),
                key_message=analysis.get('key_message', ''),
                pages=pages
            )

            response = model.generate_content(prompt)
            response_text = response.text.strip()

            print("ğŸ” Raw Gemini QA Response:\n", response_text)

            json_match = re.search(r'\{[\s\S]*\}', response_text)

            if json_match:
                validation = json.loads(json_match.group(0))
                print(f"âœ… [Quality Assurance] ê²€ì¦ ì™„ë£Œ")
                print(f"  ğŸ“Š ì¢…í•© ì ìˆ˜: {validation.get('overall_score', 0)}/10")
                print(f"  ğŸ“Š ë©”ì‹œì§€ ì „ë‹¬: {validation.get('message_clarity_score', 0)}/10")
                print(f"  ğŸ“Š ì¼ê´€ì„±: {validation.get('consistency_score', 0)}/10")

                if validation.get('suggestions'):
                    print("  ğŸ’¡ ê°œì„  ì œì•ˆ:")
                    for suggestion in validation['suggestions']:
                        print(f"     - {suggestion}")

                return validation

            return QualityAssuranceAgent._get_fallback_validation()

        except Exception as e:
            print(f"âš ï¸ [Quality Assurance] ê²€ì¦ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return QualityAssuranceAgent._get_fallback_validation()

    @staticmethod
    def _get_fallback_validation() -> Dict:
        """í´ë°± ê²€ì¦ ê²°ê³¼"""
        return {
            "overall_score": 7.0,
            "message_clarity_score": 7.0,
            "consistency_score": 7.0,
            "target_fit_score": 7.0,
            "needs_improvement": [],
            "suggestions": [],
            "approved": True
        }


# ==================== ìœ í‹¸ë¦¬í‹°: ìƒ‰ìƒ ì¶”ì¶œ ====================

def extract_dominant_color_from_image(image_data: str) -> Tuple[int, int, int]:
    """
    ì´ë¯¸ì§€ì—ì„œ ì£¼ìš” ìƒ‰ìƒì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë˜ëŠ” URL

    Returns:
        RGB íŠœí”Œ (r, g, b)
    """
    try:
        from PIL import Image
        import io
        import base64

        # Base64 ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
        if image_data.startswith('data:image'):
            image_bytes = base64.b64decode(image_data.split(',')[1])
            img = Image.open(io.BytesIO(image_bytes))
        else:
            import requests
            response = requests.get(image_data, timeout=10)
            img = Image.open(io.BytesIO(response.content))

        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´)
        img = img.resize((50, 50))
        img = img.convert('RGB')

        # í”½ì…€ ìƒ‰ìƒ ìˆ˜ì§‘
        pixels = list(img.getdata())

        # í‰ê·  ìƒ‰ìƒ ê³„ì‚° (ë‹¨ìˆœ ë°©ì‹)
        r_total = sum(p[0] for p in pixels)
        g_total = sum(p[1] for p in pixels)
        b_total = sum(p[2] for p in pixels)
        count = len(pixels)

        return (r_total // count, g_total // count, b_total // count)

    except Exception as e:
        print(f"âš ï¸ ìƒ‰ìƒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return (100, 100, 100)  # ê¸°ë³¸ íšŒìƒ‰


def get_text_color_for_background(bg_color: Tuple[int, int, int]) -> str:
    """
    ë°°ê²½ìƒ‰ì— ë”°ë¼ ì í•©í•œ í…ìŠ¤íŠ¸ ìƒ‰ìƒ(ê²€ì •/í°ìƒ‰)ì„ ê²°ì •í•©ë‹ˆë‹¤.

    Args:
        bg_color: RGB íŠœí”Œ (r, g, b)

    Returns:
        "white" ë˜ëŠ” "black"
    """
    r, g, b = bg_color
    # ë°ê¸° ê³„ì‚° (YIQ ê³µì‹)
    brightness = (r * 299 + g * 587 + b * 114) / 1000

    # ë°ê¸°ê°€ 128 ì´ìƒì´ë©´ ì–´ë‘ìš´ í…ìŠ¤íŠ¸, ì•„ë‹ˆë©´ ë°ì€ í…ìŠ¤íŠ¸
    return "black" if brightness > 128 else "white"


def adjust_color_for_harmony(dominant_color: Tuple[int, int, int], style: str) -> Tuple[int, int, int]:
    """
    ì¸ë„¤ì¼ì˜ ì£¼ìš” ìƒ‰ìƒì„ ê¸°ë°˜ìœ¼ë¡œ ì¡°í™”ë¡œìš´ ë‹¨ìƒ‰ ë°°ê²½ ìƒ‰ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        dominant_color: ì¸ë„¤ì¼ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” RGB ìƒ‰ìƒ
        style: ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (modern/minimal/vibrant/professional)

    Returns:
        ì¡°ì •ëœ RGB íŠœí”Œ
    """
    r, g, b = dominant_color

    if style == "minimal":
        # ë°ê³  ë¶€ë“œëŸ¬ìš´ í†¤ìœ¼ë¡œ ì¡°ì •
        return (min(255, r + 60), min(255, g + 60), min(255, b + 60))
    elif style == "vibrant":
        # ì±„ë„ ë†’ì´ê¸°
        max_val = max(r, g, b)
        if max_val > 0:
            factor = 255 / max_val
            return (min(255, int(r * factor * 0.9)), min(255, int(g * factor * 0.9)), min(255, int(b * factor * 0.9)))
        return dominant_color
    elif style == "professional":
        # ì•½ê°„ ì–´ë‘¡ê³  ì°¨ë¶„í•˜ê²Œ
        return (max(0, r - 30), max(0, g - 30), max(0, b - 30))
    else:  # modern
        # ì›ë³¸ ìœ ì§€í•˜ë©´ì„œ ì‚´ì§ ì¡°ì •
        return (min(255, max(0, r + 10)), min(255, max(0, g + 10)), min(255, max(0, b + 10)))


# ==================== Master Workflow (ë§ˆìŠ¤í„° ì›Œí¬í”Œë¡œìš°) ====================

class AgenticCardNewsWorkflow:
    """ëª¨ë“  ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ëŠ” ë§ˆìŠ¤í„° ì›Œí¬í”Œë¡œìš°"""

    def __init__(self):
        self.content_enricher = ContentEnricherAgent()
        self.orchestrator = OrchestratorAgent()
        self.content_planner = ContentPlannerAgent()
        self.visual_designer = VisualDesignerAgent()
        self.qa = QualityAssuranceAgent()

    async def execute(self, user_input: str, purpose: str = "info", user_context: Dict = None) -> Dict:
        """
        ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ í”„ë¡¬í”„íŠ¸
            purpose: ëª©ì  (promotion/menu/info/event)
            user_context: ì˜¨ë³´ë”©ì—ì„œ ìˆ˜ì§‘í•œ ì‚¬ìš©ì ì •ë³´ (ë¸Œëœë“œ, íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤, í†¤ ë“±)

        Returns:
            {
                "success": True,
                "analysis": {...},
                "pages": [...],
                "quality_report": {...},
                "design_settings": {...}
            }
        """
        print("\n" + "="*80)
        print("ğŸš€ AI Agentic ì¹´ë“œë‰´ìŠ¤ ìƒì„± ì›Œí¬í”Œë¡œìš° ì‹œì‘")
        if user_context:
            print(f"   ğŸ¢ ë¸Œëœë“œ: {user_context.get('brand_name', 'ë¯¸ì„¤ì •')}")
            print(f"   ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤: {user_context.get('business_type', 'ë¯¸ì„¤ì •')}")
        print("="*80 + "\n")

        try:
            # Step 1: ì •ë³´ í™•ì¥ (ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            print("âœ¨ Step 1/5: ì‚¬ìš©ì ì…ë ¥ ì •ë³´ í™•ì¥ ì¤‘...")
            enriched_data = await self.content_enricher.enrich_content(user_input, purpose, user_context)
            print(f"   âœ… ì •ë³´ í™•ì¥ ì™„ë£Œ (ì¶”ê°€ ìš”ì†Œ: {len(enriched_data.get('added_elements', []))}ê°œ)\n")

            # Step 2: ìš”ì²­ ë¶„ì„ (í™•ì¥ëœ ì •ë³´ ê¸°ë°˜)
            print("ğŸ“‹ Step 2/5: ì½˜í…ì¸  ë¶„ì„ ë° ì„¤ì • ê²°ì • ì¤‘...")
            analysis = await self.orchestrator.analyze_user_request(enriched_data, purpose)
            print(f"   âœ… {analysis['page_count']}í˜ì´ì§€, {analysis['style']} ìŠ¤íƒ€ì¼, {analysis.get('font_pair', 'pretendard')} í°íŠ¸\n")

            # Step 3: ì½˜í…ì¸  ê¸°íš (í™•ì¥ëœ ì •ë³´ ì‚¬ìš©)
            print("âœï¸  Step 3/5: í˜ì´ì§€ë³„ ì½˜í…ì¸  ê¸°íš ì¤‘...")
            enriched_content = analysis.get('enriched_content', user_input)
            pages = await self.content_planner.plan_cardnews_pages(enriched_content, analysis)
            print(f"   âœ… {len(pages)}ê°œ í˜ì´ì§€ ê¸°íš ì™„ë£Œ\n")

            # Step 4: ë¹„ì£¼ì–¼ ë””ìì¸
            print("ğŸ¨ Step 4/5: ê° í˜ì´ì§€ì˜ ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            pages = await self.visual_designer.generate_page_visuals(
                pages,
                analysis.get('style', 'modern')
            )
            print(f"   âœ… ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ\n")

            # Step 5: í’ˆì§ˆ ê²€ì¦
            print("ğŸ” Step 5/5: ì½˜í…ì¸  í’ˆì§ˆ ê²€ì¦ ì¤‘...")
            quality_report = await self.qa.validate_and_improve(pages, user_input, analysis)
            print(f"   âœ… í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ\n")

            # ë””ìì¸ ì„¤ì • êµ¬ì„±
            font_pair = analysis.get('font_pair', 'pretendard')
            design_settings = {
                "font_pair": font_pair,
                "font_korean": FONT_PAIRS.get(font_pair, FONT_PAIRS['pretendard'])['korean'],
                "font_english": FONT_PAIRS.get(font_pair, FONT_PAIRS['pretendard'])['english'],
                "style": analysis.get('style', 'modern'),
                "text_color": "white",  # ê¸°ë³¸ê°’, ì¸ë„¤ì¼ ìƒì„± í›„ ì—…ë°ì´íŠ¸ë¨
                "bg_color": None  # ì¸ë„¤ì¼ ìƒ‰ìƒ ì¶”ì¶œ í›„ ì„¤ì •ë¨
            }

            print("="*80)
            print("âœ… AI Agentic ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
            print(f"   ğŸ“„ í˜ì´ì§€: {len(pages)}ì¥")
            print(f"   ğŸ”¤ í°íŠ¸: {design_settings['font_korean']} / {design_settings['font_english']}")
            print(f"   ğŸ¨ ìŠ¤íƒ€ì¼: {design_settings['style']}")
            print("="*80 + "\n")

            return {
                "success": True,
                "analysis": analysis,
                "pages": pages,
                "quality_report": quality_report,
                "design_settings": design_settings,
                "enriched_data": enriched_data
            }

        except Exception as e:
            print(f"\nâŒ ì›Œí¬í”Œë¡œìš° ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

            return {
                "success": False,
                "error": str(e),
                "analysis": None,
                "pages": [],
                "quality_report": None,
                "design_settings": None
            }
