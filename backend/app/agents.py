"""
AI Agentic ì¹´ë“œë‰´ìŠ¤ ìƒì„± ì‹œìŠ¤í…œ
ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°: ì •ë³´ í™•ì¥ â†’ ë¶„ì„ â†’ ê¸°íš â†’ ë””ìì¸ â†’ í’ˆì§ˆê²€ì¦

Vertex AI API ì‚¬ìš© (Google Cloud Platform)
"""

import os
import json
import re
from typing import List, Dict, Optional, Tuple
import httpx

# Vertex AI ì„í¬íŠ¸
import vertexai
from vertexai.generative_models import GenerativeModel, Part, Tool
from google.cloud import aiplatform

# Vertex AI ì´ˆê¸°í™” í•¨ìˆ˜
def init_vertex_ai():
    """Vertex AI ì´ˆê¸°í™” - í”„ë¡œì íŠ¸ ë° ì¸ì¦ ì„¤ì •"""
    project_id = os.getenv("GOOGLE_CLOUD_PROJECT", "bubbly-solution-480805-b5")
    location = "us-central1"  # Gemini ëª¨ë¸ ì§€ì› ë¦¬ì „

    # ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if credentials_path and os.path.exists(credentials_path):
        print(f"ğŸ”‘ [Vertex AI] ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦: {credentials_path}")
    else:
        print(f"âš ï¸ [Vertex AI] GOOGLE_APPLICATION_CREDENTIALS ê²½ë¡œ í™•ì¸ í•„ìš”")

    try:
        vertexai.init(project=project_id, location=location)
        print(f"âœ… [Vertex AI] ì´ˆê¸°í™” ì™„ë£Œ - í”„ë¡œì íŠ¸: {project_id}, ë¦¬ì „: {location}")
        return True
    except Exception as e:
        print(f"âŒ [Vertex AI] ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# ì•± ì‹œì‘ ì‹œ Vertex AI ì´ˆê¸°í™”
_vertex_ai_initialized = False

# í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from .prompts import (
    get_content_enricher_prompt,
    get_orchestrator_prompt,
    get_content_planner_prompt,
    get_visual_designer_prompt,
    get_quality_assurance_prompt,
    TONE_MAPPING,
    STYLE_GUIDELINES,
    PAGE_STRUCTURE_GUIDE,
    HOW_TO_PAGE_STRUCTURE,
)


def get_nearest_page_structure(page_count: int, is_how_to: bool = False) -> dict:
    """
    ì£¼ì–´ì§„ í˜ì´ì§€ ìˆ˜ì— ê°€ì¥ ê°€ê¹Œìš´ í˜ì´ì§€ êµ¬ì¡°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì •ì˜ë˜ì§€ ì•Šì€ í˜ì´ì§€ ìˆ˜ì˜ ê²½ìš° ê°€ì¥ ê°€ê¹Œìš´ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        page_count: í˜ì´ì§€ ìˆ˜
        is_how_to: How-To ì½˜í…ì¸  ì—¬ë¶€

    Returns:
        í˜ì´ì§€ êµ¬ì¡° ë”•ì…”ë„ˆë¦¬
    """
    structure_guide = HOW_TO_PAGE_STRUCTURE if is_how_to else PAGE_STRUCTURE_GUIDE

    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” êµ¬ì¡°ê°€ ìˆìœ¼ë©´ ë°˜í™˜
    if page_count in structure_guide:
        return structure_guide[page_count]

    # ê°€ì¥ ê°€ê¹Œìš´ êµ¬ì¡° ì°¾ê¸°
    available_counts = sorted(structure_guide.keys())

    # ê°€ì¥ ê°€ê¹Œìš´ ê°’ ì°¾ê¸°
    closest = min(available_counts, key=lambda x: abs(x - page_count))

    # í˜ì´ì§€ ìˆ˜ê°€ ë” ë§ì€ ê²½ìš°, ê¸°ë³¸ êµ¬ì¡°ë¥¼ í™•ì¥
    if page_count > max(available_counts):
        base_structure = structure_guide[max(available_counts)]
        return _extend_page_structure(base_structure, page_count)

    return structure_guide[closest]


def _extend_page_structure(base_structure: dict, target_count: int) -> dict:
    """
    ê¸°ë³¸ êµ¬ì¡°ë¥¼ í™•ì¥í•˜ì—¬ ë” ë§ì€ í˜ì´ì§€ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
    """
    base_count = len(base_structure['structure'])
    extra_pages = target_count - base_count

    # êµ¬ì¡° í™•ì¥
    extended_structure = base_structure['structure'].copy()
    extended_roles = base_structure['page_roles'].copy()

    # CTAë¥¼ ë§ˆì§€ë§‰ìœ¼ë¡œ ìœ ì§€í•˜ë©´ì„œ ì¤‘ê°„ì— Detail í˜ì´ì§€ ì¶”ê°€
    cta_structure = extended_structure[-1]
    cta_role = extended_roles.get(base_count, 'í–‰ë™ ì´‰êµ¬ - ë‹¤ìŒ ë‹¨ê³„')

    # CTA ì œê±° í›„ ì¶”ê°€ í˜ì´ì§€ ì‚½ì…
    extended_structure = extended_structure[:-1]

    for i in range(extra_pages):
        page_num = base_count + i
        extended_structure.append(f'Details{i+1}')
        extended_roles[page_num] = f'ì¶”ê°€ ì„¸ë¶€ ì •ë³´ {i+1}'

    # CTA ë‹¤ì‹œ ì¶”ê°€
    extended_structure.append(cta_structure)
    extended_roles[target_count] = cta_role

    return {
        'structure': extended_structure,
        'description': f'{target_count}ì¥ í™•ì¥ êµ¬ì„±',
        'page_roles': extended_roles
    }


# ==================== í°íŠ¸ ì„¤ì • ====================

FONT_PAIRS = {
    "pretendard": {
        "korean": "Pretendard",
        "english": "Inter",
        "style": "modern",
        "description": "í˜„ëŒ€ì ì´ê³  ê¹”ë”í•œ ëŠë‚Œ"
    },
    "noto": {
        "korean": "Noto Sans KR",
        "english": "Noto Sans",
        "style": "neutral",
        "description": "ì¤‘ë¦½ì ì´ê³  ê°€ë…ì„± ì¢‹ì€ ëŠë‚Œ"
    },
    "spoqa": {
        "korean": "Spoqa Han Sans",
        "english": "Roboto",
        "style": "friendly",
        "description": "ì¹œê·¼í•˜ê³  ë¶€ë“œëŸ¬ìš´ ëŠë‚Œ"
    }
}


# ==================== Agent 0: Content Enricher (ì •ë³´ í™•ì¥ + ì›¹ ê²€ìƒ‰) ====================

class ContentEnricherAgent:
    """ì‚¬ìš©ìì˜ ê°„ë‹¨í•œ ì…ë ¥ì„ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì‹¤ì œ ì •ë³´ë¡œ í™•ì¥í•˜ëŠ” ì—ì´ì „íŠ¸"""

    # "~ í•˜ëŠ” ë°©ë²•" íŒ¨í„´ ê°ì§€ë¥¼ ìœ„í•œ ì •ê·œì‹
    HOW_TO_PATTERNS = [
        r'(.+?)\s*í•˜ëŠ”\s*ë°©ë²•',           # "~ í•˜ëŠ” ë°©ë²•"
        r'(.+?)\s*í•˜ëŠ”\s*ë²•',             # "~ í•˜ëŠ” ë²•"
        r'ì–´ë–»ê²Œ\s*(.+?)(?:\s*í• ê¹Œ|\s*í•˜ë‚˜|\s*í•´ìš”|\s*í•©ë‹ˆê¹Œ)',  # "ì–´ë–»ê²Œ ~ í• ê¹Œ/í•˜ë‚˜/í•´ìš”"
        r'(.+?)\s*(?:ë°©ë²•|íŒ|ë…¸í•˜ìš°)',    # "~ ë°©ë²•/íŒ/ë…¸í•˜ìš°"
        r'(.+?)\s*(?:ê°€ì´ë“œ|íŠœí† ë¦¬ì–¼)',   # "~ ê°€ì´ë“œ/íŠœí† ë¦¬ì–¼"
    ]

    @staticmethod
    def _detect_how_to_pattern(user_input: str) -> Tuple[bool, str]:
        """
        "~ í•˜ëŠ” ë°©ë²•" íŒ¨í„´ ê°ì§€

        Returns:
            (is_how_to: bool, extracted_topic: str)
        """
        import re

        for pattern in ContentEnricherAgent.HOW_TO_PATTERNS:
            match = re.search(pattern, user_input)
            if match:
                topic = match.group(1).strip()
                print(f"ğŸ” [How-To íŒ¨í„´ ê°ì§€] ì£¼ì œ: '{topic}'")
                return True, topic

        return False, user_input

    @staticmethod
    def _ensure_vertex_ai():
        """Vertex AI ì´ˆê¸°í™” í™•ì¸"""
        global _vertex_ai_initialized
        if not _vertex_ai_initialized:
            _vertex_ai_initialized = init_vertex_ai()
        return _vertex_ai_initialized

    @staticmethod
    async def _search_web_info(query: str, is_how_to: bool = False) -> str:
        """
        Google Searchë¥¼ í†µí•´ ì£¼ì œì— ëŒ€í•œ ì‹¤ì œ ì •ë³´ë¥¼ ê²€ìƒ‰
        Vertex AI Gemini + Google Search Grounding ì‚¬ìš©

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            is_how_to: "~ í•˜ëŠ” ë°©ë²•" íŒ¨í„´ì¸ì§€ ì—¬ë¶€
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âš ï¸ [Web Search] Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨")
                return ""

            # Vertex AI Gemini ëª¨ë¸ (Google Search Grounding ì§€ì›)
            from vertexai.generative_models import GenerativeModel, Tool, grounding

            # Google Search ë„êµ¬ ì„¤ì •
            google_search_tool = Tool.from_google_search_retrieval(
                grounding.GoogleSearchRetrieval()
            )

            search_model = GenerativeModel(
                "gemini-2.0-flash-001",
                tools=[google_search_tool]
            )

            # "~ í•˜ëŠ” ë°©ë²•" íŒ¨í„´ì¸ ê²½ìš° ë‹¨ê³„ë³„ ê°€ì´ë“œ ê²€ìƒ‰
            if is_how_to:
                search_prompt = f"""ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì‹¤ìš©ì ì¸ ë°©ë²•/ê°€ì´ë“œë¥¼ ê²€ìƒ‰í•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”.
ì£¼ì œ: {query}

ê²€ìƒ‰í•´ì„œ ì°¾ì•„ì•¼ í•  ì •ë³´:
1. **ë‹¨ê³„ë³„ ë°©ë²•** (Step 1, Step 2, ... í˜•íƒœë¡œ ì •ë¦¬)
2. **í•„ìš”í•œ ì¤€ë¹„ë¬¼/ì¡°ê±´** (ìˆë‹¤ë©´)
3. **ì£¼ì˜ì‚¬í•­ ë° íŒ**
4. **ì˜ˆìƒ ì†Œìš” ì‹œê°„/ë¹„ìš©** (í•´ë‹¹ë˜ëŠ” ê²½ìš°)
5. **ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜ì™€ í•´ê²°ë²•**

ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ” ë‹¨ê³„ë³„ ê°€ì´ë“œë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.
ê° ë‹¨ê³„ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.
ë§Œì•½ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ë‹¤ë©´ "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"ì´ë¼ê³  ë‹µí•˜ì„¸ìš”."""
            else:
                search_prompt = f"""ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”.
ì£¼ì œ: {query}

ê²€ìƒ‰í•´ì„œ ì°¾ì•„ì•¼ í•  ì •ë³´:
1. ì •í™•í•œ ë‚ ì§œ, ì‹œê°„, ì¥ì†Œ
2. ê´€ë ¨ëœ ì£¼ìš” ì¸ë¬¼/ê¸°ê´€
3. êµ¬ì²´ì ì¸ ìˆ«ìë‚˜ í†µê³„
4. ì£¼ìš” ì‚¬ê±´ì˜ ê²½ê³¼ë‚˜ ê³¼ì •
5. ì˜ë¯¸ì™€ ì¤‘ìš”ì„±

ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ì •ë³´ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.
ë§Œì•½ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ë‹¤ë©´ "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"ì´ë¼ê³  ë‹µí•˜ì„¸ìš”."""

            response = search_model.generate_content(search_prompt)
            search_result = response.text.strip()

            print(f"ğŸ” [Web Search] ê²€ìƒ‰ ì™„ë£Œ: {query[:30]}... (How-To: {is_how_to})")
            print(f"   ğŸ“„ ê²°ê³¼ ê¸¸ì´: {len(search_result)}ì")

            return search_result

        except Exception as e:
            print(f"âš ï¸ [Web Search] ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return ""

    @staticmethod
    async def enrich_content(user_input: str, purpose: str, user_context: Dict = None) -> Dict:
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ê³  ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì‹¤ì œ ì •ë³´ë¡œ í™•ì¥

        Returns:
            {
                "original_input": "ì›ë³¸ ì…ë ¥",
                "enriched_content": "í™•ì¥ëœ ì½˜í…ì¸ ",
                "added_elements": ["ê³„ì ˆê°", "êµ¬ì²´ì  ì˜ˆì‹œ", ...],
                "context_suggestions": ["ì¶”ê°€ ë§¥ë½ ì •ë³´"],
                "recommended_page_count": 3-5,
                "researched_facts": ["ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ì‚¬ì‹¤ë“¤"],
                "is_how_to": True/False,
                "content_mode": "how_to" | "general"
            }
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨!")
                return ContentEnricherAgent._get_fallback_enrichment(user_input, purpose)

            # Step 0: "~ í•˜ëŠ” ë°©ë²•" íŒ¨í„´ ê°ì§€
            is_how_to, extracted_topic = ContentEnricherAgent._detect_how_to_pattern(user_input)

            if is_how_to:
                print(f"ğŸ“š [Content Enricher] How-To ëª¨ë“œ í™œì„±í™”: '{extracted_topic}'")
                # How-To íŒ¨í„´ì¸ ê²½ìš° purposeë¥¼ 'how_to'ë¡œ ë³€ê²½
                purpose = "how_to"

            # Step 1: ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ ì •ë³´ ìˆ˜ì§‘
            print(f"ğŸŒ [Content Enricher] ì›¹ ê²€ìƒ‰ ì‹œì‘: {user_input}")
            web_info = await ContentEnricherAgent._search_web_info(user_input, is_how_to=is_how_to)

            # Step 2: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½˜í…ì¸  ìƒì„±
            model = GenerativeModel("gemini-2.0-flash-001")

            # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì •ë³´ êµ¬ì„±
            user_context_info = ""
            if user_context:
                context_parts = []
                if user_context.get('brand_name'):
                    context_parts.append(f"- ë¸Œëœë“œëª…: {user_context['brand_name']}")
                if user_context.get('business_type'):
                    business_type_map = {
                        'startup': 'ìŠ¤íƒ€íŠ¸ì—…/ì‹ ìƒ ë¸Œëœë“œ',
                        'small_business': 'ì†Œê·œëª¨ ë¹„ì¦ˆë‹ˆìŠ¤',
                        'personal_brand': 'ê°œì¸ ë¸Œëœë“œ/ì¸í”Œë£¨ì–¸ì„œ',
                        'corporate': 'ê¸°ì—…/ëŒ€ê¸°ì—…',
                        'nonprofit': 'ë¹„ì˜ë¦¬ ë‹¨ì²´',
                        'freelancer': 'í”„ë¦¬ëœì„œ',
                        'ecommerce': 'ì´ì»¤ë¨¸ìŠ¤/ì˜¨ë¼ì¸ ì‡¼í•‘ëª°',
                        'local_business': 'ì§€ì—­ ë¹„ì¦ˆë‹ˆìŠ¤'
                    }
                    context_parts.append(f"- ë¹„ì¦ˆë‹ˆìŠ¤ ìœ í˜•: {business_type_map.get(user_context['business_type'], user_context['business_type'])}")
                if user_context.get('business_description'):
                    context_parts.append(f"- ë¹„ì¦ˆë‹ˆìŠ¤ ì„¤ëª…: {user_context['business_description']}")
                if user_context.get('target_audience'):
                    target = user_context['target_audience']
                    if isinstance(target, dict):
                        target_str = ", ".join([f"{k}: {v}" for k, v in target.items()])
                    else:
                        target_str = str(target)
                    context_parts.append(f"- íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤: {target_str}")
                if user_context.get('brand_tone'):
                    context_parts.append(f"- ë¸Œëœë“œ í†¤: {user_context['brand_tone']}")
                if user_context.get('brand_personality'):
                    context_parts.append(f"- ë¸Œëœë“œ ì„±ê²©: {user_context['brand_personality']}")
                if user_context.get('key_themes'):
                    context_parts.append(f"- í•µì‹¬ í…Œë§ˆ: {', '.join(user_context['key_themes'])}")
                if user_context.get('text_tone'):
                    tone_map = {
                        'casual': 'ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ',
                        'professional': 'ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ”',
                        'friendly': 'ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ',
                        'formal': 'ê²©ì‹ ìˆê³  ì •ì¤‘í•œ'
                    }
                    context_parts.append(f"- í…ìŠ¤íŠ¸ í†¤: {tone_map.get(user_context['text_tone'], user_context['text_tone'])}")

                if context_parts:
                    user_context_info = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¢ ë¸Œëœë“œ/ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ (ì˜¨ë³´ë”© ë°ì´í„°)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{chr(10).join(context_parts)}
**ì¤‘ìš”**: ìœ„ ë¸Œëœë“œ ì •ë³´ë¥¼ ë°˜ì˜í•˜ì—¬ ë¸Œëœë“œ ì •ì²´ì„±ì— ë§ëŠ” ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            web_search_section = ""
            if web_info and "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ" not in web_info:
                web_search_section = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ì‹¤ì œ ì •ë³´
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{web_info}
**ì¤‘ìš”**: ìœ„ ê²€ìƒ‰ ê²°ê³¼ì˜ êµ¬ì²´ì ì¸ ì‚¬ì‹¤(ë‚ ì§œ, ì¥ì†Œ, ìˆ«ì, ê³¼ì • ë“±)ì„ ë°˜ë“œì‹œ ì½˜í…ì¸ ì— í¬í•¨í•˜ì„¸ìš”!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

            # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš© + ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (How-To ëª¨ë“œ ì „ë‹¬)
            base_prompt = get_content_enricher_prompt(
                user_input=user_input,
                purpose=purpose,
                user_context=user_context_info,
                is_how_to=is_how_to
            )

            # ì›¹ ê²€ìƒ‰ ì„¹ì…˜ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            if web_search_section:
                enhanced_prompt = base_prompt.replace(
                    "## ë‹¹ì‹ ì˜ ì—­í• ",
                    f"{web_search_section}\n## ë‹¹ì‹ ì˜ ì—­í• "
                )
            else:
                enhanced_prompt = base_prompt

            response = model.generate_content(enhanced_prompt)
            response_text = response.text.strip()

            print("ğŸ” Raw Enrichment Response:\n", response_text)

            json_match = re.search(r'\{[\s\S]*\}', response_text)

            if json_match:
                enrichment = json.loads(json_match.group(0))
                # ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
                if web_info and "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ" not in web_info:
                    enrichment['web_search_used'] = True
                    enrichment['researched_info'] = web_info[:500]  # ìš”ì•½ë³¸ ì €ì¥
                else:
                    enrichment['web_search_used'] = False

                # How-To ëª¨ë“œ í”Œë˜ê·¸ ì¶”ê°€
                enrichment['is_how_to'] = is_how_to
                enrichment['content_mode'] = 'how_to' if is_how_to else 'general'

                # How-To ì½˜í…ì¸ ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 4-5í˜ì´ì§€ ê¶Œì¥
                if is_how_to and enrichment.get('recommended_page_count', 3) < 4:
                    enrichment['recommended_page_count'] = 4
                    enrichment['page_count_reason'] = "How-To ì½˜í…ì¸ : ë‹¨ê³„ë³„ ì„¤ëª…ì„ ìœ„í•´ 4í˜ì´ì§€ ì´ìƒ í•„ìš”"

                print(f"âœ… [Content Enricher] ì •ë³´ í™•ì¥ ì™„ë£Œ")
                print(f"   ğŸ“ ì›ë³¸: {user_input[:50]}...")
                print(f"   âœ¨ í™•ì¥: {enrichment.get('enriched_content', '')[:80]}...")
                print(f"   ğŸ“Š ì¶”ì²œ í˜ì´ì§€: {enrichment.get('recommended_page_count', 3)}ì¥")
                print(f"   ğŸŒ ì›¹ ê²€ìƒ‰ ì‚¬ìš©: {enrichment.get('web_search_used', False)}")
                print(f"   ğŸ“š How-To ëª¨ë“œ: {is_how_to}")
                return enrichment

            return ContentEnricherAgent._get_fallback_enrichment(user_input, purpose, is_how_to)

        except Exception as e:
            print(f"âš ï¸ [Content Enricher] í™•ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            is_how_to_fallback, _ = ContentEnricherAgent._detect_how_to_pattern(user_input)
            return ContentEnricherAgent._get_fallback_enrichment(user_input, purpose, is_how_to_fallback)

    @staticmethod
    def _get_fallback_enrichment(user_input: str, purpose: str = "info", is_how_to: bool = False) -> Dict:
        """
        í´ë°± í™•ì¥ ê²°ê³¼ - ëª©ì (purpose)ì— ë§ëŠ” ì „ë¬¸ì ì¸ ì½˜í…ì¸  ìƒì„±

        purpose ì¢…ë¥˜:
        - promotion: ì œí’ˆ/ì„œë¹„ìŠ¤ í™ë³´ (AIDA êµ¬ì¡°)
        - event: ì´ë²¤íŠ¸/í–‰ì‚¬ ì•ˆë‚´ (5W1H êµ¬ì¡°)
        - menu: ë©”ë‰´/ê°€ê²© ì†Œê°œ (ê°ê°ì  ë¬˜ì‚¬)
        - info: ì •ë³´ ì „ë‹¬ (ê°€ì¹˜ ì¤‘ì‹¬)
        - how_to: ë°©ë²•/ê°€ì´ë“œ ì„¤ëª… (ë‹¨ê³„ë³„)
        """
        input_length = len(user_input)

        # ì½˜í…ì¸  ê¸¸ì´ ê¸°ë°˜ í˜ì´ì§€ ìˆ˜ ê²°ì • (ìµœëŒ€ 20ì¥)
        if is_how_to:
            if input_length < 50:
                page_count = 4
            elif input_length < 100:
                page_count = 5
            elif input_length < 200:
                page_count = 6
            elif input_length < 400:
                page_count = 8
            else:
                page_count = 10
        elif input_length < 30:
            page_count = 3
        elif input_length < 80:
            page_count = 4
        elif input_length < 150:
            page_count = 5
        elif input_length < 300:
            page_count = 7
        elif input_length < 500:
            page_count = 10
        elif input_length < 800:
            page_count = 15
        else:
            page_count = 20

        # ëª©ì ë³„ ì „ë¬¸ ì½˜í…ì¸  í…œí”Œë¦¿
        if is_how_to or purpose == "how_to":
            # How-To: ì‹¤ìš©ì ì¸ ë‹¨ê³„ë³„ ê°€ì´ë“œ
            enriched = f"'{user_input}'ì„(ë¥¼) ì²˜ìŒ ì‹œì‘í•˜ì‹œëŠ” ë¶„ë“¤ì„ ìœ„í•œ ì‹¤ì „ ê°€ì´ë“œì…ë‹ˆë‹¤. ë³µì¡í•´ ë³´ì´ì§€ë§Œ í•µì‹¬ë§Œ ì•Œë©´ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ë”°ë¼í•  ìˆ˜ ìˆì–´ìš”."
            key_points = [
                "ì‹œì‘ ì „ í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸: ì¤€ë¹„ë¬¼ê³¼ ê¸°ë³¸ ì¡°ê±´ í™•ì¸",
                "í•µì‹¬ ë‹¨ê³„ 1: ê¸°ì´ˆë¶€í„° íƒ„íƒ„í•˜ê²Œ ì‹œì‘í•˜ê¸°",
                "í•µì‹¬ ë‹¨ê³„ 2: ì‹¤ì „ ì ìš©ê³¼ ë°˜ë³µ ì—°ìŠµ",
                "í•µì‹¬ ë‹¨ê³„ 3: ì™„ì„±ë„ ë†’ì´ê¸°ì™€ ë§ˆë¬´ë¦¬",
                "ì‹¤ìˆ˜ ë°©ì§€ íŒ: í”íˆ í•˜ëŠ” ì‹¤ìˆ˜ì™€ í•´ê²°ë²•",
                "ë‹¤ìŒ ë‹¨ê³„: ë” ë°œì „í•˜ê¸° ìœ„í•œ ì¶”ì²œ ë¦¬ì†ŒìŠ¤"
            ]
            tone = "friendly"
        elif purpose == "promotion":
            # í™ë³´: AIDA êµ¬ì¡° (Attention â†’ Interest â†’ Desire â†’ Action)
            enriched = f"ì§€ê¸ˆê¹Œì§€ ê²½í—˜í•´ë³´ì§€ ëª»í•œ ìƒˆë¡œìš´ ê°€ì¹˜ë¥¼ ë§Œë‚˜ë³´ì„¸ìš”. {user_input}ì´(ê°€) ì—¬ëŸ¬ë¶„ì˜ ì¼ìƒì„ íŠ¹ë³„í•˜ê²Œ ë°”ê¿”ë“œë¦½ë‹ˆë‹¤. ì´ë¯¸ ìˆ˜ë§ì€ ë¶„ë“¤ì´ ë§Œì¡±í•˜ê³  ê³„ì‹­ë‹ˆë‹¤."
            key_points = [
                "ì£¼ëª©í•  ê°€ì¹˜: ë‹¤ë¥¸ ê²ƒê³¼ í™•ì‹¤íˆ ë‹¤ë¥¸ ì°¨ë³„í™” í¬ì¸íŠ¸",
                "í•µì‹¬ í˜œíƒ: ê³ ê°ì´ ì–»ê²Œ ë˜ëŠ” êµ¬ì²´ì ì¸ ì´ì ",
                "ì‚¬íšŒì  ì¦ê±°: ì‹¤ì œ ì‚¬ìš©ìë“¤ì˜ ë§Œì¡± í›„ê¸°",
                "í•œì • í˜œíƒ: ì§€ê¸ˆ ì„ íƒí•˜ë©´ ì–»ëŠ” íŠ¹ë³„í•œ ê¸°íšŒ",
                "í–‰ë™ ì´‰êµ¬: ë§ì„¤ì´ë©´ ë†“ì¹˜ëŠ” í˜œíƒ"
            ]
            tone = "professional"
        elif purpose == "event":
            # ì´ë²¤íŠ¸: 5W1H êµ¬ì¡° (What, When, Where, Who, Why, How)
            enriched = f"íŠ¹ë³„í•œ ìˆœê°„ì„ í•¨ê»˜ ë§Œë“¤ì–´ê°‘ë‹ˆë‹¤. {user_input}ì— ì—¬ëŸ¬ë¶„ì„ ì´ˆëŒ€í•©ë‹ˆë‹¤. ì°¸ì—¬í•˜ì‹œëŠ” ë¶„ë“¤ê»˜ ìŠì§€ ëª»í•  ê²½í—˜ê³¼ íŠ¹ë³„í•œ í˜œíƒì„ ë“œë¦½ë‹ˆë‹¤."
            key_points = [
                "ì´ë²¤íŠ¸ ì†Œê°œ: ë¬´ì—‡ì„ ê²½í—˜í•  ìˆ˜ ìˆëŠ”ì§€",
                "ì¼ì • ì•ˆë‚´: ì–¸ì œ, ì–´ë””ì„œ ì§„í–‰ë˜ëŠ”ì§€",
                "ì°¸ì—¬ ëŒ€ìƒ: ëˆ„êµ¬ë‚˜ í™˜ì˜ ë˜ëŠ” íŠ¹ë³„ ì¡°ê±´",
                "ì°¸ì—¬ í˜œíƒ: ì°¸ê°€ìê°€ ì–»ëŠ” êµ¬ì²´ì ì¸ ë³´ìƒ",
                "ì°¸ì—¬ ë°©ë²•: ì§€ê¸ˆ ë°”ë¡œ í•  ìˆ˜ ìˆëŠ” í–‰ë™"
            ]
            tone = "exciting"
        elif purpose == "menu":
            # ë©”ë‰´: ê°ê°ì  ë¬˜ì‚¬ì™€ ìŠ¤í† ë¦¬í…”ë§
            enriched = f"ì •ì„±ê³¼ ì „ë¬¸ì„±ìœ¼ë¡œ ì¤€ë¹„í•œ íŠ¹ë³„í•œ ë©”ë‰´ì…ë‹ˆë‹¤. {user_input}ì˜ ì§„ì •í•œ ë§›ì„ ê²½í—˜í•´ë³´ì„¸ìš”. ì—„ì„ ëœ ì¬ë£Œì™€ ì¥ì¸ì˜ ì†ê¸¸ì´ ë§Œë‚˜ íƒ„ìƒí•œ ë§›ì…ë‹ˆë‹¤."
            key_points = [
                "ë©”ë‰´ ìŠ¤í† ë¦¬: ì´ ë©”ë‰´ê°€ íŠ¹ë³„í•œ ì´ìœ ",
                "ì¬ë£Œì˜ í’ˆê²©: ì—„ì„ ëœ ì‹ ì„ í•œ ì¬ë£Œ ì†Œê°œ",
                "ë§›ì˜ íŠ¹ì§•: í’ë¯¸ì™€ ì‹ê°ì˜ ì¡°í™”",
                "ì¶”ì²œ ì¡°í•©: í•¨ê»˜ ì¦ê¸°ë©´ ì¢‹ì€ í˜ì–´ë§",
                "ì£¼ë¬¸ ì•ˆë‚´: ê°€ê²©ê³¼ ì£¼ë¬¸ ë°©ë²•"
            ]
            tone = "friendly"
        else:
            # ì •ë³´: ê°€ì¹˜ ì¤‘ì‹¬ ì •ë³´ ì „ë‹¬
            enriched = f"ì•Œì•„ë‘ë©´ í™•ì‹¤íˆ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ì…ë‹ˆë‹¤. {user_input}ì— ëŒ€í•´ í•µì‹¬ë§Œ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. ë³µì¡í•œ ë‚´ìš©ì„ ì‰½ê³  ëª…í™•í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤."
            key_points = [
                "í•µì‹¬ ê°œë…: ê°€ì¥ ì¤‘ìš”í•œ ê²ƒë¶€í„° ì´í•´í•˜ê¸°",
                "ì™œ ì¤‘ìš”í•œê°€: ì´ ì •ë³´ê°€ í•„ìš”í•œ ì´ìœ ",
                "ì‹¤ì „ í™œìš©ë²•: ì¼ìƒì—ì„œ ë°”ë¡œ ì ìš©í•˜ëŠ” ë°©ë²•",
                "ì£¼ì˜ì‚¬í•­: ì•Œì•„ë‘ë©´ í”¼í•  ìˆ˜ ìˆëŠ” ì‹¤ìˆ˜",
                "ì¶”ê°€ ì •ë³´: ë” ì•Œê³  ì‹¶ë‹¤ë©´ ì°¸ê³ í•  ìë£Œ"
            ]
            tone = "professional"

        return {
            "original_input": user_input,
            "enriched_content": enriched,
            "key_points": key_points,
            "added_elements": ["ëª©ì ë³„ ì „ë¬¸ êµ¬ì¡°", "êµ¬ì²´ì  ê°€ì¹˜ ì œì•ˆ", "í–‰ë™ ìœ ë„ ë¬¸êµ¬"],
            "tone_suggestion": tone,
            "recommended_page_count": page_count,
            "page_count_reason": f"ì…ë ¥ ê¸¸ì´({input_length}ì) ê¸°ë°˜ ìë™ ê²°ì •" if not is_how_to else "How-To ì½˜í…ì¸ : ë‹¨ê³„ë³„ ì„¤ëª… í•„ìš”",
            "web_search_used": False,
            "purpose": "how_to" if is_how_to else purpose,
            "is_how_to": is_how_to,
            "content_mode": "how_to" if is_how_to else "general"
        }


# ==================== Agent 1: Orchestrator (ì¡°ìœ¨ì) ====================

class OrchestratorAgent:
    """ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ìœ¨í•˜ëŠ” ë§ˆìŠ¤í„° ì—ì´ì „íŠ¸"""

    @staticmethod
    async def analyze_user_request(enriched_data: Dict, purpose: str) -> Dict:
        """
        í™•ì¥ëœ ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—… ê³„íš ìˆ˜ë¦½

        Args:
            enriched_data: ContentEnricherAgentì˜ ê²°ê³¼
            purpose: ì½˜í…ì¸  ëª©ì 

        Returns:
            {
                "content_type": "cardnews",
                "page_count": 3,
                "target_audience": "ì¼ë°˜ ëŒ€ì¤‘",
                "tone": "ì¹œê·¼í•œ",
                "key_message": "í•µì‹¬ ë©”ì‹œì§€",
                "requires_images": true,
                "style": "modern",
                "font_pair": "pretendard",
                "enriched_content": "í™•ì¥ëœ ì½˜í…ì¸ "
            }
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨!")
                return OrchestratorAgent._get_fallback_analysis(enriched_data, purpose)

            model = GenerativeModel("gemini-2.0-flash-001")

            enriched_content = enriched_data.get('enriched_content', enriched_data.get('original_input', ''))
            recommended_pages = enriched_data.get('recommended_page_count', 3)
            tone_suggestion = enriched_data.get('tone_suggestion', 'ì¹œê·¼í•œ')

            # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš©
            prompt = get_orchestrator_prompt(
                enriched_content=enriched_content,
                key_points=enriched_data.get('key_points', []),
                recommended_pages=recommended_pages,
                tone_suggestion=tone_suggestion,
                purpose=purpose
            )

            response = model.generate_content(prompt)
            response_text = response.text.strip()

            print("ğŸ” Raw Vertex AI Analysis Response:\n", response_text)

            json_match = re.search(r'\{[\s\S]*\}', response_text)

            if json_match:
                analysis = json.loads(json_match.group(0))
                # í™•ì¥ëœ ì½˜í…ì¸  ì¶”ê°€
                analysis['enriched_content'] = enriched_content
                analysis['key_points'] = enriched_data.get('key_points', [])
                # How-To ëª¨ë“œ í”Œë˜ê·¸ ì „ë‹¬
                analysis['is_how_to'] = enriched_data.get('is_how_to', False)
                analysis['content_mode'] = enriched_data.get('content_mode', 'general')

                print(f"âœ… [Orchestrator] ë¶„ì„ ì™„ë£Œ:")
                print(f"   ğŸ“„ í˜ì´ì§€: {analysis.get('page_count', 3)}ì¥")
                print(f"   ğŸ¨ ìŠ¤íƒ€ì¼: {analysis.get('style', 'modern')}")
                print(f"   ğŸ”¤ í°íŠ¸: {analysis.get('font_pair', 'pretendard')}")
                print(f"   ğŸ“š How-To: {analysis.get('is_how_to', False)}")
                return analysis

            return OrchestratorAgent._get_fallback_analysis(enriched_data, purpose)

        except Exception as e:
            print(f"âš ï¸ [Orchestrator] ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return OrchestratorAgent._get_fallback_analysis(enriched_data, purpose)

    @staticmethod
    def _get_fallback_analysis(enriched_data: Dict, purpose: str) -> Dict:
        """í´ë°± ë¶„ì„ ê²°ê³¼ - purposeë¥¼ í¬í•¨í•˜ì—¬ í´ë°± ì½˜í…ì¸ ì—ì„œë„ ëª©ì ì— ë§ëŠ” ì½˜í…ì¸  ìƒì„±"""
        page_count = enriched_data.get('recommended_page_count', 3)
        enriched_content = enriched_data.get('enriched_content', enriched_data.get('original_input', ''))
        is_how_to = enriched_data.get('is_how_to', False)

        return {
            "content_type": "cardnews",
            "page_count": page_count,
            "page_count_reason": "ìë™ ê²°ì •",
            "target_audience": "ì¼ë°˜ ëŒ€ì¤‘",
            "tone": enriched_data.get('tone_suggestion', 'ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´'),
            "key_message": enriched_content[:50],
            "requires_images": True,
            "style": "modern",
            "font_pair": "pretendard",
            "font_reason": "ê¸°ë³¸ í°íŠ¸",
            "enriched_content": enriched_content,
            "key_points": enriched_data.get('key_points', []),
            "purpose": purpose,  # í´ë°±ì—ì„œë„ purpose ì „ë‹¬
            "is_how_to": is_how_to,  # How-To ëª¨ë“œ í”Œë˜ê·¸
            "content_mode": enriched_data.get('content_mode', 'general')
        }


# ==================== Agent 2: Content Planner (ì½˜í…ì¸  ê¸°íšì) ====================

class ContentPlannerAgent:
    """Wrtn AIë¥¼ í™œìš©í•˜ì—¬ í˜ì´ì§€ë³„ ì½˜í…ì¸ ë¥¼ ê¸°íší•˜ëŠ” ì—ì´ì „íŠ¸"""

    @staticmethod
    async def plan_cardnews_pages(user_input: str, analysis: Dict) -> List[Dict]:
        """
        Google Geminië¥¼ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ë³„ ì½˜í…ì¸  êµ¬ì„±

        Returns:
            [
                {
                    "page": 1,
                    "title": "í˜ì´ì§€ ì œëª©",
                    "content": "í˜ì´ì§€ ë‚´ìš©",
                    "visual_concept": "ë¹„ì£¼ì–¼ ì»¨ì…‰",
                    "layout": "title_center" | "split" | "full_image"
                }
            ]
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âŒ Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨!")
                return ContentPlannerAgent._get_fallback_content(user_input, analysis)

            print(f"âœ… Vertex AI í”„ë¡œì íŠ¸: {os.getenv('GOOGLE_CLOUD_PROJECT', 'bubbly-solution-480805-b5')}")
            model = GenerativeModel("gemini-2.0-flash-001")

            tone = analysis.get('tone', 'ì¹œê·¼í•œ')
            audience = analysis.get('target_audience', 'ì¼ë°˜ ëŒ€ì¤‘')
            page_count = analysis.get('page_count', 5)
            style = analysis.get('style', 'modern')
            enriched_content = analysis.get('enriched_content', user_input)
            key_points = analysis.get('key_points', [])
            is_how_to = analysis.get('is_how_to', False) or analysis.get('content_mode') == 'how_to'

            # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš© (How-To ëª¨ë“œ ë° ëª©ì  ì „ë‹¬)
            purpose = analysis.get('purpose', 'info')
            prompt = get_content_planner_prompt(
                page_count=page_count,
                enriched_content=enriched_content,
                key_points=key_points,
                tone=tone,
                audience=audience,
                style=style,
                is_how_to=is_how_to,
                purpose=purpose
            )

            # Vertex AI API í˜¸ì¶œ
            response = model.generate_content(prompt)
            response_text = response.text.strip()

            print("ğŸ” Raw Vertex AI Response:\n", response_text)

            # JSONë§Œ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì¶œ
            start = response_text.find("[")
            end = response_text.rfind("]") + 1

            if start != -1 and end != -1:
                json_text = response_text[start:end]
                print("ğŸ” Extracted JSON:\n", json_text)

                try:
                    pages = json.loads(json_text)

                    # ìƒì„±ëœ í˜ì´ì§€ ê°œìˆ˜ í™•ì¸ ì¶œë ¥
                    print(f"âœ… {len(pages)}ê°œì˜ í˜ì´ì§€ ìƒì„± ì™„ë£Œ")
                    for p in pages:
                        print(f"ğŸ“„ {p.get('page')}. {p.get('title')}")

                    return pages

                except Exception as e:
                    print("âŒ JSON ë””ì½”ë”© ì‹¤íŒ¨:", e)
                    print("ğŸ” ë””ì½”ë”© ì‹¤íŒ¨ JSON ë‚´ìš©:\n", json_text)
                    return ContentPlannerAgent._get_fallback_content(user_input, analysis)

            else:
                print("âŒ JSON êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ ( '[' ë˜ëŠ” ']' ì—†ìŒ )")
                print("ğŸ” Raw Response:\n", response_text)
                return ContentPlannerAgent._get_fallback_content(user_input, analysis)

        except Exception as e:
            print(f"âš ï¸ [Content Planner] ê¸°íš ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return ContentPlannerAgent._get_fallback_content(user_input, analysis)

    @staticmethod
    def _get_fallback_content(user_input: str, analysis: Dict) -> List[Dict]:
        """
        í´ë°± ì½˜í…ì¸  - ëª©ì (purpose)ì— ë§ëŠ” í™ë³´/ì´ë²¤íŠ¸/ì •ë³´ ì½˜í…ì¸  ìƒì„±

        í™ë³´ìš©(promotion): ë§¤ë ¥ì ì¸ ë§ˆì¼€íŒ… ë¬¸êµ¬ë¡œ êµ¬ë§¤/ì°¸ì—¬ ìœ ë„
        ì´ë²¤íŠ¸ìš©(event): ì°¸ì—¬ë¥¼ ìœ ë„í•˜ëŠ” í¥ë¯¸ë¡œìš´ ë¬¸êµ¬
        ë©”ë‰´ìš©(menu): ë©”ë‰´/ìƒí’ˆ ì†Œê°œ
        ì •ë³´ìš©(info): ìœ ìš©í•œ ì •ë³´ ì „ë‹¬
        how_to: ë‹¨ê³„ë³„ ë°©ë²• ê°€ì´ë“œ (ì‹ ê·œ)
        """
        page_count = analysis.get('page_count', 3)
        pages = []

        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        topic = analysis.get('enriched_content', user_input.strip())[:50]  # enriched_content í™œìš©
        key_points = analysis.get('key_points', [])
        purpose = analysis.get('purpose', 'info')
        is_how_to = analysis.get('is_how_to', False) or analysis.get('content_mode') == 'how_to'

        # How-To ì½˜í…ì¸  ì „ìš© í…œí”Œë¦¿
        if is_how_to or purpose == "how_to":
            page_count = max(page_count, 4)  # How-ToëŠ” ìµœì†Œ 4í˜ì´ì§€
            first_page = {
                "title": f"{topic[:15]}... í•˜ëŠ” ë²•" if len(topic) > 15 else f"{topic} í•˜ëŠ” ë²•",
                "subtitle": "ì‰½ê²Œ ë”°ë¼í•  ìˆ˜ ìˆëŠ” ì™„ë²½ ê°€ì´ë“œ",
                "hook": "ğŸ“š ì´ˆë³´ìë„ OK!",
                "visual_concept": "ë°ê³  ê¸ì •ì ì¸ êµìœ¡/ê°€ì´ë“œ ëŠë‚Œì˜ ì´ë¯¸ì§€"
            }
            middle_templates = [
                {"title": "Step 1: ì¤€ë¹„í•˜ê¸°", "content": ["â€¢ í•„ìš”í•œ ê²ƒë“¤ í™•ì¸", "â€¢ ê¸°ë³¸ í™˜ê²½ ì„¤ì •", "â€¢ ì‹œì‘ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸"], "content_type": "step"},
                {"title": "Step 2: ì‹œì‘í•˜ê¸°", "content": ["â€¢ ì²« ë²ˆì§¸ ë‹¨ê³„ ì‹¤í–‰", "â€¢ ì¤‘ìš” í¬ì¸íŠ¸ í™•ì¸", "â€¢ ì§„í–‰ ìƒí™© ì²´í¬"], "content_type": "step"},
                {"title": "Step 3: ë§ˆë¬´ë¦¬", "content": ["â€¢ ê²°ê³¼ í™•ì¸í•˜ê¸°", "â€¢ ì˜¤ë¥˜ ì ê²€", "â€¢ ìµœì¢… ì™„ë£Œ"], "content_type": "step"}
            ]
            last_page = {
                "title": "Pro Tip",
                "content": ["ğŸ’¡ ë” ì˜í•˜ëŠ” ë¹„ê²°", "âš ï¸ ì£¼ì˜í•  ì ", "âœ… í•µì‹¬ ìš”ì•½"],
                "cta": "ì„±ê³µ!"
            }

            # key_pointsê°€ ìˆìœ¼ë©´ ì ìš©
            if key_points and len(key_points) >= 3:
                for i, template in enumerate(middle_templates):
                    if i < len(key_points) - 1:  # ë§ˆì§€ë§‰ í•˜ë‚˜ëŠ” Pro Tipìš©
                        template["content"] = [f"â€¢ {key_points[i]}"]

            # í˜ì´ì§€ ìƒì„± (How-To ì „ìš©)
            for i in range(page_count):
                if i == 0:
                    page = {
                        "page": 1,
                        "title": first_page["title"],
                        "subtitle": first_page["subtitle"],
                        "content": [],
                        "content_type": "hook",
                        "visual_concept": first_page["visual_concept"],
                        "layout": "center"
                    }
                elif i == page_count - 1:
                    page = {
                        "page": i + 1,
                        "title": last_page["title"],
                        "content": last_page["content"],
                        "content_type": "tips",
                        "visual_concept": "ì„±ê³µ/ë‹¬ì„±ì„ ìƒì§•í•˜ëŠ” ê¸ì •ì  ì´ë¯¸ì§€",
                        "layout": "center"
                    }
                else:
                    template_idx = (i - 1) % len(middle_templates)
                    template = middle_templates[template_idx]
                    page = {
                        "page": i + 1,
                        "title": template["title"],
                        "content": template["content"],
                        "content_type": template.get("content_type", "step"),
                        "visual_concept": f"ë‹¨ê³„ {i}ë¥¼ ìƒì§•í•˜ëŠ” ì§„í–‰ ì¤‘ì¸ ì´ë¯¸ì§€",
                        "layout": "center"
                    }
                pages.append(page)

            return pages

        # ëª©ì ë³„ ì „ë¬¸ ì½˜í…ì¸  í…œí”Œë¦¿ (AIDA/5W1H êµ¬ì¡° ì ìš©)
        if purpose == "promotion":
            # í™ë³´ìš© í…œí”Œë¦¿ - AIDA êµ¬ì¡° (Attention â†’ Interest â†’ Desire â†’ Action)
            first_page = {
                "title": "ì§€ê¸ˆ ì£¼ëª©í•˜ì„¸ìš”",
                "subtitle": "ë‹¹ì‹ ì´ ì°¾ë˜ ë°”ë¡œ ê·¸ê²ƒ",
                "hook": "ë‹¤ë¥¸ ê³³ì—ì„œ ì°¾ê¸° í˜ë“  íŠ¹ë³„í•¨",
                "visual_concept": "ì œí’ˆ/ì„œë¹„ìŠ¤ì˜ í•µì‹¬ ê°€ì¹˜ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•œ í”„ë¦¬ë¯¸ì—„ ì´ë¯¸ì§€"
            }
            middle_templates = [
                {"title": "ì™œ íŠ¹ë³„í•œê°€", "content": ["â€¢ ì°¨ë³„í™”ëœ í•µì‹¬ ê°€ì¹˜", "â€¢ ì „ë¬¸ê°€ê°€ ì¸ì •í•œ í’ˆì§ˆ", "â€¢ ê³ ê°ì´ ì„ íƒí•œ ì´ìœ "]},
                {"title": "ì–´ë–¤ í˜œíƒì´ ìˆë‚˜", "content": ["â€¢ ì‹œê°„/ë¹„ìš© ì ˆì•½", "â€¢ í’ˆì§ˆ ë³´ì¥", "â€¢ ë§Œì¡±ë„ 100%"]},
                {"title": "ê³ ê°ì˜ ì„ íƒ", "content": ["â€¢ ì‹¤ì œ ì‚¬ìš©ì í›„ê¸°", "â€¢ ì¬êµ¬ë§¤ìœ¨ ë†’ì€ ì´ìœ ", "â€¢ ì¶”ì²œí•˜ëŠ” ì´ìœ "]},
                {"title": "ì§€ê¸ˆë§Œ ê°€ëŠ¥í•œ í˜œíƒ", "content": ["â€¢ í•œì • ê¸°ê°„ íŠ¹ê°€", "â€¢ ì¶”ê°€ í˜œíƒ ì œê³µ", "â€¢ ì„ ì°©ìˆœ ë§ˆê°"]}
            ]
            last_page = {
                "title": "ì§€ê¸ˆ ì‹œì‘í•˜ì„¸ìš”",
                "content": ["ì§€ê¸ˆ ì„ íƒí•˜ë©´ íŠ¹ë³„ í˜œíƒ", "ë¬¸ì˜/êµ¬ë§¤ ë°”ë¡œê°€ê¸°"],
                "cta": "ê¸°íšŒë¥¼ ì¡ìœ¼ì„¸ìš”"
            }
        elif purpose == "event":
            # ì´ë²¤íŠ¸ìš© í…œí”Œë¦¿ - 5W1H êµ¬ì¡°
            first_page = {
                "title": "íŠ¹ë³„í•œ ì´ˆëŒ€",
                "subtitle": "ë‹¹ì‹ ì„ ìœ„í•œ ì´ë²¤íŠ¸",
                "hook": "ì°¸ì—¬í•˜ë©´ ëˆ„êµ¬ë‚˜ ë°›ëŠ” í˜œíƒ",
                "visual_concept": "ì´ë²¤íŠ¸ì˜ í•µì‹¬ ê°€ì¹˜ì™€ í˜œíƒì„ ê°•ì¡°í•˜ëŠ” ì—­ë™ì ì¸ ì´ë¯¸ì§€"
            }
            middle_templates = [
                {"title": "ë¬´ì—‡ì„ ê²½í—˜í•˜ë‚˜ìš”", "content": ["â€¢ ì´ë²¤íŠ¸ í•µì‹¬ ë‚´ìš©", "â€¢ ì°¸ì—¬ ì‹œ ì–»ëŠ” ê°€ì¹˜", "â€¢ íŠ¹ë³„í•œ ê²½í—˜"]},
                {"title": "ì–¸ì œ, ì–´ë””ì„œ", "content": ["â€¢ ì´ë²¤íŠ¸ ê¸°ê°„", "â€¢ ì°¸ì—¬ ì¥ì†Œ/ë°©ë²•", "â€¢ ë§ˆê° ì¼ì •"]},
                {"title": "ëˆ„ê°€ ì°¸ì—¬í•  ìˆ˜ ìˆë‚˜ìš”", "content": ["â€¢ ì°¸ì—¬ ëŒ€ìƒ", "â€¢ ì°¸ì—¬ ì¡°ê±´", "â€¢ íŠ¹ë³„ ìš°ëŒ€"]},
                {"title": "ì–´ë–¤ í˜œíƒì´ ìˆë‚˜ìš”", "content": ["â€¢ ì°¸ì—¬ì ì „ì› í˜œíƒ", "â€¢ ì¶”ì²¨ ê²½í’ˆ", "â€¢ íŠ¹ë³„ ë³´ë„ˆìŠ¤"]}
            ]
            last_page = {
                "title": "ì§€ê¸ˆ ì°¸ì—¬í•˜ì„¸ìš”",
                "content": ["ì°¸ì—¬ ë°©ë²• ì•ˆë‚´", "ë§ˆê° ì „ ì„œë‘ë¥´ì„¸ìš”"],
                "cta": "ì°¸ì—¬í•˜ê¸°"
            }
        elif purpose == "menu":
            # ë©”ë‰´ìš© í…œí”Œë¦¿ - ê°ê°ì  ë¬˜ì‚¬ì™€ ìŠ¤í† ë¦¬í…”ë§
            first_page = {
                "title": "ì˜¤ëŠ˜ì˜ ì¶”ì²œ",
                "subtitle": "ì •ì„±ì„ ë‹´ì€ íŠ¹ë³„í•œ ë§›",
                "hook": "ì…°í”„ê°€ ìì‹ ìˆê²Œ ì¶”ì²œí•˜ëŠ” ë©”ë‰´",
                "visual_concept": "ë©”ë‰´ì˜ í’ë¯¸ì™€ í’ˆê²©ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ìŒì‹ ì´ë¯¸ì§€"
            }
            middle_templates = [
                {"title": "ì´ ë©”ë‰´ì˜ ì´ì•¼ê¸°", "content": ["â€¢ íƒ„ìƒ ë¹„í™”", "â€¢ ì…°í”„ì˜ ì² í•™", "â€¢ íŠ¹ë³„í•œ ì˜ë¯¸"]},
                {"title": "ì—„ì„ ëœ ì¬ë£Œ", "content": ["â€¢ ì‹ ì„ í•¨ì˜ ë¹„ê²°", "â€¢ ì‚°ì§€ ì§ì†¡ ì¬ë£Œ", "â€¢ í”„ë¦¬ë¯¸ì—„ í’ˆì§ˆ"]},
                {"title": "ë§›ì˜ íŠ¹ì§•", "content": ["â€¢ í’ë¯¸ì™€ ì‹ê°", "â€¢ ì¡°ë¦¬ë²•ì˜ ë¹„ë°€", "â€¢ ì¶”ì²œ í˜ì–´ë§"]},
                {"title": "ê°€ê²© ì•ˆë‚´", "content": ["â€¢ í•©ë¦¬ì ì¸ ê°€ê²©", "â€¢ ì„¸íŠ¸ êµ¬ì„± í˜œíƒ", "â€¢ ì£¼ë¬¸ ì˜µì…˜"]}
            ]
            last_page = {
                "title": "ì£¼ë¬¸ ì•ˆë‚´",
                "content": ["ì˜ˆì•½/ì£¼ë¬¸ ë°©ë²•", "ì˜¤ëŠ˜ì˜ í˜œíƒ"],
                "cta": "ë§›ìˆëŠ” ê²½í—˜ì„ ì‹œì‘í•˜ì„¸ìš”"
            }
        else:
            # ì •ë³´ìš© í…œí”Œë¦¿ - ê°€ì¹˜ ì¤‘ì‹¬ ì •ë³´ ì „ë‹¬
            first_page = {
                "title": "ì•Œì•„ë‘ë©´ ì¢‹ì€ ì •ë³´",
                "subtitle": "í•µì‹¬ë§Œ ì™ì™ ì •ë¦¬í–ˆì–´ìš”",
                "hook": "ì´ê²ƒë§Œ ì•Œë©´ ì¶©ë¶„í•´ìš”",
                "visual_concept": "ì •ë³´ì˜ ê°€ì¹˜ì™€ ì‹ ë¢°ê°ì„ ì „ë‹¬í•˜ëŠ” ê¹”ë”í•œ ì´ë¯¸ì§€"
            }
            middle_templates = [
                {"title": "í•µì‹¬ í¬ì¸íŠ¸", "content": ["â€¢ ê°€ì¥ ì¤‘ìš”í•œ ë‚´ìš©", "â€¢ ê¼­ ì•Œì•„ì•¼ í•  ê²ƒ", "â€¢ í•µì‹¬ ìš”ì•½"]},
                {"title": "ì™œ ì¤‘ìš”í•œê°€ìš”", "content": ["â€¢ ì´ ì •ë³´ê°€ í•„ìš”í•œ ì´ìœ ", "â€¢ ì•Œë©´ ì–»ëŠ” ì´ì ", "â€¢ ì‹¤ìƒí™œ ì ìš©"]},
                {"title": "ì‹¤ì „ í™œìš©ë²•", "content": ["â€¢ ë°”ë¡œ ì ìš©í•˜ëŠ” ë°©ë²•", "â€¢ ì‹¤ìš©ì ì¸ íŒ", "â€¢ ì£¼ì˜ì‚¬í•­"]},
                {"title": "ë” ì•Œì•„ë³´ê¸°", "content": ["â€¢ ì¶”ê°€ ì •ë³´", "â€¢ ì°¸ê³  ìë£Œ", "â€¢ ê´€ë ¨ ë§í¬"]}
            ]
            last_page = {
                "title": "ìš”ì•½ ì •ë¦¬",
                "content": ["í•µì‹¬ ë‚´ìš© í•œëˆˆì—", "ë” ê¶ê¸ˆí•˜ë©´ ë¬¸ì˜í•˜ì„¸ìš”"],
                "cta": "ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”?"
            }

        # í˜ì´ì§€ ìƒì„±
        for i in range(page_count):
            if i == 0:
                # ì²« í˜ì´ì§€: ì£¼ì œ ê¸°ë°˜ Hook
                page = {
                    "page": 1,
                    "title": first_page["title"],
                    "subtitle": first_page["subtitle"],
                    "content": [],
                    "content_type": "hook",
                    "visual_concept": first_page["visual_concept"],
                    "layout": "center"
                }
            elif i == page_count - 1:
                # ë§ˆì§€ë§‰ í˜ì´ì§€: CTA
                page = {
                    "page": i + 1,
                    "title": last_page["title"],
                    "content": last_page["content"],
                    "content_type": "cta",
                    "visual_concept": "í–‰ë™ì„ ìœ ë„í•˜ëŠ” ë°ê³  ê¸ì •ì ì¸ ì´ë¯¸ì§€",
                    "layout": "center"
                }
            else:
                # ì¤‘ê°„ í˜ì´ì§€: í‚¤í¬ì¸íŠ¸ ë˜ëŠ” í…œí”Œë¦¿
                template_idx = (i - 1) % len(middle_templates)
                template = middle_templates[template_idx]

                # key_pointsê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                if key_points and i - 1 < len(key_points):
                    content_items = [f"â€¢ {key_points[i - 1]}"]
                else:
                    content_items = template["content"]

                page = {
                    "page": i + 1,
                    "title": template["title"],
                    "content": content_items,
                    "content_type": "bullet",
                    "visual_concept": f"{topic} ê´€ë ¨ ì‹œê°ì  ì´ë¯¸ì§€",
                    "layout": "center"
                }

            pages.append(page)

        return pages


# ==================== Agent 3: Visual Designer (ë¹„ì£¼ì–¼ ë””ìì´ë„ˆ) ====================

class VisualDesignerAgent:
    """Gamma AI ë˜ëŠ” ì´ë¯¸ì§€ ìƒì„± AIë¥¼ í™œìš©í•˜ì—¬ ë¹„ì£¼ì–¼ì„ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸"""

    @staticmethod
    async def generate_page_visuals(pages: List[Dict], style: str) -> List[Dict]:
        """
        ê° í˜ì´ì§€ì˜ ë¹„ì£¼ì–¼ ì´ë¯¸ì§€ ìƒì„± - ê° í˜ì´ì§€ë§ˆë‹¤ ê³ ìœ í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            pages: í˜ì´ì§€ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸
            style: ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (modern/minimal/vibrant/professional)

        Returns:
            pagesì— image_prompt ì¶”ê°€ëœ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if not ContentEnricherAgent._ensure_vertex_ai():
                print("âš ï¸ [Visual Designer] Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨, í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±")
                return VisualDesignerAgent._generate_prompts_only(pages, style)

            model = GenerativeModel("gemini-2.0-flash-001")

            print(f"\nğŸ¨ [Visual Designer] ê° í˜ì´ì§€ë§ˆë‹¤ ê³ ìœ í•œ ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")

            for i, page in enumerate(pages):
                # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš©
                prompt = get_visual_designer_prompt(
                    page_num=i + 1,
                    total_pages=len(pages),
                    title=page['title'],
                    content=page.get('content', []),
                    visual_concept=page.get('visual_concept', ''),
                    style=style,
                    layout=page.get('layout', 'center')
                )

                response = model.generate_content(prompt)
                optimized_prompt = response.text.strip()

                # í”„ë¡¬í”„íŠ¸ ì •ë³´ ì €ì¥
                page['image_prompt'] = optimized_prompt
                page['prompt_generation_log'] = f"Vertex AIê°€ í˜ì´ì§€ {i+1}ì˜ ê³ ìœ í•œ ë¹„ì£¼ì–¼ ìƒì„±: {page['visual_concept']}"

                print(f"  âœ… í˜ì´ì§€ {i+1}/{len(pages)} ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸:")
                print(f"     ğŸ“ {optimized_prompt[:100]}...")

            print(f"\nâœ… [Visual Designer] {len(pages)}ê°œì˜ ê³ ìœ í•œ ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
            return pages

        except Exception as e:
            print(f"âš ï¸ [Visual Designer] ë¹„ì£¼ì–¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return VisualDesignerAgent._generate_prompts_only(pages, style)

    @staticmethod
    def _generate_prompts_only(pages: List[Dict], style: str) -> List[Dict]:
        """ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„± (í´ë°±)"""
        style_keywords = {
            "modern": "clean gradient background, geometric shapes, modern design, no text",
            "minimal": "minimal white background, subtle colors, simple, no text",
            "vibrant": "vibrant colors, dynamic composition, energetic, no text",
            "professional": "professional corporate background, balanced, trustworthy, no text"
        }

        base_prompt = style_keywords.get(style, style_keywords["modern"])

        for page in pages:
            page['image_prompt'] = f"{base_prompt}, {page['visual_concept']}, high quality, absolutely no text or letters or words"

        return pages


# ==================== Agent 4: Quality Assurance (í’ˆì§ˆ ê²€ì¦) ====================

class QualityAssuranceAgent:
    """ìƒì„±ëœ ì½˜í…ì¸ ì˜ í’ˆì§ˆì„ ê²€ì¦í•˜ê³  ê°œì„ í•˜ëŠ” ì—ì´ì „íŠ¸"""

    @staticmethod
    def _ensure_vertex_ai():
        """Vertex AI ì´ˆê¸°í™” í™•ì¸"""
        global _vertex_ai_initialized
        if not _vertex_ai_initialized:
            _vertex_ai_initialized = init_vertex_ai()
        return _vertex_ai_initialized

    @staticmethod
    async def validate_and_improve(pages: List[Dict], original_input: str, analysis: Dict) -> Dict:
        """
        ì½˜í…ì¸  í’ˆì§ˆ ê²€ì¦ ë° ê°œì„  ì œì•ˆ

        Returns:
            {
                "overall_score": 8.5,
                "consistency_score": 9,
                "message_clarity_score": 8,
                "needs_improvement": [2, 4],
                "suggestions": ["í˜ì´ì§€ 2: ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ìš”", ...],
                "approved": true
            }
        """
        try:
            # Vertex AI ì´ˆê¸°í™”
            QualityAssuranceAgent._ensure_vertex_ai()

            # Vertex AI ëª¨ë¸ ì‚¬ìš©
            model = GenerativeModel("gemini-2.0-flash-001")

            # ìƒˆ í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ì‚¬ìš©
            prompt = get_quality_assurance_prompt(
                original_input=original_input,
                target_audience=analysis.get('target_audience', 'ì¼ë°˜ ëŒ€ì¤‘'),
                tone=analysis.get('tone', 'ì¹œê·¼í•œ'),
                key_message=analysis.get('key_message', ''),
                pages=pages
            )

            response = model.generate_content(prompt)
            response_text = response.text.strip()

            print("ğŸ” Raw Gemini QA Response:\n", response_text)

            json_match = re.search(r'\{[\s\S]*\}', response_text)

            if json_match:
                validation = json.loads(json_match.group(0))
                print(f"âœ… [Quality Assurance] ê²€ì¦ ì™„ë£Œ")
                print(f"  ğŸ“Š ì¢…í•© ì ìˆ˜: {validation.get('overall_score', 0)}/10")
                print(f"  ğŸ“Š ë©”ì‹œì§€ ì „ë‹¬: {validation.get('message_clarity_score', 0)}/10")
                print(f"  ğŸ“Š ì¼ê´€ì„±: {validation.get('consistency_score', 0)}/10")

                if validation.get('suggestions'):
                    print("  ğŸ’¡ ê°œì„  ì œì•ˆ:")
                    for suggestion in validation['suggestions']:
                        print(f"     - {suggestion}")

                return validation

            return QualityAssuranceAgent._get_fallback_validation()

        except Exception as e:
            print(f"âš ï¸ [Quality Assurance] ê²€ì¦ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return QualityAssuranceAgent._get_fallback_validation()

    @staticmethod
    def _get_fallback_validation() -> Dict:
        """í´ë°± ê²€ì¦ ê²°ê³¼"""
        return {
            "overall_score": 7.0,
            "message_clarity_score": 7.0,
            "consistency_score": 7.0,
            "target_fit_score": 7.0,
            "needs_improvement": [],
            "suggestions": [],
            "approved": True
        }


# ==================== ìœ í‹¸ë¦¬í‹°: ìƒ‰ìƒ ì¶”ì¶œ ====================

def extract_dominant_color_from_image(image_data: str) -> Tuple[int, int, int]:
    """
    ì´ë¯¸ì§€ì—ì„œ ì£¼ìš” ìƒ‰ìƒì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë˜ëŠ” URL

    Returns:
        RGB íŠœí”Œ (r, g, b)
    """
    try:
        from PIL import Image
        import io
        import base64

        # Base64 ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
        if image_data.startswith('data:image'):
            image_bytes = base64.b64decode(image_data.split(',')[1])
            img = Image.open(io.BytesIO(image_bytes))
        else:
            import requests
            response = requests.get(image_data, timeout=10)
            img = Image.open(io.BytesIO(response.content))

        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´)
        img = img.resize((50, 50))
        img = img.convert('RGB')

        # í”½ì…€ ìƒ‰ìƒ ìˆ˜ì§‘
        pixels = list(img.getdata())

        # í‰ê·  ìƒ‰ìƒ ê³„ì‚° (ë‹¨ìˆœ ë°©ì‹)
        r_total = sum(p[0] for p in pixels)
        g_total = sum(p[1] for p in pixels)
        b_total = sum(p[2] for p in pixels)
        count = len(pixels)

        return (r_total // count, g_total // count, b_total // count)

    except Exception as e:
        print(f"âš ï¸ ìƒ‰ìƒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return (100, 100, 100)  # ê¸°ë³¸ íšŒìƒ‰


def get_text_color_for_background(bg_color: Tuple[int, int, int]) -> str:
    """
    ë°°ê²½ìƒ‰ì— ë”°ë¼ ì í•©í•œ í…ìŠ¤íŠ¸ ìƒ‰ìƒ(ê²€ì •/í°ìƒ‰)ì„ ê²°ì •í•©ë‹ˆë‹¤.

    Args:
        bg_color: RGB íŠœí”Œ (r, g, b)

    Returns:
        "white" ë˜ëŠ” "black"
    """
    r, g, b = bg_color
    # ë°ê¸° ê³„ì‚° (YIQ ê³µì‹)
    brightness = (r * 299 + g * 587 + b * 114) / 1000

    # ë°ê¸°ê°€ 128 ì´ìƒì´ë©´ ì–´ë‘ìš´ í…ìŠ¤íŠ¸, ì•„ë‹ˆë©´ ë°ì€ í…ìŠ¤íŠ¸
    return "black" if brightness > 128 else "white"


def adjust_color_for_harmony(dominant_color: Tuple[int, int, int], style: str) -> Tuple[int, int, int]:
    """
    ì¸ë„¤ì¼ì˜ ì£¼ìš” ìƒ‰ìƒì„ ê¸°ë°˜ìœ¼ë¡œ ì¡°í™”ë¡œìš´ ë‹¨ìƒ‰ ë°°ê²½ ìƒ‰ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        dominant_color: ì¸ë„¤ì¼ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” RGB ìƒ‰ìƒ
        style: ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ (modern/minimal/vibrant/professional)

    Returns:
        ì¡°ì •ëœ RGB íŠœí”Œ
    """
    r, g, b = dominant_color

    if style == "minimal":
        # ë°ê³  ë¶€ë“œëŸ¬ìš´ í†¤ìœ¼ë¡œ ì¡°ì •
        return (min(255, r + 60), min(255, g + 60), min(255, b + 60))
    elif style == "vibrant":
        # ì±„ë„ ë†’ì´ê¸°
        max_val = max(r, g, b)
        if max_val > 0:
            factor = 255 / max_val
            return (min(255, int(r * factor * 0.9)), min(255, int(g * factor * 0.9)), min(255, int(b * factor * 0.9)))
        return dominant_color
    elif style == "professional":
        # ì•½ê°„ ì–´ë‘¡ê³  ì°¨ë¶„í•˜ê²Œ
        return (max(0, r - 30), max(0, g - 30), max(0, b - 30))
    else:  # modern
        # ì›ë³¸ ìœ ì§€í•˜ë©´ì„œ ì‚´ì§ ì¡°ì •
        return (min(255, max(0, r + 10)), min(255, max(0, g + 10)), min(255, max(0, b + 10)))


# ==================== Master Workflow (ë§ˆìŠ¤í„° ì›Œí¬í”Œë¡œìš°) ====================

class AgenticCardNewsWorkflow:
    """ëª¨ë“  ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ëŠ” ë§ˆìŠ¤í„° ì›Œí¬í”Œë¡œìš°"""

    def __init__(self):
        self.content_enricher = ContentEnricherAgent()
        self.orchestrator = OrchestratorAgent()
        self.content_planner = ContentPlannerAgent()
        self.visual_designer = VisualDesignerAgent()
        self.qa = QualityAssuranceAgent()

    async def execute(self, user_input: str, purpose: str = "info", user_context: Dict = None) -> Dict:
        """
        ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ í”„ë¡¬í”„íŠ¸
            purpose: ëª©ì  (promotion/menu/info/event)
            user_context: ì˜¨ë³´ë”©ì—ì„œ ìˆ˜ì§‘í•œ ì‚¬ìš©ì ì •ë³´ (ë¸Œëœë“œ, íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤, í†¤ ë“±)

        Returns:
            {
                "success": True,
                "analysis": {...},
                "pages": [...],
                "quality_report": {...},
                "design_settings": {...}
            }
        """
        print("\n" + "="*80)
        print("ğŸš€ AI Agentic ì¹´ë“œë‰´ìŠ¤ ìƒì„± ì›Œí¬í”Œë¡œìš° ì‹œì‘")
        if user_context:
            print(f"   ğŸ¢ ë¸Œëœë“œ: {user_context.get('brand_name', 'ë¯¸ì„¤ì •')}")
            print(f"   ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤: {user_context.get('business_type', 'ë¯¸ì„¤ì •')}")
        print("="*80 + "\n")

        try:
            # Step 1: ì •ë³´ í™•ì¥ (ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            print("âœ¨ Step 1/5: ì‚¬ìš©ì ì…ë ¥ ì •ë³´ í™•ì¥ ì¤‘...")
            enriched_data = await self.content_enricher.enrich_content(user_input, purpose, user_context)
            print(f"   âœ… ì •ë³´ í™•ì¥ ì™„ë£Œ (ì¶”ê°€ ìš”ì†Œ: {len(enriched_data.get('added_elements', []))}ê°œ)\n")

            # Step 2: ìš”ì²­ ë¶„ì„ (í™•ì¥ëœ ì •ë³´ ê¸°ë°˜)
            print("ğŸ“‹ Step 2/5: ì½˜í…ì¸  ë¶„ì„ ë° ì„¤ì • ê²°ì • ì¤‘...")
            analysis = await self.orchestrator.analyze_user_request(enriched_data, purpose)
            print(f"   âœ… {analysis['page_count']}í˜ì´ì§€, {analysis['style']} ìŠ¤íƒ€ì¼, {analysis.get('font_pair', 'pretendard')} í°íŠ¸\n")

            # Step 3: ì½˜í…ì¸  ê¸°íš (í™•ì¥ëœ ì •ë³´ ì‚¬ìš©)
            print("âœï¸  Step 3/5: í˜ì´ì§€ë³„ ì½˜í…ì¸  ê¸°íš ì¤‘...")
            enriched_content = analysis.get('enriched_content', user_input)
            pages = await self.content_planner.plan_cardnews_pages(enriched_content, analysis)
            print(f"   âœ… {len(pages)}ê°œ í˜ì´ì§€ ê¸°íš ì™„ë£Œ\n")

            # Step 4: ë¹„ì£¼ì–¼ ë””ìì¸
            print("ğŸ¨ Step 4/5: ê° í˜ì´ì§€ì˜ ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            pages = await self.visual_designer.generate_page_visuals(
                pages,
                analysis.get('style', 'modern')
            )
            print(f"   âœ… ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ\n")

            # Step 5: í’ˆì§ˆ ê²€ì¦
            print("ğŸ” Step 5/5: ì½˜í…ì¸  í’ˆì§ˆ ê²€ì¦ ì¤‘...")
            quality_report = await self.qa.validate_and_improve(pages, user_input, analysis)
            print(f"   âœ… í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ\n")

            # ë””ìì¸ ì„¤ì • êµ¬ì„±
            font_pair = analysis.get('font_pair', 'pretendard')
            design_settings = {
                "font_pair": font_pair,
                "font_korean": FONT_PAIRS.get(font_pair, FONT_PAIRS['pretendard'])['korean'],
                "font_english": FONT_PAIRS.get(font_pair, FONT_PAIRS['pretendard'])['english'],
                "style": analysis.get('style', 'modern'),
                "text_color": "white",  # ê¸°ë³¸ê°’, ì¸ë„¤ì¼ ìƒì„± í›„ ì—…ë°ì´íŠ¸ë¨
                "bg_color": None  # ì¸ë„¤ì¼ ìƒ‰ìƒ ì¶”ì¶œ í›„ ì„¤ì •ë¨
            }

            print("="*80)
            print("âœ… AI Agentic ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
            print(f"   ğŸ“„ í˜ì´ì§€: {len(pages)}ì¥")
            print(f"   ğŸ”¤ í°íŠ¸: {design_settings['font_korean']} / {design_settings['font_english']}")
            print(f"   ğŸ¨ ìŠ¤íƒ€ì¼: {design_settings['style']}")
            print("="*80 + "\n")

            return {
                "success": True,
                "analysis": analysis,
                "pages": pages,
                "quality_report": quality_report,
                "design_settings": design_settings,
                "enriched_data": enriched_data
            }

        except Exception as e:
            print(f"\nâŒ ì›Œí¬í”Œë¡œìš° ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

            return {
                "success": False,
                "error": str(e),
                "analysis": None,
                "pages": [],
                "quality_report": None,
                "design_settings": None
            }
