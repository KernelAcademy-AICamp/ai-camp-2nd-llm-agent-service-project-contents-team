"""
AI ë¹„ë””ì˜¤ ìƒì„± ì„œë¹„ìŠ¤
- Master Planning Agent: ì œí’ˆ ë¶„ì„ + ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±
- Image Generation: Vertex AI Gemini 2.5 Flashë¡œ ê° ì»· ì´ë¯¸ì§€ ìƒì„±
- Video Generation: Veo 3.1ë¡œ ì»· ì‚¬ì´ íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ ìƒì„±
- Video Composition: moviepy/ffmpegë¡œ ìµœì¢… ë¹„ë””ì˜¤ í•©ì„±
"""
import os
import json
import base64
import httpx
import asyncio
from typing import List, Dict, Any, Optional
from pathlib import Path
import anthropic
import google.generativeai as genai
import vertexai
from vertexai.generative_models import GenerativeModel as VertexGenerativeModel, Part
from sqlalchemy.orm import Session

from ..models import VideoGenerationJob, User, BrandAnalysis
from ..logger import get_logger

logger = get_logger(__name__)

# Google Gemini ì„¤ì • (ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„± ìœ ì§€)
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Vertex AI ì´ˆê¸°í™” (GOOGLE_APPLICATION_CREDENTIALS ì‚¬ìš©)
try:
    location = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
    vertexai.init(
        project=os.getenv("GOOGLE_CLOUD_PROJECT"),
        location=location
    )
    logger.info(f"Vertex AI initialized: project={os.getenv('GOOGLE_CLOUD_PROJECT')}, location={location}")
except Exception as e:
    logger.warning(f"Failed to initialize Vertex AI: {e}")


class MasterPlanningAgent:
    """
    Master Planning Agent
    - ì œí’ˆ ì´ë¯¸ì§€ì™€ ì •ë³´ë¥¼ ë¶„ì„
    - ë¸Œëœë“œ ë¶„ì„ ë°ì´í„° í™œìš©
    - ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± (ì»· ìˆ˜, ê° ì»·ì˜ ì¥ë©´ ì„¤ëª…, ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸)
    """

    def __init__(self, model: str = "gemini-2.5-flash"):
        self.model = model

    async def analyze_and_plan(
        self,
        job: VideoGenerationJob,
        user: User,
        brand_analysis: Optional[BrandAnalysis],
        db: Session
    ) -> List[Dict[str, Any]]:
        """
        ì œí’ˆì„ ë¶„ì„í•˜ê³  ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±

        Args:
            job: VideoGenerationJob ì¸ìŠ¤í„´ìŠ¤
            user: User ì¸ìŠ¤í„´ìŠ¤
            brand_analysis: BrandAnalysis ì¸ìŠ¤í„´ìŠ¤ (ìˆëŠ” ê²½ìš°)
            db: Database session

        Returns:
            List[Dict]: ìŠ¤í† ë¦¬ë³´ë“œ ì»· ë¦¬ìŠ¤íŠ¸
            [
                {
                    "cut": 1,
                    "scene_description": "...",
                    "image_prompt": "...",
                    "duration": 4.0
                },
                ...
            ]
        """
        try:
            # Job ìƒíƒœ ì—…ë°ì´íŠ¸
            job.status = "planning"
            job.current_step = "Analyzing product and generating storyboard"
            db.commit()

            logger.info(f"Starting Master Planning Agent for job {job.id}")

            # ì œí’ˆ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° base64 ì¸ì½”ë”©
            image_data = await self._download_and_encode_image(job.uploaded_image_url)

            # ë¸Œëœë“œ ì •ë³´ ì¤€ë¹„
            brand_context = self._prepare_brand_context(user, brand_analysis)

            # Claudeì—ê²Œ ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± ìš”ì²­
            storyboard = await self._generate_storyboard(
                product_name=job.product_name,
                product_description=job.product_description,
                cut_count=job.cut_count,
                duration_seconds=job.duration_seconds,
                image_data=image_data,
                brand_context=brand_context
            )

            # ìŠ¤í† ë¦¬ë³´ë“œ ì €ì¥
            job.storyboard = storyboard
            db.commit()

            logger.info(f"Storyboard generated for job {job.id}: {len(storyboard)} cuts")
            return storyboard

        except Exception as e:
            logger.error(f"Error in Master Planning Agent for job {job.id}: {str(e)}")
            job.status = "failed"
            job.error_message = f"Planning failed: {str(e)}"
            db.commit()
            raise

    async def _download_and_encode_image(self, image_url: str) -> Dict[str, str]:
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (HTTP/HTTPS) ë˜ëŠ” ë¡œì»¬ íŒŒì¼ ì½ê¸° ë° base64 ì¸ì½”ë”©"""

        if image_url.startswith(("http://", "https://")):
            # HTTP/HTTPS URL - ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
            async with httpx.AsyncClient() as client:
                response = await client.get(image_url)
                response.raise_for_status()

                content_type = response.headers.get("content-type", "image/jpeg")
                media_type = content_type.split("/")[-1]
                image_content = response.content
        else:
            # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ - íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì½ê¸°
            import mimetypes

            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
            # image_urlì´ "/uploads/..."ë¡œ ì‹œì‘í•˜ë¯€ë¡œ ì•ì˜ "/" ì œê±°
            file_path = Path(__file__).parent.parent.parent / image_url.lstrip("/")

            logger.info(f"Reading image from local filesystem: {file_path}")

            if not file_path.exists():
                raise FileNotFoundError(f"Image file not found: {file_path}")

            # íŒŒì¼ ì½ê¸°
            image_content = file_path.read_bytes()

            # MIME íƒ€ì… ì¶”ì¸¡
            mime_type, _ = mimetypes.guess_type(str(file_path))
            if mime_type and mime_type.startswith("image/"):
                media_type = mime_type.split("/")[-1]
            else:
                # í™•ì¥ìë¡œ ì¶”ì¸¡
                extension = file_path.suffix.lstrip(".")
                media_type = extension if extension else "jpeg"

            logger.info(f"Image loaded from filesystem: {len(image_content)} bytes, type: image/{media_type}")

        # base64 ì¸ì½”ë”©
        image_base64 = base64.b64encode(image_content).decode("utf-8")

        return {
            "type": "base64",
            "media_type": f"image/{media_type}",
            "data": image_base64
        }

    def _prepare_brand_context(
        self,
        user: User,
        brand_analysis: Optional[BrandAnalysis]
    ) -> str:
        """ë¸Œëœë“œ ë¶„ì„ ë°ì´í„°ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¤€ë¹„"""
        context_parts = []

        # ì‚¬ìš©ì ê¸°ë³¸ ì •ë³´
        if user.brand_name:
            context_parts.append(f"ë¸Œëœë“œëª…: {user.brand_name}")
        if user.business_type:
            context_parts.append(f"ì—…ì¢…: {user.business_type}")
        if user.business_description:
            context_parts.append(f"ë¹„ì¦ˆë‹ˆìŠ¤ ì„¤ëª…: {user.business_description}")

        # ë¸Œëœë“œ ë¶„ì„ ì •ë³´
        if brand_analysis:
            if brand_analysis.brand_tone:
                context_parts.append(f"ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆ: {brand_analysis.brand_tone}")
            if brand_analysis.target_audience:
                context_parts.append(f"íƒ€ê²Ÿ ê³ ê°: {brand_analysis.target_audience}")
            if brand_analysis.emotional_tone:
                context_parts.append(f"ê°ì •ì  í†¤: {brand_analysis.emotional_tone}")
            if brand_analysis.brand_values:
                values = ", ".join(brand_analysis.brand_values) if isinstance(brand_analysis.brand_values, list) else brand_analysis.brand_values
                context_parts.append(f"ë¸Œëœë“œ ê°€ì¹˜: {values}")

        if not context_parts:
            return "ë¸Œëœë“œ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì œí’ˆ ì´ë¯¸ì§€ì™€ ì„¤ëª…ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."

        return "\n".join(context_parts)

    async def _generate_storyboard(
        self,
        product_name: str,
        product_description: Optional[str],
        cut_count: int,
        duration_seconds: int,
        image_data: Dict[str, str],
        brand_context: str
    ) -> List[Dict[str, Any]]:
        """Claudeë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±"""

        # ê° ì»·ì˜ í‰ê·  ê¸¸ì´ ê³„ì‚°
        avg_duration_per_cut = duration_seconds / cut_count

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""ë‹¹ì‹ ì€ ì œí’ˆ ë§ˆì¼€íŒ… ë¹„ë””ì˜¤ì˜ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ì œí’ˆ ì´ë¯¸ì§€ì™€ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬, {cut_count}ê°œì˜ ì»·ìœ¼ë¡œ êµ¬ì„±ëœ ì•½ {duration_seconds}ì´ˆ ê¸¸ì´ì˜ ë§ˆì¼€íŒ… ë¹„ë””ì˜¤ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì¤‘ìš”: ë¹„ìš© ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì—¬ ì»· ì •ë³´ì™€ ì „í™˜ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•´ì£¼ì„¸ìš”.**

ê° ìš”ì†Œì˜ êµ¬ì¡°:

**ì»· ì •ë³´:**
1. cut: ì»· ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
2. scene_description: ì¥ë©´ ì„¤ëª… (í•œêµ­ì–´, 2-3ë¬¸ì¥)
3. image_prompt: ì´ë¯¸ì§€ ìƒì„± AI í”„ë¡¬í”„íŠ¸ (ì˜ì–´, ìƒì„¸í•˜ê²Œ)
4. duration: ì»· ê¸¸ì´ (ì´ˆ, í‰ê·  {avg_duration_per_cut:.1f}ì´ˆ)
5. is_hero_shot: true/false
   - ì²« ì»·, ë§ˆì§€ë§‰ ì»·, ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ì»·ì€ true
   - ë‚˜ë¨¸ì§€ëŠ” false
6. resolution: "1080p" (hero shot) ë˜ëŠ” "720p" (ì¼ë°˜)

**ì „í™˜ ì •ë³´ (ì»·ê³¼ ì»· ì‚¬ì´):**
1. method: "veo" ë˜ëŠ” "ffmpeg"
   - **veo**: ì—­ë™ì  ì›€ì§ì„ í•„ìš” (ì¤Œì¸/ì•„ì›ƒ, íšŒì „, ë³µì¡í•œ ì¹´ë©”ë¼ ë¬´ë¸Œ)
   - **ffmpeg**: ì‹¬í”Œí•œ ì „í™˜ ì¶©ë¶„ (ë””ì¡¸ë¸Œ, í˜ì´ë“œ, ë‹¨ìˆœ íŒ¨ë‹)
   - **ë¹„ìš© ìµœì í™”**: ì „ì²´ ì „í™˜ì˜ 30-40%ë§Œ veo ì‚¬ìš© (ê°€ì¥ ì„íŒ©íŠ¸ ìˆëŠ” ë¶€ë¶„)
2. effect: ì „í™˜ íš¨ê³¼ëª…
   - veo: "dynamic_zoom_in", "dynamic_zoom_out", "dynamic_pan", "complex_transition"
   - ffmpeg: "dissolve", "fade", "zoom_in", "zoom_out", "pan_left", "pan_right"
3. duration: ì „í™˜ ê¸¸ì´ (veo: 4-6ì´ˆ, ffmpeg: 0.5-2ì´ˆ)
4. reason: ì´ ë°©ì‹ì„ ì„ íƒí•œ ì´ìœ  (í•œ ì¤„)

**ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„± ê°€ì´ë“œë¼ì¸:**
- ì²« ë²ˆì§¸ ì»·: ì„íŒ©íŠ¸ ìˆëŠ” ì˜¤í”„ë‹ (hero shot)
- ì¤‘ê°„ ì»·ë“¤: ì œí’ˆ íŠ¹ì§•, ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤, í˜œíƒ
- ë§ˆì§€ë§‰ ì»·: CTA ë˜ëŠ” ë¸Œëœë“œ ë©”ì‹œì§€ (hero shot)
- ì²« ì „í™˜ê³¼ ë§ˆì§€ë§‰ ì „í™˜ì€ ê°•ë ¬í•˜ê²Œ (veo ì¶”ì²œ)
- ì¤‘ê°„ ì „í™˜ ì¤‘ ë¹„ìŠ·í•œ ë¶„ìœ„ê¸°ë©´ ffmpeg ì‚¬ìš©
- ì „ì²´ íë¦„ì˜ ë¦¬ë“¬ê° ìœ ì§€
- image_promptëŠ” ì¡°ëª…, ê°ë„, ë¶„ìœ„ê¸°, ìƒ‰ê° í¬í•¨í•˜ì—¬ ìƒì„¸í•˜ê²Œ

**ì‘ë‹µ í˜•ì‹ (JSON ë°°ì—´):**
[
  {{
    "cut": 1,
    "scene_description": "...",
    "image_prompt": "...",
    "duration": 4.0,
    "is_hero_shot": true,
    "resolution": "1080p"
  }},
  {{
    "transition": {{
      "method": "veo",
      "effect": "dynamic_zoom_out",
      "duration": 4.0,
      "reason": "ì œí’ˆ ë””í…Œì¼ì—ì„œ ì „ì²´ë¡œ, ê°•ë ¬í•œ ì „í™˜ í•„ìš”"
    }}
  }},
  {{
    "cut": 2,
    "scene_description": "...",
    "image_prompt": "...",
    "duration": 4.0,
    "is_hero_shot": false,
    "resolution": "720p"
  }},
  ...
]

ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSON ë°°ì—´ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”."""

        user_message = f"""ì œí’ˆëª…: {product_name}
ì œí’ˆ ì„¤ëª…: {product_description or 'ì œê³µë˜ì§€ ì•ŠìŒ'}

ë¸Œëœë“œ ì»¨í…ìŠ¤íŠ¸:
{brand_context}

ìœ„ ì œí’ˆ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³ , {cut_count}ê°œì˜ ì»·ìœ¼ë¡œ êµ¬ì„±ëœ ì•½ {duration_seconds}ì´ˆ ê¸¸ì´ì˜ ë§ˆì¼€íŒ… ë¹„ë””ì˜¤ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ JSON ë°°ì—´ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”."""

        # Vertex AI Gemini API í˜¸ì¶œ
        logger.info(f"Calling Vertex AI Gemini API for storyboard generation ({cut_count} cuts, {duration_seconds}s)")

        # Vertex AI Gemini ëª¨ë¸ ì´ˆê¸°í™”
        gemini_model = VertexGenerativeModel(self.model)

        # image_dataë¥¼ PIL Imageë¡œ ë³€í™˜ í›„ Vertex AI Part ê°ì²´ë¡œ ë³€í™˜
        from PIL import Image
        import io

        image_bytes = base64.b64decode(image_data["data"])
        pil_image = Image.open(io.BytesIO(image_bytes))

        # PIL Image â†’ Vertex AI Part ê°ì²´ ë³€í™˜
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='JPEG')
        img_bytes = img_byte_arr.getvalue()

        image_part = Part.from_data(
            data=img_bytes,
            mime_type="image/jpeg"
        )

        # System promptì™€ user messageë¥¼ ê²°í•© (GeminiëŠ” system íŒŒë¼ë¯¸í„° ë¯¸ì§€ì›)
        combined_prompt = f"""{system_prompt}

---

{user_message}"""

        # Vertex AI Gemini API í˜¸ì¶œ (Part ê°ì²´ ì‚¬ìš©)
        response = gemini_model.generate_content([combined_prompt, image_part])

        # ì‘ë‹µ íŒŒì‹±
        response_text = response.text
        logger.info(f"Gemini response: {response_text[:200]}...")

        # JSON íŒŒì‹±
        try:
            # JSON ì½”ë“œ ë¸”ë¡ì´ ìˆë‹¤ë©´ ì¶”ì¶œ
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()
            elif "```" in response_text:
                json_start = response_text.find("```") + 3
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()

            storyboard = json.loads(response_text)

            # ìœ íš¨ì„± ê²€ì¦
            if not isinstance(storyboard, list):
                raise ValueError("Storyboard must be a list")

            # ì»·ê³¼ ì „í™˜ì„ ë¶„ë¦¬í•˜ì—¬ ê²€ì¦
            cuts = [item for item in storyboard if 'cut' in item]
            transitions = [item for item in storyboard if 'transition' in item]

            if len(cuts) != cut_count:
                logger.warning(f"Expected {cut_count} cuts but got {len(cuts)}")

            # ê° ì»· ê²€ì¦
            for i, cut in enumerate(cuts, 1):
                required_fields = ["cut", "scene_description", "image_prompt", "duration", "is_hero_shot", "resolution"]
                for field in required_fields:
                    if field not in cut:
                        raise ValueError(f"Cut {i} missing required field: {field}")

            # ê° ì „í™˜ ê²€ì¦
            for i, item in enumerate(transitions, 1):
                transition = item.get('transition', {})
                required_fields = ["method", "effect", "duration", "reason"]
                for field in required_fields:
                    if field not in transition:
                        logger.warning(f"Transition {i} missing field: {field}")

            logger.info(f"Storyboard validated: {len(cuts)} cuts, {len(transitions)} transitions")
            return storyboard

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Claude response as JSON: {str(e)}")
            logger.error(f"Response text: {response_text}")
            raise ValueError(f"Invalid JSON response from Claude: {str(e)}")


class ImageGenerationAgent:
    """
    Image Generation Agent
    - Vertex AI Gemini 2.5 Flash Image ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤í† ë¦¬ë³´ë“œ ê° ì»·ì˜ ì´ë¯¸ì§€ ìƒì„±
    - 9:16 ì„¸ë¡œ ë¹„ìœ¨ (ìˆí¼ ìµœì í™”)
    - ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— PNGë¡œ ì €ì¥
    """

    def __init__(self, model: str = "gemini-2.5-flash-image"):
        self.model = model
        logger.info(f"ImageGenerationAgent initialized with Vertex AI model: {self.model}")

    async def generate_images(
        self,
        job: VideoGenerationJob,
        storyboard: List[Dict[str, Any]],
        db: Session
    ) -> List[Dict[str, str]]:
        """
        ìŠ¤í† ë¦¬ë³´ë“œì˜ ê° ì»·ì— ëŒ€í•œ ì´ë¯¸ì§€ ìƒì„±

        Args:
            job: VideoGenerationJob ì¸ìŠ¤í„´ìŠ¤
            storyboard: ìŠ¤í† ë¦¬ë³´ë“œ ë°ì´í„° (ì»·ê³¼ ì „í™˜ì´ í˜¼í•©ëœ ë°°ì—´)
            db: Database session

        Returns:
            List[Dict]: ìƒì„±ëœ ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
            [{"cut": 1, "url": "https://...", "resolution": "1080p", "is_hero_shot": true}, ...]
        """
        try:
            # ìŠ¤í† ë¦¬ë³´ë“œì—ì„œ ì»·ë§Œ í•„í„°ë§
            cuts = [item for item in storyboard if 'cut' in item]

            # Job ìƒíƒœ ì—…ë°ì´íŠ¸
            job.status = "generating_images"
            job.current_step = f"Generating images for {len(cuts)} cuts"
            db.commit()

            logger.info(f"Starting image generation for job {job.id}: {len(cuts)} cuts")
            logger.info(f"Using Vertex AI Gemini model: {self.model}")

            generated_images = []

            for i, cut in enumerate(cuts, 1):
                try:
                    cut_number = cut['cut']
                    resolution = cut.get('resolution', '720p')
                    is_hero_shot = cut.get('is_hero_shot', False)

                    logger.info(f"Generating image for cut {cut_number}/{len(cuts)}: {cut['image_prompt'][:50]}... (resolution: {resolution}, hero: {is_hero_shot})")

                    # Job ìƒíƒœ ì—…ë°ì´íŠ¸
                    job.current_step = f"Generating image {i}/{len(cuts)}"
                    db.commit()

                    # Gemini 2.5 Flash Imageë¡œ ì´ë¯¸ì§€ ìƒì„±
                    # TODO: í•´ìƒë„ ìµœì í™” ì§€ì› ì‹œ resolution íŒŒë¼ë¯¸í„° í™œìš©
                    image_bytes = await self._generate_with_gemini_image(cut['image_prompt'])

                    if not image_bytes:
                        raise ValueError(f"Failed to generate image for cut {cut_number}")

                    # ì´ë¯¸ì§€ë¥¼ Cloudinaryì— ì—…ë¡œë“œ
                    image_url = await self._upload_to_cloudinary(
                        image_bytes,
                        job.user_id,
                        job.id,
                        cut_number
                    )

                    generated_images.append({
                        "cut": cut_number,
                        "url": image_url,
                        "prompt": cut['image_prompt'],
                        "resolution": resolution,
                        "is_hero_shot": is_hero_shot
                    })

                    logger.info(f"Image generated and uploaded for cut {cut_number}: {image_url}")

                    # ì¿¼í„° ì´ˆê³¼ ë°©ì§€ë¥¼ ìœ„í•œ ìš”ì²­ ê°„ê²© ì¶”ê°€
                    if i < len(cuts):
                        wait_time = 3  # 3ì´ˆ ëŒ€ê¸°
                        logger.info(f"ë‹¤ìŒ ì´ë¯¸ì§€ ìƒì„± ì „ {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘... (ì¿¼í„° ìµœì í™”)")
                        await asyncio.sleep(wait_time)

                except Exception as e:
                    logger.error(f"Error generating image for cut {cut.get('cut', i)}: {str(e)}")
                    # ì¼ë¶€ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                    generated_images.append({
                        "cut": cut.get('cut', i),
                        "url": None,
                        "error": str(e),
                        "prompt": cut.get('image_prompt', ''),
                        "resolution": cut.get('resolution', '720p'),
                        "is_hero_shot": cut.get('is_hero_shot', False)
                    })

            # ìƒì„±ëœ ì´ë¯¸ì§€ ì €ì¥
            job.generated_image_urls = generated_images
            db.commit()

            logger.info(f"Image generation completed for job {job.id}: {len([img for img in generated_images if img.get('url')])} successful")
            return generated_images

        except Exception as e:
            logger.error(f"Error in image generation for job {job.id}: {str(e)}")
            job.status = "failed"
            job.error_message = f"Image generation failed: {str(e)}"
            db.commit()
            raise

    async def _generate_with_gemini_image(self, prompt: str) -> bytes:
        """
        Vertex AI Gemini 2.5 Flash Image ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±
        Exponential backoff ì¬ì‹œë„ ë¡œì§ í¬í•¨ (429 ì¿¼í„° ì—ëŸ¬ ëŒ€ì‘)
        """
        import base64
        from vertexai.generative_models import GenerativeModel
        from google.api_core.exceptions import ResourceExhausted, TooManyRequests

        max_retries = 5
        base_delay = 2  # ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

        for attempt in range(max_retries):
            try:
                logger.info(f"Vertex AI Gemini 2.5 Flash Imageë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘... (ì‹œë„ {attempt + 1}/{max_retries}, í”„ë¡¬í”„íŠ¸: {prompt[:50]}...)")

                # Vertex AI Gemini ëª¨ë¸ ì´ˆê¸°í™”
                model = GenerativeModel("gemini-2.5-flash-image")

                # ì´ë¯¸ì§€ ìƒì„± ìš”ì²­
                response = model.generate_content([
                    f"Generate an image with 9:16 aspect ratio (vertical, for short-form video): {prompt}"
                ])

                # ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
                if response.candidates and len(response.candidates) > 0:
                    candidate = response.candidates[0]

                    if candidate.content and candidate.content.parts:
                        for part in candidate.content.parts:
                            # inline_data ë˜ëŠ” inlineData í˜•ì‹ í™•ì¸
                            inline_data = getattr(part, 'inline_data', None) or getattr(part, 'inlineData', None)

                            if inline_data:
                                # Vertex AIëŠ” inline_data.dataì— bytes í˜•ì‹ìœ¼ë¡œ ì €ì¥
                                if hasattr(inline_data, 'data'):
                                    image_bytes = inline_data.data
                                    mime_type = getattr(inline_data, 'mime_type', 'image/png')

                                    logger.info(f"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (ì‹œë„ {attempt + 1}, MIME type: {mime_type}, size: {len(image_bytes)} bytes)")
                                    return image_bytes
                                # ë˜ëŠ” Base64 ë¬¸ìì—´ë¡œ ì €ì¥ë˜ì–´ ìˆì„ ìˆ˜ë„ ìˆìŒ
                                elif isinstance(inline_data.get('data') if hasattr(inline_data, 'get') else None, str):
                                    image_data_base64 = inline_data['data']
                                    image_bytes = base64.b64decode(image_data_base64)

                                    logger.info(f"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (ì‹œë„ {attempt + 1}, Base64 ë””ì½”ë”©, size: {len(image_bytes)} bytes)")
                                    return image_bytes

                # ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
                logger.error(f"Vertex AI Gemini ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•¨: {response}")
                raise ValueError("Vertex AI Geminië¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            except (ResourceExhausted, TooManyRequests) as e:
                # 429 ì¿¼í„° ì—ëŸ¬ ë°œìƒ ì‹œ exponential backoff ì¬ì‹œë„
                if attempt < max_retries - 1:
                    wait_time = base_delay * (2 ** attempt)  # 2, 4, 8, 16, 32ì´ˆ
                    logger.warning(f"âš ï¸  429 ì¿¼í„° ì—ëŸ¬ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                    logger.info(f"ğŸ”„ {wait_time}ì´ˆ í›„ ì¬ì‹œë„... (exponential backoff)")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜({max_retries})ì— ë„ë‹¬. ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    raise

            except Exception as e:
                # 429 ì™¸ì˜ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì‹¤íŒ¨
                logger.error(f"âŒ Vertex AI Gemini 2.5 Flash Image ìƒì„± ì‹¤íŒ¨: {str(e)}")
                raise

    async def _upload_to_cloudinary(
        self,
        image_data: bytes,
        user_id: int,
        job_id: int,
        cut_number: int
    ) -> str:
        """ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— PNGë¡œ ì €ì¥"""
        try:
            # ì €ì¥ ê²½ë¡œ ìƒì„±
            save_dir = Path("uploads") / "ai_video_images" / str(user_id) / str(job_id)
            save_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ì €ì¥ (PNG í˜•ì‹)
            file_path = save_dir / f"cut_{cut_number}.png"
            with open(file_path, 'wb') as f:
                f.write(image_data)

            # URL ë°˜í™˜ (FastAPI static files ê²½ë¡œ)
            file_url = f"/uploads/ai_video_images/{user_id}/{job_id}/cut_{cut_number}.png"
            logger.info(f"Image saved to local filesystem as PNG: {file_url}")
            return file_url
        except Exception as e:
            logger.error(f"Failed to save image to local filesystem: {str(e)}")
            raise


class VideoGenerationAgent:
    """
    Video Generation Agent
    - Vertex AI Veo 3.1ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ê°„ íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ ìƒì„±
    - ìƒì„±ëœ ë¹„ë””ì˜¤ë¥¼ Cloudinaryì— ì—…ë¡œë“œ
    """

    def __init__(self, model: str = "veo-3.1-fast-generate-001"):
        self.model = model
        logger.info(f"VideoGenerationAgent initialized with Vertex AI model: {self.model}")

    async def generate_transition_videos(
        self,
        job: VideoGenerationJob,
        storyboard: List[Dict[str, Any]],
        images: List[Dict[str, str]],
        db: Session
    ) -> List[Dict[str, str]]:
        """
        ì´ë¯¸ì§€ ê°„ íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ ìƒì„± (Veo ë°©ì‹ë§Œ ì„ íƒì ìœ¼ë¡œ)

        Args:
            job: VideoGenerationJob ì¸ìŠ¤í„´ìŠ¤
            storyboard: ìŠ¤í† ë¦¬ë³´ë“œ ë°ì´í„° (ì „í™˜ ì •ë³´ í¬í•¨)
            images: ìƒì„±ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            db: Database session

        Returns:
            List[Dict]: ìƒì„±ëœ ë¹„ë””ì˜¤ URL ë¦¬ìŠ¤íŠ¸ (Veo ì „í™˜ë§Œ)
            [{"transition": "1-2", "url": "https://...", "method": "veo", "effect": "..."}, ...]
        """
        try:
            # ìŠ¤í† ë¦¬ë³´ë“œì—ì„œ Veo ë°©ì‹ì˜ ì „í™˜ë§Œ í•„í„°ë§
            veo_transitions = [
                item['transition'] for item in storyboard
                if 'transition' in item and item['transition'].get('method') == 'veo'
            ]

            # Job ìƒíƒœ ì—…ë°ì´íŠ¸
            job.status = "generating_videos"
            job.current_step = f"Generating {len(veo_transitions)} Veo transition videos"
            db.commit()

            logger.info(f"Starting Veo video generation for job {job.id}: {len(veo_transitions)} transitions (FFmpeg transitions will be handled in composition)")

            if not veo_transitions:
                logger.info("No Veo transitions needed - all transitions will use FFmpeg")
                job.generated_video_urls = []
                db.commit()
                return []

            generated_videos = []
            # Vertex AI ëª¨ë¸ ì‚¬ìš©
            veo_model = VertexGenerativeModel(self.model)
            logger.info(f"Using Vertex AI Veo model: {self.model}")

            # ìœ íš¨í•œ ì´ë¯¸ì§€ë§Œ í•„í„°ë§
            valid_images = [img for img in images if img.get('url')]

            if len(valid_images) < 2:
                raise ValueError("Need at least 2 images to create transition videos")

            # ì´ë¯¸ì§€ë¥¼ cut ë²ˆí˜¸ë¡œ ë§¤í•‘
            image_by_cut = {img['cut']: img for img in valid_images}

            # ìŠ¤í† ë¦¬ë³´ë“œì—ì„œ ì „í™˜ê³¼ ì»·ì˜ ë§¤í•‘ ìƒì„±
            cuts = [item for item in storyboard if 'cut' in item]

            # ê° Veo ì „í™˜ ë¹„ë””ì˜¤ ìƒì„±
            for idx, transition_data in enumerate(veo_transitions, 1):
                try:
                    effect = transition_data.get('effect', 'smooth_transition')
                    duration = transition_data.get('duration', 4.0)
                    reason = transition_data.get('reason', '')

                    # ì „í™˜ì´ ì–´ëŠ ì»· ì‚¬ì´ì¸ì§€ ì¶”ë¡  (ìŠ¤í† ë¦¬ë³´ë“œì˜ ìˆœì„œ ê¸°ë°˜)
                    # ìŠ¤í† ë¦¬ë³´ë“œì—ì„œ ì „í™˜ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ ì•ë’¤ ì»· ë²ˆí˜¸ ì¶”ì¶œ
                    transition_index = None
                    for i, item in enumerate(storyboard):
                        if 'transition' in item and item['transition'] == transition_data:
                            transition_index = i
                            break

                    if transition_index is None:
                        logger.warning(f"Could not find transition in storyboard, skipping")
                        continue

                    # ì•ë’¤ ì»· ì°¾ê¸°
                    from_cut = None
                    to_cut = None
                    for i in range(transition_index - 1, -1, -1):
                        if 'cut' in storyboard[i]:
                            from_cut = storyboard[i]['cut']
                            break
                    for i in range(transition_index + 1, len(storyboard)):
                        if 'cut' in storyboard[i]:
                            to_cut = storyboard[i]['cut']
                            break

                    if not from_cut or not to_cut:
                        logger.warning(f"Could not determine from/to cuts for transition, skipping")
                        continue

                    from_image = image_by_cut.get(from_cut)
                    to_image = image_by_cut.get(to_cut)

                    if not from_image or not to_image:
                        logger.warning(f"Missing images for transition {from_cut}-{to_cut}, skipping")
                        continue

                    transition_name = f"{from_cut}-{to_cut}"

                    logger.info(f"Generating Veo transition video {idx}/{len(veo_transitions)}: {transition_name} (effect: {effect})")

                    # Job ìƒíƒœ ì—…ë°ì´íŠ¸
                    job.current_step = f"Generating Veo transition {idx}/{len(veo_transitions)} ({effect})"
                    db.commit()

                    # íš¨ê³¼ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
                    video_prompt = self._create_veo_prompt(effect, duration)

                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    from_image_data = await self._download_image(from_image['url'])
                    to_image_data = await self._download_image(to_image['url'])

                    # Veo 3.1 API í˜¸ì¶œ (Part ê°ì²´ ì‚¬ìš©)
                    response = veo_model.generate_content([
                        Part.from_data(data=from_image_data, mime_type="image/png"),
                        Part.from_data(data=to_image_data, mime_type="image/png"),
                        video_prompt
                    ])

                    # ë¹„ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ
                    if not response.candidates or not response.candidates[0].content.parts:
                        raise ValueError(f"No video generated for transition {transition_name}")

                    video_data = response.candidates[0].content.parts[0].inline_data.data

                    # ë¹„ë””ì˜¤ë¥¼ Cloudinaryì— ì—…ë¡œë“œ
                    video_url = await self._upload_to_cloudinary(
                        base64.b64decode(video_data),
                        job.user_id,
                        job.id,
                        transition_name
                    )

                    generated_videos.append({
                        "transition": transition_name,
                        "url": video_url,
                        "from_cut": from_cut,
                        "to_cut": to_cut,
                        "method": "veo",
                        "effect": effect,
                        "duration": duration,
                        "reason": reason
                    })

                    logger.info(f"Veo transition video generated and uploaded: {transition_name} -> {video_url}")

                except Exception as e:
                    logger.error(f"Error generating Veo transition video: {str(e)}")
                    # ì¼ë¶€ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                    if 'transition_name' in locals():
                        generated_videos.append({
                            "transition": transition_name,
                            "url": None,
                            "error": str(e),
                            "method": "veo",
                            "effect": transition_data.get('effect', '')
                        })

            # ìƒì„±ëœ ë¹„ë””ì˜¤ ì €ì¥
            job.generated_video_urls = generated_videos
            db.commit()

            logger.info(f"Veo video generation completed for job {job.id}: {len([vid for vid in generated_videos if vid.get('url')])} successful")
            return generated_videos

        except Exception as e:
            logger.error(f"Error in video generation for job {job.id}: {str(e)}")
            job.status = "failed"
            job.error_message = f"Video generation failed: {str(e)}"
            db.commit()
            raise

    def _create_veo_prompt(self, effect: str, duration: float) -> str:
        """íš¨ê³¼ì— ë”°ë¥¸ Veo í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompts = {
            "dynamic_zoom_in": "Smooth, cinematic zoom in from the first image to the second image. Professional camera movement with elegant transition.",
            "dynamic_zoom_out": "Smooth, cinematic zoom out from the first image to the second image. Professional camera movement with elegant transition.",
            "dynamic_pan": "Smooth, cinematic panning from the first image to the second image. Professional lateral camera movement.",
            "complex_transition": "Dynamic, creative transition from the first image to the second image. Cinematic and engaging camera movement."
        }
        return prompts.get(effect, "Smooth transition from the first image to the second image. Professional, cinematic camera movement.")

    async def _download_image(self, url: str) -> bytes:
        """
        ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë¡œì»¬ íŒŒì¼ ë˜ëŠ” HTTP)
        - ìƒëŒ€ ê²½ë¡œ(/uploads/...)ì¸ ê²½ìš°: ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì§ì ‘ ì½ê¸°
        - ì ˆëŒ€ URL(http://, https://)ì¸ ê²½ìš°: HTTPë¡œ ë‹¤ìš´ë¡œë“œ
        """
        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì§ì ‘ ì½ê¸°
        if url.startswith('/uploads/'):
            try:
                # /uploads/ ê²½ë¡œë¥¼ ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œë¡œ ë³€í™˜
                # íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (í™˜ê²½ ë…ë¦½ì )
                # backend/app/services/ â†’ backend/app/ â†’ backend/ â†’ í”„ë¡œì íŠ¸ë£¨íŠ¸/
                file_path = Path(__file__).parent.parent.parent / url.lstrip('/')

                logger.info(f"Reading image from local filesystem: {file_path}")

                with open(file_path, 'rb') as f:
                    image_data = f.read()

                logger.info(f"Successfully read local image: {len(image_data)} bytes")
                return image_data

            except Exception as e:
                logger.error(f"Failed to read local image {file_path}: {str(e)}")
                raise
        else:
            # ì ˆëŒ€ URLì¸ ê²½ìš° HTTPë¡œ ë‹¤ìš´ë¡œë“œ
            try:
                logger.info(f"Downloading image from URL: {url}")
                async with httpx.AsyncClient() as client:
                    response = await client.get(url)
                    response.raise_for_status()
                    logger.info(f"Successfully downloaded image: {len(response.content)} bytes")
                    return response.content
            except Exception as e:
                logger.error(f"Failed to download image from {url}: {str(e)}")
                raise

    async def _upload_to_cloudinary(
        self,
        video_data: bytes,
        user_id: int,
        job_id: int,
        transition_name: str
    ) -> str:
        """ë¹„ë””ì˜¤ë¥¼ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥"""
        try:
            # ì €ì¥ ê²½ë¡œ ìƒì„±
            save_dir = Path("uploads") / "ai_video_transitions" / str(user_id) / str(job_id)
            save_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ì €ì¥
            file_path = save_dir / f"transition_{transition_name}.mp4"
            with open(file_path, 'wb') as f:
                f.write(video_data)

            # URL ë°˜í™˜ (FastAPI static files ê²½ë¡œ)
            file_url = f"/uploads/ai_video_transitions/{user_id}/{job_id}/transition_{transition_name}.mp4"
            logger.info(f"Video saved to local filesystem: {file_url}")
            return file_url
        except Exception as e:
            logger.error(f"Failed to save video to local filesystem: {str(e)}")
            raise


class VideoCompositionAgent:
    """
    Video Composition Agent
    - moviepy/ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì™€ íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ë¥¼ ìµœì¢… ë¹„ë””ì˜¤ë¡œ í•©ì„±
    - FFmpeg ê¸°ë°˜ ê°„ë‹¨í•œ ì „í™˜ íš¨ê³¼ (dissolve, fade, zoom, pan) ì§€ì›
    - ìƒì„±ëœ ìµœì¢… ë¹„ë””ì˜¤ë¥¼ Cloudinaryì— ì—…ë¡œë“œ
    """

    def __init__(self):
        pass

    def _create_ffmpeg_transition(
        self,
        from_clip,
        to_clip,
        effect: str,
        duration: float
    ):
        """
        FFmpeg ê¸°ë°˜ ì „í™˜ íš¨ê³¼ ìƒì„±

        Args:
            from_clip: ì‹œì‘ í´ë¦½
            to_clip: ì¢…ë£Œ í´ë¦½
            effect: ì „í™˜ íš¨ê³¼ëª… (dissolve, fade, zoom_in, zoom_out, pan_left, pan_right)
            duration: ì „í™˜ ê¸¸ì´ (ì´ˆ)

        Returns:
            ì „í™˜ í´ë¦½
        """
        from moviepy import CompositeVideoClip, concatenate_videoclips

        try:
            if effect == "dissolve":
                # Crossfade íš¨ê³¼
                from_clip_end = from_clip.subclip(max(0, from_clip.duration - duration), from_clip.duration)
                to_clip_start = to_clip.subclip(0, min(duration, to_clip.duration))

                # Fade outê³¼ fade in í•©ì„±
                from_clip_fading = from_clip_end.fadein(0).fadeout(duration)
                to_clip_fading = to_clip_start.fadein(duration).fadeout(0)

                transition = CompositeVideoClip([
                    from_clip_fading,
                    to_clip_fading.set_start(0)
                ]).set_duration(duration)

                return transition

            elif effect == "fade":
                # ê²€ì€ í™”ë©´ì„ í†µí•œ í˜ì´ë“œ ì „í™˜
                from moviepy import ColorClip

                fade_duration = duration / 2
                from_clip_fade = from_clip.subclip(max(0, from_clip.duration - fade_duration), from_clip.duration).fadeout(fade_duration)
                to_clip_fade = to_clip.subclip(0, min(fade_duration, to_clip.duration)).fadein(fade_duration)

                # ë‘ í´ë¦½ì„ ì—°ê²°
                transition = concatenate_videoclips([from_clip_fade, to_clip_fade], method="compose")
                return transition.set_duration(duration)

            elif effect == "zoom_in":
                # ì¤Œì¸ íš¨ê³¼ (ì²« ë²ˆì§¸ í´ë¦½ì˜ ë§ˆì§€ë§‰ í”„ë ˆì„ì—ì„œ ì‹œì‘)
                # ê°„ë‹¨í•œ êµ¬í˜„: to_clipì„ ì„œì„œíˆ í¬ê²Œ ì‹œì‘
                to_clip_short = to_clip.subclip(0, min(duration, to_clip.duration))

                def zoom_effect(get_frame, t):
                    # t: 0 to duration
                    scale = 0.8 + (0.2 * (t / duration))  # 0.8ì—ì„œ 1.0ìœ¼ë¡œ í™•ëŒ€
                    frame = get_frame(t)
                    from PIL import Image
                    import numpy as np

                    img = Image.fromarray(frame)
                    w, h = img.size
                    new_w, new_h = int(w * scale), int(h * scale)

                    # ë¦¬ì‚¬ì´ì¦ˆ í›„ ì¤‘ì•™ í¬ë¡­
                    img_resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)

                    # ì¤‘ì•™ í¬ë¡­í•˜ì—¬ ì›ë˜ í¬ê¸°ë¡œ
                    left = (new_w - w) // 2
                    top = (new_h - h) // 2

                    if new_w < w or new_h < h:
                        # íŒ¨ë”© í•„ìš”
                        result = Image.new('RGB', (w, h), (0, 0, 0))
                        result.paste(img_resized, ((w - new_w) // 2, (h - new_h) // 2))
                        return np.array(result)
                    else:
                        img_cropped = img_resized.crop((left, top, left + w, top + h))
                        return np.array(img_cropped)

                # ê°„ë‹¨í•˜ê²Œ ê·¸ëƒ¥ í˜ì´ë“œì¸ìœ¼ë¡œ ëŒ€ì²´ (ë³µì¡í•œ zoom íš¨ê³¼ëŠ” êµ¬í˜„ ì–´ë ¤ì›€)
                return to_clip_short.fadein(duration * 0.3)

            elif effect == "zoom_out":
                # ì¤Œì•„ì›ƒ íš¨ê³¼
                to_clip_short = to_clip.subclip(0, min(duration, to_clip.duration))
                return to_clip_short.fadein(duration * 0.3)

            elif effect in ["pan_left", "pan_right"]:
                # íŒ¨ë‹ íš¨ê³¼ (ê°„ë‹¨í•œ êµ¬í˜„: í˜ì´ë“œ ì „í™˜)
                to_clip_short = to_clip.subclip(0, min(duration, to_clip.duration))
                return to_clip_short.fadein(duration * 0.3)

            else:
                # ê¸°ë³¸: ê°„ë‹¨í•œ í¬ë¡œìŠ¤í˜ì´ë“œ
                to_clip_short = to_clip.subclip(0, min(duration, to_clip.duration))
                return to_clip_short.fadein(min(0.5, duration))

        except Exception as e:
            logger.error(f"Error creating FFmpeg transition effect '{effect}': {str(e)}")
            # í´ë°±: ê°„ë‹¨í•œ í˜ì´ë“œì¸
            to_clip_short = to_clip.subclip(0, min(duration, to_clip.duration))
            return to_clip_short.fadein(0.5)

    async def compose_final_video(
        self,
        job: VideoGenerationJob,
        storyboard: List[Dict[str, Any]],
        images: List[Dict[str, str]],
        transition_videos: List[Dict[str, str]],
        db: Session
    ) -> str:
        """
        ìµœì¢… ë¹„ë””ì˜¤ í•©ì„± (Veo ì „í™˜ + FFmpeg ì „í™˜ í˜¼í•©)

        Args:
            job: VideoGenerationJob ì¸ìŠ¤í„´ìŠ¤
            storyboard: ìŠ¤í† ë¦¬ë³´ë“œ ë°ì´í„° (ì»·ê³¼ ì „í™˜ì´ í˜¼í•©ëœ ë°°ì—´)
            images: ìƒì„±ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            transition_videos: ìƒì„±ëœ Veo íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ ë¦¬ìŠ¤íŠ¸
            db: Database session

        Returns:
            str: ìµœì¢… ë¹„ë””ì˜¤ URL
        """
        import tempfile
        import os
        from moviepy import (
            ImageClip,
            VideoFileClip,
            concatenate_videoclips,
            CompositeVideoClip
        )
        from PIL import Image
        import io

        try:
            # Job ìƒíƒœ ì—…ë°ì´íŠ¸
            job.status = "composing"
            job.current_step = "Composing final video with mixed transitions"
            db.commit()

            logger.info(f"Starting video composition for job {job.id}")

            # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            temp_dir = tempfile.mkdtemp()
            logger.info(f"Created temp directory: {temp_dir}")

            # ìŠ¤í† ë¦¬ë³´ë“œì—ì„œ ì»·ê³¼ ì „í™˜ ë¶„ë¦¬
            cuts = [item for item in storyboard if 'cut' in item]
            transitions_data = {}  # {index: transition_info}

            for i, item in enumerate(storyboard):
                if 'transition' in item:
                    transitions_data[i] = item['transition']

            logger.info(f"Storyboard: {len(cuts)} cuts, {len(transitions_data)} transitions")

            # ìœ íš¨í•œ ì´ë¯¸ì§€ë§Œ í•„í„°ë§ ë° ë§¤í•‘
            image_by_cut = {img['cut']: img for img in images if img.get('url')}

            if not image_by_cut:
                raise ValueError("No valid images to compose video")

            # Veo íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ ë§¤í•‘
            veo_videos = {
                tv['transition']: tv
                for tv in transition_videos
                if tv.get('url')
            }

            logger.info(f"Processing {len(image_by_cut)} images, {len(veo_videos)} Veo transitions")

            clips = []
            image_clips_cache = {}  # ì´ë¯¸ì§€ í´ë¦½ ìºì‹œ (FFmpeg ì „í™˜ì— ì¬ì‚¬ìš©)

            # ìŠ¤í† ë¦¬ë³´ë“œ ìˆœì„œëŒ€ë¡œ í´ë¦½ ìƒì„±
            for i, item in enumerate(storyboard):
                if 'cut' in item:
                    # ì»· ì²˜ë¦¬
                    cut = item
                    cut_number = cut['cut']

                    if cut_number not in image_by_cut:
                        logger.warning(f"Image for cut {cut_number} not found, skipping")
                        continue

                    try:
                        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                        image_path = os.path.join(temp_dir, f"image_{cut_number}.jpg")
                        image_bytes = await self._download_file(image_by_cut[cut_number]['url'])

                        with open(image_path, 'wb') as f:
                            f.write(image_bytes)

                        # ImageClip ìƒì„±
                        duration = cut.get('duration', 4.0)
                        image_clip = ImageClip(image_path, duration=duration)
                        clips.append(image_clip)

                        # ìºì‹œì— ì €ì¥ (FFmpeg ì „í™˜ìš©)
                        image_clips_cache[cut_number] = image_clip

                        logger.info(f"Added image clip {cut_number} with duration {duration}s")

                    except Exception as e:
                        logger.error(f"Error processing image {cut_number}: {str(e)}")
                        continue

                elif 'transition' in item:
                    # ì „í™˜ ì²˜ë¦¬
                    transition = item['transition']
                    method = transition.get('method', 'ffmpeg')
                    effect = transition.get('effect', 'dissolve')
                    duration = transition.get('duration', 1.0)

                    # ì•ë’¤ ì»· ì°¾ê¸°
                    from_cut = None
                    to_cut = None

                    for j in range(i - 1, -1, -1):
                        if 'cut' in storyboard[j]:
                            from_cut = storyboard[j]['cut']
                            break

                    for j in range(i + 1, len(storyboard)):
                        if 'cut' in storyboard[j]:
                            to_cut = storyboard[j]['cut']
                            break

                    if not from_cut or not to_cut:
                        logger.warning(f"Could not determine from/to cuts for transition, skipping")
                        continue

                    transition_key = f"{from_cut}-{to_cut}"

                    try:
                        if method == "veo":
                            # Veo ë¹„ë””ì˜¤ ì‚¬ìš©
                            if transition_key in veo_videos:
                                transition_path = os.path.join(temp_dir, f"veo_transition_{transition_key}.mp4")
                                video_bytes = await self._download_file(veo_videos[transition_key]['url'])

                                with open(transition_path, 'wb') as f:
                                    f.write(video_bytes)

                                transition_clip = VideoFileClip(transition_path)
                                clips.append(transition_clip)

                                logger.info(f"Added Veo transition {transition_key} ({effect})")
                            else:
                                logger.warning(f"Veo video for {transition_key} not found, falling back to FFmpeg")
                                # FFmpeg í´ë°±
                                if from_cut in image_clips_cache and to_cut in image_clips_cache:
                                    ffmpeg_transition = self._create_ffmpeg_transition(
                                        image_clips_cache[from_cut],
                                        image_clips_cache[to_cut],
                                        effect,
                                        duration
                                    )
                                    clips.append(ffmpeg_transition)
                                    logger.info(f"Added FFmpeg fallback transition {transition_key} ({effect})")

                        elif method == "ffmpeg":
                            # FFmpeg ì „í™˜ ìƒì„±
                            if from_cut in image_clips_cache and to_cut in image_clips_cache:
                                ffmpeg_transition = self._create_ffmpeg_transition(
                                    image_clips_cache[from_cut],
                                    image_clips_cache[to_cut],
                                    effect,
                                    duration
                                )
                                clips.append(ffmpeg_transition)
                                logger.info(f"Added FFmpeg transition {transition_key} ({effect})")
                            else:
                                logger.warning(f"Image clips for {transition_key} not found in cache")

                    except Exception as e:
                        logger.error(f"Error processing transition {transition_key}: {str(e)}")
                        # ì „í™˜ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

            if not clips:
                raise ValueError("No clips to compose")

            # Job ìƒíƒœ ì—…ë°ì´íŠ¸
            job.current_step = f"Concatenating {len(clips)} clips"
            db.commit()

            # ëª¨ë“  í´ë¦½ í•©ì„±
            logger.info(f"Concatenating {len(clips)} clips...")
            final_video = concatenate_videoclips(clips, method="compose")

            # ìµœì¢… ë¹„ë””ì˜¤ ì €ì¥
            output_path = os.path.join(temp_dir, f"final_video_{job.id}.mp4")
            logger.info(f"Writing final video to {output_path}")

            job.current_step = "Rendering final video"
            db.commit()

            final_video.write_videofile(
                output_path,
                fps=30,
                codec='libx264',
                audio=False,
                preset='medium',
                threads=4
            )

            logger.info(f"Final video rendered: {output_path}")

            # Cloudinaryì— ì—…ë¡œë“œ
            job.current_step = "Uploading final video to cloud storage"
            db.commit()

            with open(output_path, 'rb') as f:
                video_url = await self._upload_to_cloudinary(
                    f.read(),
                    job.user_id,
                    job.id
                )

            # ì¸ë„¤ì¼ ìƒì„± ë° ì—…ë¡œë“œ
            thumbnail_url = await self._generate_and_upload_thumbnail(
                final_video,
                temp_dir,
                job.user_id,
                job.id
            )

            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            logger.info("Cleaning up temporary files...")
            final_video.close()
            for clip in clips:
                try:
                    clip.close()
                except:
                    pass

            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
            import shutil
            shutil.rmtree(temp_dir)
            logger.info("Temporary files cleaned up")

            # Job ì—…ë°ì´íŠ¸
            from sqlalchemy import func
            job.final_video_url = video_url
            job.thumbnail_url = thumbnail_url
            job.status = "completed"
            job.current_step = "Video generation completed"
            job.completed_at = func.now()
            db.commit()

            logger.info(f"Video composition completed for job {job.id}: {video_url}")
            return video_url

        except Exception as e:
            logger.error(f"Error in video composition for job {job.id}: {str(e)}")
            job.status = "failed"
            job.error_message = f"Video composition failed: {str(e)}"
            db.commit()

            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ ì‹œë„
            try:
                if 'temp_dir' in locals():
                    import shutil
                    shutil.rmtree(temp_dir, ignore_errors=True)
            except:
                pass

            raise

    async def _download_file(self, url: str) -> bytes:
        """
        íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ë¡œì»¬ íŒŒì¼ ë˜ëŠ” HTTP)
        - ìƒëŒ€ ê²½ë¡œ(/uploads/...)ì¸ ê²½ìš°: ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì§ì ‘ ì½ê¸°
        - ì ˆëŒ€ URL(http://, https://)ì¸ ê²½ìš°: HTTPë¡œ ë‹¤ìš´ë¡œë“œ
        """
        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì§ì ‘ ì½ê¸°
        if url.startswith('/uploads/'):
            try:
                # /uploads/ ê²½ë¡œë¥¼ ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œë¡œ ë³€í™˜
                # íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (í™˜ê²½ ë…ë¦½ì )
                # backend/app/services/ â†’ backend/app/ â†’ backend/ â†’ í”„ë¡œì íŠ¸ë£¨íŠ¸/
                file_path = Path(__file__).parent.parent.parent / url.lstrip('/')

                logger.info(f"Reading file from local filesystem: {file_path}")

                with open(file_path, 'rb') as f:
                    file_data = f.read()

                logger.info(f"Successfully read local file: {len(file_data)} bytes")
                return file_data

            except Exception as e:
                logger.error(f"Failed to read local file {file_path}: {str(e)}")
                raise
        else:
            # ì ˆëŒ€ URLì¸ ê²½ìš° HTTPë¡œ ë‹¤ìš´ë¡œë“œ
            try:
                logger.info(f"Downloading file from URL: {url}")
                async with httpx.AsyncClient() as client:
                    response = await client.get(url)
                    response.raise_for_status()
                    logger.info(f"Successfully downloaded file: {len(response.content)} bytes")
                    return response.content
            except Exception as e:
                logger.error(f"Failed to download file from {url}: {str(e)}")
                raise

    async def _upload_to_cloudinary(
        self,
        video_data: bytes,
        user_id: int,
        job_id: int
    ) -> str:
        """ìµœì¢… ë¹„ë””ì˜¤ë¥¼ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥"""
        try:
            # ì €ì¥ ê²½ë¡œ ìƒì„±
            save_dir = Path("uploads") / "ai_video_final" / str(user_id)
            save_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ì €ì¥
            file_path = save_dir / f"video_{job_id}.mp4"
            with open(file_path, 'wb') as f:
                f.write(video_data)

            # URL ë°˜í™˜ (FastAPI static files ê²½ë¡œ)
            file_url = f"/uploads/ai_video_final/{user_id}/video_{job_id}.mp4"
            logger.info(f"Final video saved to local filesystem: {file_url}")
            return file_url
        except Exception as e:
            logger.error(f"Failed to save final video to local filesystem: {str(e)}")
            raise

    async def _generate_and_upload_thumbnail(
        self,
        video_clip,
        temp_dir: str,
        user_id: int,
        job_id: int
    ) -> str:
        """ë¹„ë””ì˜¤ì—ì„œ ì¸ë„¤ì¼ ìƒì„± ë° ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥"""
        try:
            # ì €ì¥ ê²½ë¡œ ìƒì„±
            save_dir = Path("uploads") / "ai_video_thumbnails" / str(user_id)
            save_dir.mkdir(parents=True, exist_ok=True)

            # ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ì¸ë„¤ì¼ë¡œ ì €ì¥
            thumbnail_path = save_dir / f"thumbnail_{job_id}.jpg"
            video_clip.save_frame(str(thumbnail_path), t=0)

            # URL ë°˜í™˜ (FastAPI static files ê²½ë¡œ)
            file_url = f"/uploads/ai_video_thumbnails/{user_id}/thumbnail_{job_id}.jpg"
            logger.info(f"Thumbnail saved to local filesystem: {file_url}")
            return file_url
        except Exception as e:
            logger.error(f"Failed to generate/save thumbnail: {str(e)}")
            return None


# ë¹„ë””ì˜¤ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def run_video_generation_pipeline(job_id: int, db: Session):
    """
    ë¹„ë””ì˜¤ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)

    1. Master Planning Agent: ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±
    2. Image Generation: ê° ì»·ì˜ ì´ë¯¸ì§€ ìƒì„±
    3. Video Generation: ì»· ì‚¬ì´ íŠ¸ëœì§€ì…˜ ë¹„ë””ì˜¤ ìƒì„±
    4. Video Composition: ìµœì¢… ë¹„ë””ì˜¤ í•©ì„±
    """
    try:
        # Job ì¡°íšŒ
        job = db.query(VideoGenerationJob).filter(VideoGenerationJob.id == job_id).first()
        if not job:
            logger.error(f"Job {job_id} not found")
            return

        # User ì¡°íšŒ
        user = db.query(User).filter(User.id == job.user_id).first()
        if not user:
            logger.error(f"User {job.user_id} not found for job {job_id}")
            job.status = "failed"
            job.error_message = "User not found"
            db.commit()
            return

        # BrandAnalysis ì¡°íšŒ (ìˆëŠ” ê²½ìš°)
        brand_analysis = db.query(BrandAnalysis).filter(
            BrandAnalysis.user_id == user.id
        ).first()

        # 1. Master Planning Agent ì‹¤í–‰
        logger.info(f"Step 1/4: Running Master Planning Agent for job {job_id}")
        planning_agent = MasterPlanningAgent()
        storyboard = await planning_agent.analyze_and_plan(job, user, brand_analysis, db)

        # 2. Image Generation
        cuts = [item for item in storyboard if 'cut' in item]
        logger.info(f"Step 2/4: Generating images for {len(cuts)} cuts")
        image_agent = ImageGenerationAgent()
        images = await image_agent.generate_images(job, storyboard, db)

        # 3. Video Generation (Veo transitions only)
        logger.info(f"Step 3/4: Generating Veo transition videos")
        video_agent = VideoGenerationAgent()
        videos = await video_agent.generate_transition_videos(job, storyboard, images, db)

        # 4. Video Composition (mixed: Veo + FFmpeg transitions)
        logger.info(f"Step 4/4: Composing final video with mixed transitions")
        composition_agent = VideoCompositionAgent()
        final_video_url = await composition_agent.compose_final_video(
            job, storyboard, images, videos, db
        )

        logger.info(f"Video generation pipeline completed for job {job_id}: {final_video_url}")

    except Exception as e:
        logger.error(f"Error in video generation pipeline for job {job_id}: {str(e)}")
        if job:
            job.status = "failed"
            job.error_message = str(e)
            db.commit()
